{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84524716-c757-4e6c-985d-90b5ef122840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.0 (SDL 2.28.0, Python 3.7.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import argparse\n",
    "from collections import OrderedDict\n",
    "import datetime\n",
    "import matplotlib.pylab as plt\n",
    "from numbers import Number\n",
    "import numpy as np\n",
    "import gc\n",
    "import pdb\n",
    "import pickle\n",
    "import pprint as pp\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import grad\n",
    "from torch_geometric.data.dataloader import DataLoader\n",
    "from chaotic_ellipse_dataset import Ellipse\n",
    "from utils import compute_pressForce\n",
    "from tqdm import tqdm\n",
    "import matplotlib.backends.backend_pdf\n",
    "import pprint as pp\n",
    "\n",
    "import sys, os\n",
    "\n",
    "from nbody_dataset import NBodyDataset\n",
    "from diffusion_1d import TemporalUnet1D, GaussianDiffusion1D\n",
    "from utils import p, get_item_1d, eval_simu, simulation, to_np_array, make_dir, pdump, pload\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e4d49c6-e180-4f69-8db4-88ac6fdce3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Analyze the trained model')\n",
    "\n",
    "parser.add_argument('--exp_id', default='inv_design', type=str, help='experiment folder id')\n",
    "parser.add_argument('--date_time', default='09-23', type=str, help='date for the experiment folder')\n",
    "parser.add_argument('--dataset', default='nbody-2', type=str, help='dataset to evaluate')\n",
    "\n",
    "parser.add_argument('--model_type', default='temporal-unet1d', type=str, help='model type.')\n",
    "parser.add_argument('--model_name', default='basic-model', type=str, help='model type.')\n",
    "parser.add_argument('--conditioned_steps', default=4, type=int, help='conditioned steps')\n",
    "parser.add_argument('--rollout_steps', default=20, type=int, help='rollout steps')\n",
    "parser.add_argument('--time_interval', default=4, type=int, help='time interval')\n",
    "\n",
    "parser.add_argument('--val_batch_size', default=1000, type=int, help='batch size for validation')\n",
    "parser.add_argument('--is_test', default=True, type=bool,help='flag for testing')\n",
    "parser.add_argument('--sample_steps', default=1000, type=int, help='sample steps')\n",
    "parser.add_argument('--num_features', default=4, type=int,\n",
    "                    help='in original datset,every data have 4 features,and processed datset just have 11 features ')\n",
    "\n",
    "parser.add_argument('--dataset_path', default=\"/user/project/inverse_design/dataset/nbody_dataset\", type=str,\n",
    "                    help='the path to load dataset')\n",
    "\n",
    "parser.add_argument('--n_composed', default=0, type=int,\n",
    "                    help='how many prediction to be composed')\n",
    "parser.add_argument('--compose_start_step', default=10, type=int,\n",
    "                    help='Starting step of composition.')\n",
    "parser.add_argument('--compose_n_bodies', default=2, type=int,\n",
    "                    help='Number of total bodies.')\n",
    "\n",
    "parser.add_argument('--design_guidance', type=str,\n",
    "                    help='string for list of design_guidance')\n",
    "parser.add_argument('--compose_mode', default=\"mean\", type=str,\n",
    "                    help='\"mean\" or \"noise_sum\"')\n",
    "parser.add_argument('--design_fn_mode', default=\"L2\", type=str,\n",
    "                    help='Choose from \"L2\" and \"L2square\".')\n",
    "parser.add_argument('--design_coef', default=\"0.05\", type=str,\n",
    "                    help='Coefficient for the design_fn')\n",
    "parser.add_argument('--consistency_coef', default=\"0.05\", type=str,\n",
    "                    help='Coefficient for the consistency regularization')\n",
    "\n",
    "try:\n",
    "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "    args = parser.parse_args([])\n",
    "    args.exp_id = \"test\"\n",
    "    args.n_composed = 2\n",
    "    args.compose_n_bodies = 4\n",
    "    args.compose_mode = \"mean-inside\"\n",
    "    args.design_fn_mode = \"L2\"\n",
    "    args.design_coef = \"0.4\"\n",
    "    args.consistency_coef = \"0.2\"\n",
    "\n",
    "    args.compose_start_step = 10\n",
    "    args.val_batch_size = 50\n",
    "    args.model_name = \"Diffusion_cond-0_rollout-24_bodies-2\"\n",
    "    args.model_name = \"Diffusion_cond-0_rollout-24_bodies-2_more_collision\"\n",
    "    args.sample_steps = 1000\n",
    "    design_guidance_list = [\n",
    "        # \"standard-recurrence-5\",\n",
    "        # \"standard-alpha-recurrence-5\",\n",
    "        # \"universal-forward-recurrence-5\",\n",
    "        # \"universal-backward-recurrence-5\",\n",
    "        \"standard-recurrence-10\",\n",
    "        # \"standard-alpha-recurrence-10\",\n",
    "        # \"universal-backward-pure-recurrence-10\",\n",
    "        # \"universal-forward-pure-recurrence-10\",\n",
    "        # \"universal-backward-recurrence-10\",\n",
    "        # \"universal-forward-recurrence-10\",\n",
    "        # \"standard\",\n",
    "        # \"standard-alpha\",\n",
    "        # \"universal-forward\",\n",
    "        # \"universal-backward\",\n",
    "    ]\n",
    "    args.design_guidance = \",\".join(design_guidance_list)\n",
    "    is_jupyter = True\n",
    "except:\n",
    "    args = parser.parse_args()\n",
    "    is_jupyter = False\n",
    "if args.model_name == \"basic_model\":\n",
    "    args.rollout_steps = 20\n",
    "elif args.model_name == \"single_step_model\":\n",
    "    args.rollout_steps = 4\n",
    "elif args.model_name in [\"Diffusion_cond-0_rollout-24_bodies-2\",\n",
    "                         \"Diffusion_cond-0_rollout-24_bodies-2_more_collision\",\n",
    "                        ]:\n",
    "    args.rollout_steps = 24\n",
    "    args.conditioned_steps = 0\n",
    "else:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47115bb6-0665-4088-b063-42b65437ff66",
   "metadata": {},
   "source": [
    "## Load model and dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b11bdf0-a7c5-4328-ae1b-5376afe22469",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TemporalUnet1D(\n",
    "    horizon=args.conditioned_steps + args.rollout_steps,### horizon Maybe match the time_steps\n",
    "    transition_dim=2*args.num_features, #n_bodies = 2, this matches num_bodies*nun_feactures\n",
    "    cond_dim=False,\n",
    "    dim=64,\n",
    "    dim_mults=(1, 2, 4, 8),\n",
    "    attention=True,\n",
    ")\n",
    "diffusion = GaussianDiffusion1D(\n",
    "    model,\n",
    "    image_size = args.rollout_steps,\n",
    "    conditioned_steps=args.conditioned_steps,\n",
    "    timesteps=1000,           # number of steps\n",
    "    sampling_timesteps=args.sample_steps,   # number of sampling timesteps (using ddim for faster inference [see citation for ddim paper])\n",
    "    loss_type='l1',           # L1 or L2\n",
    ").to(device)\n",
    "model_checkpoint = torch.load(f\"results/{args.model_name}.pt\")\n",
    "diffusion.load_state_dict(model_checkpoint[\"model\"])\n",
    "\n",
    "dataset = NBodyDataset(\n",
    "    dataset=f\"nbody-2\",\n",
    "    input_steps=args.conditioned_steps,\n",
    "    output_steps=args.rollout_steps+args.n_composed*args.compose_start_step,\n",
    "    time_interval=4,\n",
    "    is_y_diff=False,\n",
    "    is_train=not args.is_test,\n",
    "    is_testdata=False,\n",
    "    dataset_path=args.dataset_path\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=args.val_batch_size, shuffle=False, pin_memory=True, num_workers=6)\n",
    "\n",
    "for data in dataloader:\n",
    "    break\n",
    "if args.model_name not in [\"Diffusion_cond-0_rollout-24_bodies-2\", \"Diffusion_cond-0_rollout-24_bodies-2_more_collision\"]:\n",
    "    cond = get_item_1d(data, \"x\").to(device)\n",
    "else:\n",
    "    cond = None\n",
    "    initial_state_overwrite = get_item_1d(data, \"y\").to(device)[:,:4]\n",
    "y_gt = get_item_1d(data, \"y\")\n",
    "output_steps = args.rollout_steps+args.n_composed*args.compose_start_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d227aff7-08f4-4ef0-a4d4-e64a3f2fc098",
   "metadata": {},
   "source": [
    "## Design:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81019e0d-7da3-48e3-9a06-5f76e97ee252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective:\n",
    "def get_design_fn(pos_target, last_n_step, gamma=2, coef=100, time_consistency_coef=0, design_fn_mode=\"L2\"):\n",
    "    assert len(pos_target.shape) == 1\n",
    "    def point_objective(pos):\n",
    "        \"\"\"pos: [B, steps, n_bodies*4]\"\"\"\n",
    "        n_bodies = pos.shape[-1] // 4\n",
    "        if design_fn_mode == \"L2\":\n",
    "            assert gamma == 2\n",
    "            loss = torch.stack([(((pos[...,-last_n_step:,jj*4:jj*4+2] - pos_target).abs() ** gamma).sum(-1) ** (1/gamma)).mean(-1).sum(0) for jj in range(n_bodies)]).sum()\n",
    "        elif design_fn_mode == \"L2square\":\n",
    "            assert gamma == 2\n",
    "            loss = torch.stack([((pos[...,-last_n_step:,jj*4:jj*4+2] - pos_target).abs() ** gamma).sum(-1).mean(-1).sum(0) for jj in range(n_bodies)]).sum()\n",
    "        else:\n",
    "            raise\n",
    "        loss_total = loss * coef\n",
    "        if time_consistency_coef > 0:\n",
    "            indices = torch.cat([torch.arange(ii*4,ii*4+2) for ii in range(n_bodies)])\n",
    "            loss_total = loss_total + (pos[:,1:,indices] - pos[:,:-1,indices]).square().sum(-1).mean(-1).sum() * time_consistency_coef\n",
    "        return loss_total\n",
    "    return point_objective\n",
    "\n",
    "def get_eval_fn(pos_target, last_n_step, gamma=2):\n",
    "    \"\"\"pos: [B, steps, F], pos_target: [F]\"\"\"\n",
    "    assert len(pos_target.shape) == 1\n",
    "    def point_eval_objective(pos):\n",
    "        n_bodies = pos.shape[-1] // 4\n",
    "        loss = torch.stack([(((pos[...,-last_n_step:,jj*4:jj*4+2] - pos_target).abs() ** gamma).sum(-1) ** (1/gamma)).mean() for jj in range(n_bodies)]).mean()\n",
    "        return loss.item()\n",
    "    return point_eval_objective\n",
    "\n",
    "\n",
    "def get_eval_fn_std(pos_target, last_n_step, gamma=2):\n",
    "    \"\"\"pos: [B, steps, F], pos_target: [F]\"\"\"\n",
    "    assert len(pos_target.shape) == 1\n",
    "    def point_eval_objective_std(pos):\n",
    "        n_bodies = pos.shape[-1] // 4\n",
    "        loss = torch.cat([(((pos[...,-last_n_step:,jj*4:jj*4+2] - pos_target).abs() ** gamma).sum(-1) ** (1/gamma)) for jj in range(n_bodies)], -1).mean(-1)\n",
    "        loss_std = loss.std()\n",
    "        return loss_std.item()\n",
    "    return point_eval_objective_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a8a6e-03e0-45ad-8751-c97863c9e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With composition:\n",
    "print(f\"n_composed: {args.n_composed}\")\n",
    "print(f\"compose_n_bodies: {args.compose_n_bodies}\")\n",
    "print(\"model name: \", args.model_name)\n",
    "pp.pprint(args.__dict__)\n",
    "start_eval_t = 0\n",
    "pos_target = torch.tensor([0.5,0.5], device=device, dtype=float)\n",
    "for design_guidance in args.design_guidance.split(\",\"):\n",
    "    for design_coef in args.design_coef.split(\",\"):\n",
    "        design_coef = eval(design_coef)\n",
    "        for consistency_coef in args.consistency_coef.split(\",\"):\n",
    "            data_record = {}\n",
    "            consistency_coef = eval(consistency_coef)\n",
    "            design_fn = get_design_fn(\n",
    "                pos_target,\n",
    "                last_n_step=1,\n",
    "                coef=design_coef,\n",
    "                time_consistency_coef=consistency_coef,\n",
    "                design_fn_mode=args.design_fn_mode,\n",
    "            )\n",
    "            eval_fn = get_eval_fn(pos_target, last_n_step=1)\n",
    "            eval_fn_std = get_eval_fn_std(pos_target, last_n_step=1)\n",
    "            p.print(f\"Design guidance: {design_guidance}, design_coef: {design_coef}, consistency_coef: {consistency_coef}\", banner_size=100)\n",
    "            data_record.update(args.__dict__)\n",
    "            data_record[\"design_coef\"] = design_coef\n",
    "            data_record[\"consistency_coef\"] = consistency_coef\n",
    "            data_record[\"design_guidance\"] = design_guidance\n",
    "            \n",
    "            pred = diffusion.sample(\n",
    "                batch_size=args.val_batch_size,\n",
    "                cond=cond,\n",
    "                is_composing_time=args.n_composed>0,\n",
    "                n_composed=args.n_composed,\n",
    "                compose_start_step=args.compose_start_step,\n",
    "                compose_n_bodies=args.compose_n_bodies,\n",
    "                compose_mode=args.compose_mode,\n",
    "                design_fn=design_fn,\n",
    "                design_guidance=design_guidance,\n",
    "            )\n",
    "            pred_simu, design_obj_simu = eval_simu(\n",
    "                cond_design=pred[:50,start_eval_t:start_eval_t+1],\n",
    "                design_fn=eval_fn,\n",
    "                n_bodies=args.compose_n_bodies,\n",
    "                rollout_steps=output_steps - 1,\n",
    "            )\n",
    "            data_record[\"pred\"] = to_np_array(pred)\n",
    "            data_record[\"pred_simu\"] = to_np_array(pred_simu)\n",
    "            data_record[\"design_obj_simu\"] = design_obj_simu\n",
    "            design_obj_simu_CI = eval_fn_std(pred_simu) * 1.96 / np.sqrt(args.val_batch_size)\n",
    "            data_record[\"design_obj_simu_CI\"] = design_obj_simu_CI\n",
    "            pred_simu = torch.cat([pred[:50,:start_eval_t+1].to(device), pred_simu], 1)\n",
    "            diff = pred_simu - pred\n",
    "            RMSE = diff.square().mean((1,2)).sqrt().mean()\n",
    "            # 95% confidence interval:\n",
    "            RMSE_CI = diff.square().mean((1,2)).sqrt().std() * 1.96 / np.sqrt(args.val_batch_size)\n",
    "            MAE = torch.nn.L1Loss()(pred_simu, pred).item()\n",
    "            MAE_CI = diff.abs().mean((1,2)).std().item() * 1.96 / np.sqrt(args.val_batch_size)\n",
    "            data_record[\"RMSE\"] = RMSE\n",
    "            data_record[\"RMSE_CI\"] = RMSE_CI\n",
    "            data_record[\"MAE\"] = MAE\n",
    "            data_record[\"MAE_CI\"] = MAE_CI\n",
    "            print(f\"design_obj_simu: {design_obj_simu:.6f} ± {design_obj_simu_CI:.6f}\", )\n",
    "            print(f\"RMSE: {RMSE} ± {RMSE_CI}\", )\n",
    "            print(f\"MAE: {MAE} ± {MAE_CI}\", )\n",
    "            if np.isnan(design_obj_simu):\n",
    "                pred_simu_mask = ~torch.isnan(pred_simu.mean((1,2)))\n",
    "                design_obj_simu_nonan = eval_fn(pred_simu[pred_simu_mask])\n",
    "                print(f\"{torch.sum(~pred_simu_mask).item()} elements are NaN. After excluding, design_obj_simu = {design_obj_simu_nonan}\")\n",
    "                data_record[\"design_obj_simu_nonan\"] = design_obj_simu_nonan\n",
    "\n",
    "            fontsize = 16\n",
    "            T = pred.shape[1]\n",
    "\n",
    "            dirname = f\"results/inverse_design_diffusion/{args.exp_id}_{args.date_time}/\"\n",
    "            filename = f\"comp_{args.compose_n_bodies}_nt_{args.n_composed}_guid_{design_guidance}_descoef_{design_coef}_conscoef_{consistency_coef}_desmode_{args.design_fn_mode}_compmode_{args.compose_mode}_val_{args.val_batch_size}\"\n",
    "            make_dir(dirname + filename)\n",
    "            pdump(data_record, dirname + \"record_\" + filename + \".p\")\n",
    "            pdf = matplotlib.backends.backend_pdf.PdfPages(dirname + filename + \".pdf\")\n",
    "\n",
    "            for ball_id in range(20):\n",
    "                fig = plt.figure(figsize=(20,8))\n",
    "                plt.subplot(1,2,1)\n",
    "                # diffused traj:\n",
    "                for ii in range(args.compose_n_bodies):\n",
    "                    plt.plot(pred.cpu()[ball_id, :, ii*4], pred.cpu()[ball_id, :, ii*4+1])\n",
    "                    plt.scatter(pred.cpu()[ball_id, :, ii*4], pred.cpu()[ball_id, :, ii*4+1], s=np.arange(1, T+1)*5, marker=\"v\")\n",
    "                # evolved traj with initial design:\n",
    "                for ii in range(args.compose_n_bodies):\n",
    "                    plt.plot(pred_simu.cpu()[ball_id, :, ii*4], pred_simu.cpu()[ball_id, :, ii*4+1])\n",
    "                    plt.scatter(pred_simu.cpu()[ball_id, :, ii*4], pred_simu.cpu()[ball_id, :, ii*4+1], s=np.arange(1, T+1)*5, marker=\"+\")\n",
    "                plt.xlim([0,1])\n",
    "                plt.ylim([0,1])\n",
    "                plt.title(f\"design_obj_eval = {design_obj_simu:.9f} ± {design_obj_simu_CI:.6f}\", fontsize=fontsize)\n",
    "                plt.subplot(1,2,2)\n",
    "                for ii in range(args.compose_n_bodies):\n",
    "                    plt.plot(pred_simu.cpu()[ball_id, :, ii*4], pred_simu.cpu()[ball_id, :, ii*4+1])\n",
    "                    plt.scatter(pred_simu.cpu()[ball_id, :, ii*4], pred_simu.cpu()[ball_id, :, ii*4+1], s=np.arange(1, T+1)*5, marker=\"+\")\n",
    "                plt.xlim([0,1])\n",
    "                plt.ylim([0,1])\n",
    "                plt.title(f\"RMSE = {RMSE:.9f}    MAE = {MAE:.9f} ± {MAE_CI:.6f}\")\n",
    "                pdf.savefig(fig)\n",
    "                if is_jupyter:\n",
    "                    plt.show()\n",
    "            pdf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "invDes_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
