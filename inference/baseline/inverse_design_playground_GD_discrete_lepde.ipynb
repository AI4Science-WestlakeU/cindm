{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41481747-0049-4511-b512-df8489041673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import OrderedDict\n",
    "import datetime\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pylab as plt\n",
    "from numbers import Number\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "pd.options.display.max_rows = 1500\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.width = 1000\n",
    "pd.set_option('max_colwidth', 400)\n",
    "import pdb\n",
    "import pickle\n",
    "import pprint as pp\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from deepsnap.batch import Batch as deepsnap_Batch\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..', '..'))\n",
    "from le_pde.argparser import arg_parse\n",
    "from le_pde.datasets.load_dataset import load_data\n",
    "from le_pde.models import load_model\n",
    "from le_pde.pytorch_net.util import groupby_add_keys, filter_df, get_unique_keys_df, Attr_Dict, Printer, get_num_params, get_machine_name, pload, pdump, to_np_array, get_pdict, reshape_weight_to_matrix, ddeepcopy as deepcopy, plot_vectors, record_data, filter_filename, Early_Stopping, str2bool, get_filename_short, print_banner, plot_matrices, get_num_params, init_args, filter_kwargs, to_string, COLOR_LIST\n",
    "from le_pde.utils import update_legacy_default_hyperparam, EXP_PATH, deepsnap_to_pyg, LpLoss, to_cpu, to_tuple_shape, parse_multi_step, loss_op, get_device, get_data_next_step\n",
    "from utils import compute_pressForce\n",
    "#from le_pde.utils import deepsnap_to_pyg, LpLoss, to_cpu, to_tuple_shape, parse_multi_step, loss_op, get_device, get_data_next_step\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "p = Printer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34edf99f-9265-45b0-906d-650e4261dc77",
   "metadata": {},
   "source": [
    "## 1. Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67193e7b-5777-4aac-9426-f91e6837d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(data_record):\n",
    "    x_axis = np.arange(len(data_record[\"train_loss\"]))\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(x_axis, data_record[\"train_loss\"], label=\"train\")\n",
    "    plt.plot(x_axis, data_record[\"val_loss\"], label=\"val\")\n",
    "    plt.plot(x_axis, data_record[\"test_loss\"], label=\"test\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.semilogy(x_axis, data_record[\"train_loss\"], label=\"train\")\n",
    "    plt.semilogy(x_axis, data_record[\"val_loss\"], label=\"val\")\n",
    "    plt.semilogy(x_axis, data_record[\"test_loss\"], label=\"test\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4494e7-afaf-4d55-a1fc-b32168ca62b5",
   "metadata": {},
   "source": [
    "## 2. Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a74011e-cb80-444a-ae95-6f29d830193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_PATH = \"./results/\"\n",
    "\n",
    "isplot = True\n",
    "all_hash = [\n",
    "    # \"0LVoHLHQ_ampere4\",\n",
    "    # \"zDOCitP9_ampere4\",\n",
    "    # \"6en0gt6G_turing1\",\n",
    "    # \"zHQu3EKe_turing2\",\n",
    "    # \"2okNCadZ_turing3\",\n",
    "    # \"I6EepBQI_turing3\",\n",
    "    # \"clnAWVnz_hyperturing1\",\n",
    "    # \"YDHgg+il_turing3\",\n",
    "    # \"HD2hmsb+_turing3\",\n",
    "    # \"krep6ZNu_turing2\",\n",
    "    \"QvUQ8aaL_turing2\",\n",
    "]\n",
    "hash_str = all_hash[0]\n",
    "dirname = EXP_PATH + \"naca_ellipse_2023-04-30/\"\n",
    "filename = filter_filename(dirname, include=hash_str)\n",
    "if len(filename) == 0:\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    data_record = pload(dirname + filename[0])\n",
    "except Exception as e:\n",
    "    print(f\"error {e}\")\n",
    "    # continue\n",
    "    raise\n",
    "if isplot:\n",
    "    plot_learning_curve(data_record)\n",
    "args = init_args(update_legacy_default_hyperparam(data_record[\"args\"]))\n",
    "args.filename = filename\n",
    "# model = load_model(data_record[\"best_model_dict\"], device=device)\n",
    "model = load_model(data_record[\"model_dict\"][-1], device=device)\n",
    "model.eval()\n",
    "p.print(filename, banner_size=100)\n",
    "\n",
    "# Load test dataset:\n",
    "args_test = deepcopy(args)\n",
    "if args.temporal_bundle_steps == 1:\n",
    "    if args.dataset in [\"fno\", \"fno-2\", \"fno-3\"]:\n",
    "        args_test.multi_step = \"20\"\n",
    "    elif args.dataset in [\"fno-1\"]:\n",
    "        args_test.multi_step = \"40\"\n",
    "    elif args.dataset in [\"fno-4\"]:\n",
    "        args_test.multi_step = \"10\"\n",
    "    elif args.dataset in [\"naca_ellipse_lepde\"]:\n",
    "        args_test.multi_step = \"1\"\n",
    "        args_test.latent_multi_step=\"1\"\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    pass\n",
    "args_test.batch_size = 1\n",
    "args_test.is_test_only=True\n",
    "\n",
    "(dataset_train_val, dataset_test), (train_loader, val_loader, test_loader) = load_data(args_test)\n",
    "test_loader = DataLoader(dataset_test, num_workers=0, collate_fn=deepsnap_Batch.collate(),\n",
    "                         batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c2ec3-faee-4f4d-b028-7026e83cf37a",
   "metadata": {},
   "source": [
    "## 3. inverse optimization with LEPDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57467659-cf55-4963-9194-ad76d1d57f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_PATH = \"./results/\"\n",
    "\n",
    "isplot = True\n",
    "all_hash = [\n",
    "    # \"0LVoHLHQ_ampere4\",\n",
    "    # \"zDOCitP9_ampere4\",\n",
    "    # \"6en0gt6G_turing1\",\n",
    "    # \"zHQu3EKe_turing2\",\n",
    "    # \"2okNCadZ_turing3\",\n",
    "    # \"I6EepBQI_turing3\",\n",
    "    # \"clnAWVnz_hyperturing1\",\n",
    "    # \"YDHgg+il_turing3\",\n",
    "    # \"HD2hmsb+_turing3\",\n",
    "    # \"krep6ZNu_turing2\",\n",
    "    #\"QvUQ8aaL_turing2\", #<---- most recent\n",
    "    \"YpkNljy1_whdeng\",\n",
    "]\n",
    "hash_str = all_hash[0]\n",
    "dirname = EXP_PATH + \"naca_ellipse_2023-09-27/\"\n",
    "filename = filter_filename(dirname, include=hash_str)\n",
    "if len(filename) == 0:\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    data_record = pload(dirname + filename[0])\n",
    "except Exception as e:\n",
    "    print(f\"error {e}\")\n",
    "    # continue\n",
    "    raise\n",
    "if isplot:\n",
    "    plot_learning_curve(data_record)\n",
    "args = init_args(update_legacy_default_hyperparam(data_record[\"args\"]))\n",
    "args.filename = filename\n",
    "# model = load_model(data_record[\"best_model_dict\"], device=device)\n",
    "model = load_model(data_record[\"model_dict\"][-1], device=device)\n",
    "model.eval()\n",
    "p.print(filename, banner_size=100)\n",
    "\n",
    "# Load test dataset:\n",
    "args_test = deepcopy(args)\n",
    "if args.temporal_bundle_steps == 1:\n",
    "    if args.dataset in [\"fno\", \"fno-2\", \"fno-3\"]:\n",
    "        args_test.multi_step = \"20\"\n",
    "    elif args.dataset in [\"fno-1\"]:\n",
    "        args_test.multi_step = \"40\"\n",
    "    elif args.dataset in [\"fno-4\"]:\n",
    "        args_test.multi_step = \"10\"\n",
    "    elif args.dataset in [\"naca_ellipse_lepde\"]:\n",
    "        args_test.multi_step = \"1\"\n",
    "        args_test.latent_multi_step=\"1\"\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    pass\n",
    "args_test.batch_size = 1\n",
    "args_test.is_test_only=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ffc2c1-52e5-4830-ae2f-42666d6354b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_2d_boundary_mask import ForceUnet\n",
    "force_model = ForceUnet(\n",
    "    dim = 64,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    channels=4\n",
    ")\n",
    "force_model.load_state_dict(torch.load(\"./dataset/epoch_12.pth\"))\n",
    "force_model.to(device)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d656282-762c-4f44-a519-88fe7c357ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_filename = os.path.join(\"./dataset/naca_ellipse/training_trajectories/\", \"normalization_max_min.p\")\n",
    "normdict = pickle.load(open(normalization_filename, \"rb\"))\n",
    "x_max = normdict[\"x_max\"]\n",
    "x_min = normdict[\"x_min\"]\n",
    "y_max = normdict[\"y_max\"]\n",
    "y_min = normdict[\"y_min\"]\n",
    "p_max = normdict[\"p_max\"]\n",
    "p_min = normdict[\"p_min\"]\n",
    "p_max = p_max.to(device)\n",
    "p_min = p_min.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14be654b-6d73-419d-a1c9-b13c2b7e8861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from le_pde.utils import get_data_next_step_with_static\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from utils import compute_pressForce, compute_orthonormal, linear_transform, update_data\n",
    "        \n",
    "optim_iter = 100\n",
    "\n",
    "prerollout = 0\n",
    "one_period = 6\n",
    "vis_prerollout = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c108e7-4870-45a2-9657-6213c9ebb9f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for testnum in range(10):\n",
    "    print(\"testnum: \", testnum)\n",
    "    data_list = []\n",
    "    i=0\n",
    "    for data in test_loader:\n",
    "        # if i == 1900:\n",
    "        if (i+1)%100 == 0:\n",
    "            data_list.append(data)\n",
    "        # if i == 0:\n",
    "        # if i == 400:\n",
    "        if i == 2000:\n",
    "            break\n",
    "        i+=1\n",
    "\n",
    "    datanum = 0\n",
    "\n",
    "    for data in data_list:\n",
    "        print(\"datanum: \", datanum)\n",
    "        data.to(device)  \n",
    "        optim_param = data.node_feature[\"n0\"].detach().clone()\n",
    "        optim_param.requires_grad=True\n",
    "\n",
    "        testdata = data.clone()\n",
    "        static_data = data.clone()\n",
    "        testdata.node_feature[\"n0\"] = optim_param\n",
    "        static_data.node_feature[\"n0\"] = optim_param[..., :3]\n",
    "\n",
    "        optimizer = torch.optim.Adam([optim_param], lr=0.0001)\n",
    "\n",
    "        list_force = []\n",
    "        list_drag_force = []\n",
    "        final_results = []\n",
    "        for oiter in range(optim_iter):\n",
    "            # print(oiter)\n",
    "            total_x_force = 0\n",
    "            total_y_force = 0\n",
    "\n",
    "            testdata.node_feature[\"n0\"] = optim_param\n",
    "            static_data.node_feature[\"n0\"] = optim_param[..., :3]\n",
    "\n",
    "            if oiter == (optim_iter - 1):\n",
    "                force_list = []\n",
    "\n",
    "            for kk in range(prerollout+one_period):\n",
    "                # print(kk)\n",
    "                if oiter % 50 == 49 and kk == 0 and vis_prerollout:\n",
    "                    print(\"kk = 0\")\n",
    "                    fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "                    ax.imshow(torch.nn.functional.pad(((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min, ((1,3,1,3))).detach().cpu().numpy(), cmap='viridis',\n",
    "                             aspect='auto',\n",
    "                             origin='lower')\n",
    "                    plt.show()\n",
    "\n",
    "                    #testdata, pred = get_data_next_step(model, testdata, use_grads=False, return_data=True, is_y_diff=False, is_rollout=True)\n",
    "                    # pdb.set_trace()\n",
    "                    press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "                    # press = ((((testdata.node_label[\"n0\"][:,-1,-1].reshape(62,62)/2) + 0.5) * (p_max-p_min)) + p_min) #.detach().cpu()\n",
    "                    # raw_bound = (((testdata.param[\"n0\"].reshape(40,2)/2) + 0.5) * 62) + 0\n",
    "\n",
    "                    length, nx, ny, cen = compute_orthonormal(torch.tensor(raw_bound))\n",
    "                    cen = cen.to(device)\n",
    "\n",
    "                if oiter % 50 == 49 and kk == prerollout and vis_prerollout:\n",
    "                    # print(\"kk = \" + str(prerollout))\n",
    "                    fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "                    ax.imshow(torch.nn.functional.pad(press, ((1,3,1,3))).detach().cpu().numpy(), cmap='viridis',\n",
    "                             aspect='auto',\n",
    "                             origin='lower')\n",
    "                    plt.show()\n",
    "                    # print(cen.shape, raw_bound.shape)\n",
    "\n",
    "                if kk >= prerollout:\n",
    "                    # testdata, pred = get_data_next_step(model, testdata, use_grads=False, return_data=True, is_y_diff=False)\n",
    "                    testdata, pred = get_data_next_step_with_static(model, testdata, static_data=static_data, use_grads=False, return_data=True, is_y_diff=False)\n",
    "                    # pdb.set_trace()\n",
    "                    if oiter == optim_iter - 1:\n",
    "                        try:    \n",
    "                            os.makedirs(\"./optimized_traj_lepde_BP/test_{:06d}/sim_{:06d}\".format(testnum, datanum))\n",
    "                        except Exception:\n",
    "                            pass   \n",
    "                        with open('./optimized_traj_lepde_BP/test_{:06d}/sim_{:06d}/feature_{:06d}.npy'.format(testnum, datanum, kk), 'wb') as f:\n",
    "                            np.save(f, testdata.node_feature[\"n0\"].detach().cpu().numpy())\n",
    "\n",
    "                    input_press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,-1:])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "\n",
    "                    input_node_feature = torch.cat([input_press, testdata.node_feature[\"n0\"][:,-2:-1,:3].reshape(62, 62, 1, 3)], -1).reshape(62, 62, 1, -1)\n",
    "                    input_node_feature = torch.permute(input_node_feature, (2, 3, 0, 1))\n",
    "                    data_pad = torch.zeros(1, 4, 64, 64).to(input_node_feature.device)\n",
    "                    data_pad[ :, :, 1:-1, 1:-1] = input_node_feature\n",
    "                    input_node_feature = data_pad\n",
    "\n",
    "                    x_force, y_force = force_model(input_node_feature)[0]\n",
    "                    if oiter == optim_iter - 1:\n",
    "                        force_list.append(torch.stack([x_force, y_force], - 1))\n",
    "\n",
    "                    # press = ((((testdata.node_label[\"n0\"][:,-1,-1].reshape(62,62)/2) + 0.5) * (p_max-p_min)) + p_min) #.detach().cpu()\n",
    "                    # raw_bound = (((testdata.param[\"n0\"].reshape(40,2)/2) + 0.5) * 62) + 0\n",
    "                    # lin_press = linear_transform(torch.nn.functional.pad(press, (1,3,1,3)), cen)\n",
    "                    # x_force, y_force = compute_pressForce(torch.nn.functional.pad(press, (1,3,1,3)), raw_bound)\n",
    "\n",
    "                    total_x_force += x_force\n",
    "                    total_y_force += y_force\n",
    "\n",
    "            # if oiter == optim_iter - 1:\n",
    "            #     with open(\"./optimized_traj_lepde_BP/sim_{:06d}/raw_force.npy\".format(datanum), 'wb') as f:\n",
    "            #         np.save(f, torch.stack(force_list, 0).detach().cpu().numpy())\n",
    "\n",
    "\n",
    "            total_x_force = total_x_force/one_period\n",
    "            total_y_force = total_y_force/one_period\n",
    "\n",
    "            list_force.append(-total_y_force.item())\n",
    "            list_drag_force.append(total_x_force.item())\n",
    "\n",
    "            output = torch.abs(total_x_force) + total_y_force\n",
    "            optimizer.zero_grad()\n",
    "            output.backward()\n",
    "            optimizer.step()\n",
    "            #aft_bd = torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:].reshape(40,2).clone()\n",
    "\n",
    "            ### Visualization of updated boundary \"\"\"\n",
    "            if oiter % 50 == 49:\n",
    "            # if oiter % 10 == 9:\n",
    "                print(\"iteration: \", oiter)\n",
    "\n",
    "\n",
    "        datanum += 1\n",
    "\n",
    "        # pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b748951-9138-463d-b53c-bd3cc8acb365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lepde",
   "language": "python",
   "name": "lepde"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
