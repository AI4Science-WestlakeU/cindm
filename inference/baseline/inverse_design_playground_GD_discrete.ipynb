{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41481747-0049-4511-b512-df8489041673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import OrderedDict\n",
    "import datetime\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pylab as plt\n",
    "from numbers import Number\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "pd.options.display.max_rows = 1500\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.width = 1000\n",
    "pd.set_option('max_colwidth', 400)\n",
    "import pdb\n",
    "import pickle\n",
    "import pprint as pp\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from deepsnap.batch import Batch as deepsnap_Batch\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..', '..'))\n",
    "from le_pde.argparser import arg_parse\n",
    "from le_pde.datasets.load_dataset import load_data\n",
    "from le_pde.models import load_model\n",
    "from le_pde.pytorch_net.util import groupby_add_keys, filter_df, get_unique_keys_df, Attr_Dict, Printer, get_num_params, get_machine_name, pload, pdump, to_np_array, get_pdict, reshape_weight_to_matrix, ddeepcopy as deepcopy, plot_vectors, record_data, filter_filename, Early_Stopping, str2bool, get_filename_short, print_banner, plot_matrices, get_num_params, init_args, filter_kwargs, to_string, COLOR_LIST\n",
    "from le_pde.utils import update_legacy_default_hyperparam, EXP_PATH, deepsnap_to_pyg, LpLoss, to_cpu, to_tuple_shape, parse_multi_step, loss_op, get_device, get_data_next_step\n",
    "from utils import compute_pressForce\n",
    "#from le_pde.utils import deepsnap_to_pyg, LpLoss, to_cpu, to_tuple_shape, parse_multi_step, loss_op, get_device, get_data_next_step\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "p = Printer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34edf99f-9265-45b0-906d-650e4261dc77",
   "metadata": {},
   "source": [
    "## 1. Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67193e7b-5777-4aac-9426-f91e6837d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(data_record):\n",
    "    x_axis = np.arange(len(data_record[\"train_loss\"]))\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(x_axis, data_record[\"train_loss\"], label=\"train\")\n",
    "    plt.plot(x_axis, data_record[\"val_loss\"], label=\"val\")\n",
    "    plt.plot(x_axis, data_record[\"test_loss\"], label=\"test\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.semilogy(x_axis, data_record[\"train_loss\"], label=\"train\")\n",
    "    plt.semilogy(x_axis, data_record[\"val_loss\"], label=\"val\")\n",
    "    plt.semilogy(x_axis, data_record[\"test_loss\"], label=\"test\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4494e7-afaf-4d55-a1fc-b32168ca62b5",
   "metadata": {},
   "source": [
    "## 2. Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a74011e-cb80-444a-ae95-6f29d830193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_PATH = \"./results/\"\n",
    "\n",
    "isplot = True\n",
    "all_hash = [\n",
    "    # \"0LVoHLHQ_ampere4\",\n",
    "    # \"zDOCitP9_ampere4\",\n",
    "    # \"6en0gt6G_turing1\",\n",
    "    # \"zHQu3EKe_turing2\",\n",
    "    # \"2okNCadZ_turing3\",\n",
    "    # \"I6EepBQI_turing3\",\n",
    "    # \"clnAWVnz_hyperturing1\",\n",
    "    # \"YDHgg+il_turing3\",\n",
    "    # \"HD2hmsb+_turing3\",\n",
    "    # \"krep6ZNu_turing2\",\n",
    "    \"HGbjEn3n_hyperturing1\",\n",
    "]\n",
    "hash_str = all_hash[0]\n",
    "dirname = EXP_PATH + \"naca_ellipse_2023-06-02/\"\n",
    "filename = filter_filename(dirname, include=hash_str)\n",
    "if len(filename) == 0:\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    data_record = pload(dirname + filename[0])\n",
    "except Exception as e:\n",
    "    print(f\"error {e}\")\n",
    "    # continue\n",
    "    raise\n",
    "if isplot:\n",
    "    plot_learning_curve(data_record)\n",
    "args = init_args(update_legacy_default_hyperparam(data_record[\"args\"]))\n",
    "args.filename = filename\n",
    "# model = load_model(data_record[\"best_model_dict\"], device=device)\n",
    "model = load_model(data_record[\"model_dict\"][-1], device=device)\n",
    "model.eval()\n",
    "p.print(filename, banner_size=100)\n",
    "\n",
    "# Load test dataset:\n",
    "args_test = deepcopy(args)\n",
    "if args.temporal_bundle_steps == 1:\n",
    "    if args.dataset in [\"fno\", \"fno-2\", \"fno-3\"]:\n",
    "        args_test.multi_step = \"20\"\n",
    "    elif args.dataset in [\"fno-1\"]:\n",
    "        args_test.multi_step = \"40\"\n",
    "    elif args.dataset in [\"fno-4\"]:\n",
    "        args_test.multi_step = \"10\"\n",
    "    elif args.dataset in [\"naca_ellipse_lepde\"]:\n",
    "        args_test.multi_step = \"1\"\n",
    "        args_test.latent_multi_step=\"1\"\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    pass\n",
    "args_test.batch_size = 1\n",
    "args_test.is_test_only=True\n",
    "\n",
    "(dataset_train_val, dataset_test), (train_loader, val_loader, test_loader) = load_data(args_test)\n",
    "test_loader = DataLoader(dataset_test, num_workers=0, collate_fn=deepsnap_Batch.collate(),\n",
    "                         batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749c5974-4afc-41b3-9d23-b174133f43d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "for data in test_loader:\n",
    "    # if i == 1900:\n",
    "    # if i == 2500:\n",
    "    if i == 1200:\n",
    "    # if i == 0:\n",
    "    # if i == 400:\n",
    "        break\n",
    "    i+=1\n",
    "\n",
    "    if i%100 == 0:\n",
    "        fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "        bd = (((data.param[\"n0\"].detach().cpu().numpy()/2) + 0.5) * 62) + 0\n",
    "        mappable0 = ax.plot(bd[0,0::2], bd[0,1::2])\n",
    "        ax.set_xlim(0, 62)\n",
    "        ax.set_ylim(0, 62)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8656e5-40e6-4649-9930-8ec3b0b346e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to(device)        \n",
    "testdata = data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c340f706-2bce-4e32-8abf-1b50f8d40ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.node_feature[\"n0\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c2ec3-faee-4f4d-b028-7026e83cf37a",
   "metadata": {},
   "source": [
    "## 3. inverse optimization with LEPDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e411271b-1663-4cc7-b585-8c7bb48a77f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = data.clone()\n",
    "orgdata = data.clone()\n",
    "#print(testdata.param[\"n0\"])\n",
    "const_variable = testdata.param[\"n0\"][:,0::2].detach().clone()\n",
    "#const_variable.requires_grad=True\n",
    "opt_variable = testdata.param[\"n0\"][:,1::2].detach().clone()\n",
    "opt_variable.requires_grad=True\n",
    "#print(const_variable, opt_variable)\n",
    "testdata.param[\"n0\"] = torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:]\n",
    "#print(testdata.param[\"n0\"])\n",
    "# optimizer = torch.optim.Adam([opt_variable, const_variable], lr=0.01)\n",
    "# best\n",
    "# optimizer = torch.optim.Adam([opt_variable], lr=0.000005)\n",
    "optimizer = torch.optim.Adam([opt_variable], lr=0.0001)\n",
    "\n",
    "prerollout = 16\n",
    "one_period = 4\n",
    "vis_prerollout = False\n",
    "\n",
    "# testdata = data.clone()\n",
    "# original_optvar = testdata.param[\"n0\"][:,1::2].detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87d51c-abb1-497c-bac3-14a94942a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_filename = os.path.join(\"./dataset/naca_ellipse/training_trajectories/\", \"normalization_max_min.p\")\n",
    "normdict = pickle.load(open(normalization_filename, \"rb\"))\n",
    "x_max = normdict[\"x_max\"]\n",
    "x_min = normdict[\"x_min\"]\n",
    "y_max = normdict[\"y_max\"]\n",
    "y_min = normdict[\"y_min\"]\n",
    "p_max = normdict[\"p_max\"]\n",
    "p_min = normdict[\"p_min\"]\n",
    "p_max = p_max.to(device)\n",
    "p_min = p_min.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f27b2a-ff48-4327-80a2-e42c1cbddd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_max, p_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c108e7-4870-45a2-9657-6213c9ebb9f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from utils import compute_pressForce, compute_orthonormal, linear_transform, update_data\n",
    "        \n",
    "optim_iter = 2000\n",
    "is_objvis = True\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "bd = testdata.param[\"n0\"].reshape(40,2).detach().cpu().numpy()\n",
    "bd = (((bd/2) + 0.5) * 62) + 0\n",
    "#print(a.shape)\n",
    "mappable0 = ax.plot(bd[:,0], bd[:,1])\n",
    "ax.set_xlim(0, 62)\n",
    "ax.set_ylim(0, 62)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "ax.imshow(testdata.node_feature[\"n0\"][:,-1,-1].reshape(62,62).detach().cpu().numpy(),\n",
    "          cmap='viridis',\n",
    "          aspect='auto')\n",
    "plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "# ax.imshow(testdata.node_label[\"n0\"][:,-1,-1].reshape(62,62).detach().cpu().numpy(),\n",
    "#           cmap='viridis',\n",
    "#           aspect='auto')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8), ncols=1)\n",
    "length, nx, ny, cen = compute_orthonormal(torch.tensor(bd))\n",
    "rec_press = ((((testdata.node_label[\"n0\"][:,-1,-1].reshape(62,62)/2) + 0.5) * (p_max-p_min)) + p_min).detach().cpu()\n",
    "lin_press = linear_transform(torch.nn.functional.pad(rec_press, (1,3,1,3)), cen) #*-1\n",
    "print(lin_press)\n",
    "mappable0 = ax.plot(bd[:,0], bd[:,1])\n",
    "normals = torch.stack((lin_press*nx,lin_press*ny), -1)\n",
    "for i in range(40):\n",
    "    rel_normals = cen[i,:] + normals[i,:]\n",
    "    ax.plot((cen[i,0], rel_normals[0]), (cen[i,1], rel_normals[1]))\n",
    "ax.set_xlim(24, 35)\n",
    "ax.set_ylim(32, 43)\n",
    "# ax.set_xlim(18, 28)\n",
    "# ax.set_ylim(37, 47)\n",
    "plt.show()\n",
    "\n",
    "pdf = PdfPages('./optimized_naca_lepde_unflip.pdf')\n",
    "list_force = []\n",
    "list_drag_force = []\n",
    "for oiter in range(optim_iter):\n",
    "    total_x_force = 0\n",
    "    total_y_force = 0\n",
    "\n",
    "    bound = torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:].reshape(40,2)\n",
    "\n",
    "    rec_bound = (((bound/2) + 0.5) * 62) + 0\n",
    "    up_solid_mask, up_solid_offset = update_static_masks(rec_bound)\n",
    "    tor_batch_mask = torch.where(up_solid_mask==1, False, True).clone().flatten()\n",
    "    up_solid_mask = up_solid_mask[...,None]\n",
    "    static_feat = torch.cat((up_solid_mask, up_solid_offset), -1)\n",
    "    mul_static_feat = torch.stack([static_feat for _ in range(4)], -2).reshape(-1,4,3)\n",
    "    \n",
    "    \n",
    "    a = deepsnap_Batch\n",
    "    batch, _ = a._init_batch_fields(testdata.keys, [])\n",
    "    batch.batch = testdata.batch.clone()\n",
    "    batch.compute_func = testdata.compute_func\n",
    "    batch.directed = testdata.directed.detach().clone()\n",
    "    batch.dyn_dims = testdata.dyn_dims\n",
    "    batch.edge_attr = testdata.edge_attr\n",
    "    batch.edge_index = {('n0','0','n0'): testdata.edge_index[('n0','0','n0')].detach().clone()}\n",
    "    batch.edge_label_index = {('n0','0','n0'): testdata.edge_label_index[('n0','0','n0')].detach().clone()}\n",
    "    batch.grid_keys = testdata.grid_keys\n",
    "    batch.mask = {\"n0\": tor_batch_mask.detach()}\n",
    "    batch.node_feature = {\"n0\": torch.cat((mul_static_feat, orgdata.node_feature[\"n0\"][...,3:].detach()), -1)}\n",
    "    batch.node_label = {\"n0\": testdata.node_label[\"n0\"].detach().clone()}\n",
    "    batch.node_label_index = {\"n0\": testdata.node_label_index[\"n0\"].detach().clone()}\n",
    "    batch.node_pos = {\"n0\": testdata.node_pos[\"n0\"].detach().clone()}\n",
    "    batch.original_shape = testdata.original_shape\n",
    "    batch.param = {\"n0\": torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:]}\n",
    "    batch.params = testdata.params\n",
    "    batch.part_keys = testdata.part_keys\n",
    "    batch.task = testdata.task\n",
    "    \n",
    "    testdata = batch\n",
    "    \n",
    "#     for _ in range(6):\n",
    "#         testdata, pred = get_data_next_step(model, testdata, use_grads=False, return_data=True, is_y_diff=False)\n",
    "#         press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "#         # press = ((((testdata.node_label[\"n0\"][:,-1,-1].reshape(62,62)/2) + 0.5) * (p_max-p_min)) + p_min) #.detach().cpu()\n",
    "#         raw_bound = (((testdata.param[\"n0\"].reshape(40,2)/2) + 0.5) * 62) + 0\n",
    "        \n",
    "#         length, nx, ny, cen = compute_orthonormal(torch.tensor(raw_bound))\n",
    "#         cen = cen.to(device)\n",
    "#         lin_press = linear_transform(torch.nn.functional.pad(press, (1,3,1,3)), cen)\n",
    "#         x_force, y_force = compute_pressForce(torch.nn.functional.pad(press, (1,3,1,3)), raw_bound)\n",
    "#         total_x_force += x_force\n",
    "#         total_y_force += y_force\n",
    "    for kk in range(prerollout+one_period):\n",
    "        if oiter % 50 == 49 and kk == 0 and vis_prerollout:\n",
    "            print(\"kk = 0\")\n",
    "            fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "            ax.imshow(torch.nn.functional.pad(((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min, ((1,3,1,3))).detach().cpu().numpy(), cmap='viridis',\n",
    "                     aspect='auto',\n",
    "                     origin='lower')\n",
    "            plt.show()\n",
    "            # print(cen.shape, raw_bound.shape)\n",
    "\n",
    "        testdata, pred = get_data_next_step(model, testdata, use_grads=False, return_data=True, is_y_diff=False)\n",
    "        # pdb.set_trace()\n",
    "        press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "        # press = ((((testdata.node_label[\"n0\"][:,-1,-1].reshape(62,62)/2) + 0.5) * (p_max-p_min)) + p_min) #.detach().cpu()\n",
    "        raw_bound = (((testdata.param[\"n0\"].reshape(40,2)/2) + 0.5) * 62) + 0\n",
    "        \n",
    "        length, nx, ny, cen = compute_orthonormal(torch.tensor(raw_bound))\n",
    "        cen = cen.to(device)\n",
    "        \n",
    "        if oiter % 50 == 49 and kk == prerollout and vis_prerollout:\n",
    "            print(\"kk = \" + str(prerollout))\n",
    "            fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "            ax.imshow(torch.nn.functional.pad(press, ((1,3,1,3))).detach().cpu().numpy(), cmap='viridis',\n",
    "                     aspect='auto',\n",
    "                     origin='lower')\n",
    "            plt.show()\n",
    "            # print(cen.shape, raw_bound.shape)\n",
    "        \n",
    "        if kk >= prerollout:\n",
    "            testdata, pred = get_data_next_step(model, testdata, use_grads=False, return_data=True, is_y_diff=False)\n",
    "            # pdb.set_trace()\n",
    "            press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "            # press = ((((testdata.node_label[\"n0\"][:,-1,-1].reshape(62,62)/2) + 0.5) * (p_max-p_min)) + p_min) #.detach().cpu()\n",
    "            raw_bound = (((testdata.param[\"n0\"].reshape(40,2)/2) + 0.5) * 62) + 0\n",
    "            lin_press = linear_transform(torch.nn.functional.pad(press, (1,3,1,3)), cen)\n",
    "            x_force, y_force = compute_pressForce(torch.nn.functional.pad(press, (1,3,1,3)), raw_bound)\n",
    "            \n",
    "            total_x_force += x_force\n",
    "            total_y_force += y_force\n",
    "        \n",
    "    total_x_force = total_x_force/one_period\n",
    "    total_y_force = total_y_force/one_period\n",
    "        \n",
    "    list_force.append(total_y_force.item())\n",
    "    list_drag_force.append(total_x_force.item())\n",
    "\n",
    "    output = -1/total_x_force + 10 * torch.square(-30 - total_y_force)\n",
    "    # output = -1/total_x_force # + 10 * torch.square(-30 - total_y_force)\n",
    "    optimizer.zero_grad()\n",
    "    output.backward()\n",
    "    torch.nn.utils.clip_grad_value_(opt_variable, 0.01)\n",
    "    # print(\"Gradient: \", opt_variable.grad)\n",
    "    optimizer.step()\n",
    "    aft_bd = torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:].reshape(40,2).clone()\n",
    "\n",
    "    ### Visualization of updated boundary \"\"\"\n",
    "    if oiter % 50 == 49:\n",
    "    # if oiter % 10 == 9:\n",
    "        print(\"iteration: \", oiter)\n",
    "        bound = torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:].reshape(40,2)\n",
    "        bd = (((bound.detach().cpu().numpy()/2) + 0.5) * 62) + 0        \n",
    "        length, nx, ny, cen = compute_orthonormal(torch.tensor(bd))\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(18,3), ncols=6)\n",
    "        mappable0 = ax[0].plot(bd[:,0], bd[:,1])\n",
    "        nx = nx.detach().cpu()\n",
    "        ny = ny.detach().cpu()\n",
    "        cen = cen.detach().cpu()\n",
    "        lin_press = lin_press.cpu()\n",
    "        normals = torch.stack((lin_press*nx,lin_press*ny), -1)#.to(device)\n",
    "        for i in range(40):\n",
    "            rel_normals = cen[i,:] + normals[i,:]\n",
    "            ax[0].plot((cen[i,0].numpy(), rel_normals[0].detach().numpy()), (cen[i,1].numpy(), rel_normals[1].detach().numpy()))\n",
    "        ax[0].set_xlim(24, 35)\n",
    "        ax[0].set_ylim(32, 43)\n",
    "        mappable1 = ax[1].imshow(testdata.node_feature[\"n0\"][:,-1,0].reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "                                 aspect='auto',\n",
    "                                 origin='lower')\n",
    "        vis_offsetmask = torch.where(testdata.node_feature[\"n0\"][:,-1,1]!=0, 1, 0)\n",
    "        mappable2 = ax[2].imshow(vis_offsetmask.reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "                                 aspect='auto',\n",
    "                                 origin='lower')        \n",
    "        mappable3 = ax[3].imshow(testdata.node_feature[\"n0\"][:,-1,0].reshape(62,62).detach().cpu().numpy()-vis_offsetmask.reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "                                 aspect='auto',\n",
    "                                 origin='lower')        \n",
    "        mappable4 = ax[4].plot(np.array(list_force)[0::5])\n",
    "        mappable5 = ax[5].plot(np.array(list_drag_force)[0::5])\n",
    "         # pdf.savefig()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"diff_bef_aft \", (aft_bd - bound).sum())\n",
    "    \n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcef5c0-42a4-400a-a1b5-42bd157589a7",
   "metadata": {},
   "source": [
    "## 4. inverse optimization with FNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf5d697-782d-43ed-9d1b-0330c7e07ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "isplot = True\n",
    "all_hash = [\n",
    "    #\"Yirzlp+j_ampere4\",\n",
    "    # \"krep6ZNu_turing2\",\n",
    "    # \"8mOGk0n1_turing2\",\n",
    "    # \"97F95ucb_hyperturing1\",\n",
    "    # \"1c66CZ45_hyperturing1\",\n",
    "    # \"HGbjEn3n_hyperturing1\"\n",
    "    # \"0iA6p0Ql_hyperturing2\",\n",
    "    \"TLOUV2ee_turing2\",\n",
    "]\n",
    "hash_str = all_hash[0]\n",
    "dirname = EXP_PATH + \"naca_ellipse_2023-06-02/\"\n",
    "filename = filter_filename(dirname, include=hash_str)\n",
    "if len(filename) == 0:\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    data_record = pload(dirname + filename[0])\n",
    "except Exception as e:\n",
    "    print(f\"error {e}\")\n",
    "    # continue\n",
    "    raise\n",
    "if isplot:\n",
    "    plot_learning_curve(data_record)\n",
    "args = init_args(update_legacy_default_hyperparam(data_record[\"args\"]))\n",
    "args.filename = filename\n",
    "# model = load_model(data_record[\"best_model_dict\"], device=device)\n",
    "model_fno = load_model(data_record[\"model_dict\"][-1], device=device)\n",
    "model_fno.eval()\n",
    "p.print(filename, banner_size=100)\n",
    "\n",
    "# Load test dataset:\n",
    "args_test = deepcopy(args)\n",
    "if args.temporal_bundle_steps == 1:\n",
    "    if args.dataset in [\"fno\", \"fno-2\", \"fno-3\"]:\n",
    "        args_test.multi_step = \"20\"\n",
    "    elif args.dataset in [\"fno-1\"]:\n",
    "        args_test.multi_step = \"40\"\n",
    "    elif args.dataset in [\"fno-4\"]:\n",
    "        args_test.multi_step = \"10\"\n",
    "    elif args.dataset in [\"naca_ellipse_lepde\"]:\n",
    "        args_test.multi_step = \"1\"\n",
    "        args_test.latent_multi_step=\"1\"\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    pass\n",
    "args_test.batch_size = 1\n",
    "args_test.is_test_only=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ac95c9-0416-43f9-931d-56b5f58bdc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e0452-a0a6-4c77-a42e-9d5f92af0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_2d_boundary_mask import ForceUnet\n",
    "force_model = ForceUnet(\n",
    "    dim = 64,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    channels=4\n",
    ")\n",
    "force_model.load_state_dict(torch.load(\"./dataset/epoch_29.pth\"))\n",
    "force_model.to(device)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eac3296-fa50-4dde-b67e-2a1128e1020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_press = (((testdata.node_feature[\"n0\"][..., -1:]/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "# input_node_feature = torch.cat([input_press, testdata.node_feature[\"n0\"][..., :3]], -1).reshape(62, 62, 4, -1)\n",
    "# input_node_feature = torch.permute(input_node_feature, (2, 3, 0, 1))\n",
    "# # torch.swapaxis()\n",
    "# # input_node_feature.shape\n",
    "# data_pad = torch.zeros(4, 4, 64, 64).to(input_node_feature.device)\n",
    "# data_pad[ :, :, 1:-1, 1:-1] = input_node_feature\n",
    "# input_node_feature = data_pad\n",
    "# force_model(input_node_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ff07e-8289-45b5-8379-c15f68d75db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone data\n",
    "testdata = data.clone()\n",
    "orgdata = data.clone()\n",
    "\n",
    "opt_mask = testdata.node_feature[\"n0\"][:,-2:-1,0:1].detach().clone()\n",
    "opt_offset = testdata.node_feature[\"n0\"][:,-2:-1,1:3].detach().clone()\n",
    "opt_mask.requires_grad=True\n",
    "opt_offset.requires_grad=True\n",
    "\n",
    "cat_opt_mask = torch.concat([opt_mask, opt_offset], -1)\n",
    "static_grid = torch.concat([cat_opt_mask for _ in range(4)], -2)\n",
    "dynamic_features = testdata.node_feature[\"n0\"][:,:,3:].detach().clone()\n",
    "dynamic_features.requires_grad=False\n",
    "\n",
    "testdata.node_feature[\"n0\"] = torch.concat([static_grid, dynamic_features], -1)\n",
    "\n",
    "optimizer = torch.optim.Adam([opt_mask, opt_offset], lr=0.000001)\n",
    "\n",
    "prerollout = 12\n",
    "one_period = 4\n",
    "vis_prerollout = False\n",
    "\n",
    "optim_iter = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e012d-ad9b-46e1-9be5-3207af8a002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for normalization\n",
    "normalization_filename = os.path.join(\"./dataset/naca_ellipse/training_trajectories/\", \"normalization_max_min.p\")\n",
    "normdict = pickle.load(open(normalization_filename, \"rb\"))\n",
    "x_max = normdict[\"x_max\"]\n",
    "x_min = normdict[\"x_min\"]\n",
    "y_max = normdict[\"y_max\"]\n",
    "y_min = normdict[\"y_min\"]\n",
    "p_max = normdict[\"p_max\"]\n",
    "p_min = normdict[\"p_min\"]\n",
    "p_max = p_max.to(device)\n",
    "p_min = p_min.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab873149-29f2-4270-93ad-05acda20a5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f08e91a-a1e7-4b9a-be47-70f7fd9c2b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from utils import compute_pressForce, compute_orthonormal, linear_transform, update_data\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "bd = testdata.param[\"n0\"].reshape(40,2).detach().cpu().numpy()\n",
    "bd = (((bd/2) + 0.5) * 62) + 0\n",
    "#print(a.shape)\n",
    "mappable0 = ax.plot(bd[:,0], bd[:,1])\n",
    "ax.set_xlim(0, 62)\n",
    "ax.set_ylim(0, 62)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "ax.imshow(testdata.node_feature[\"n0\"][:,-1,-1].reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "         aspect='auto',\n",
    "         origin='lower')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8), ncols=1)\n",
    "length, nx, ny, cen = compute_orthonormal(torch.tensor(bd))\n",
    "rec_press = ((((testdata.node_label[\"n0\"][:,-1,-1].reshape(62,62)/2) + 0.5) * (p_max-p_min)) + p_min).detach().cpu()\n",
    "lin_press = linear_transform(torch.nn.functional.pad(rec_press, (1,3,1,3)), cen) #* (-1)\n",
    "print(lin_press)\n",
    "mappable0 = ax.plot(bd[:,0], bd[:,1])\n",
    "normals = torch.stack((lin_press*nx,lin_press*ny), -1)\n",
    "for i in range(40):\n",
    "    rel_normals = cen[i,:] + normals[i,:]\n",
    "    ax.plot((cen[i,0], rel_normals[0]), (cen[i,1], rel_normals[1]))\n",
    "ax.set_xlim(24, 35)\n",
    "ax.set_ylim(32, 43)\n",
    "# ax.set_xlim(18, 28)\n",
    "# ax.set_ylim(37, 47)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "mappable = ax.imshow(testdata.node_feature[\"n0\"][:,-1,0].reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "         aspect='auto',\n",
    "         origin='lower')\n",
    "fig.colorbar(mappable, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9912b7d-a3df-4680-aff9-d94ef29f0778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf = PdfPages('./optimized_naca_fno_gradient.pdf')\n",
    "\n",
    "list_force = []\n",
    "list_drag_force = []\n",
    "for oiter in range(optim_iter):\n",
    "    total_x_force = 0\n",
    "    total_y_force = 0\n",
    "\n",
    "    ### Define boundary ###\n",
    "    # bound = torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:].reshape(40,2)\n",
    "    \n",
    "    ### update boundary ###\n",
    "    # rec_bound = (((bound/2) + 0.5) * 62) + 0  \n",
    "    # testdata = update_data(rec_bound, testdata, orgdata, const_variable, opt_variable)\n",
    "    \n",
    "    raw_bound = (((testdata.param[\"n0\"].reshape(40,2)/2) + 0.5) * 62) + 0\n",
    "    raw_bound.requires_grad = False\n",
    "    \n",
    "    ### Perform rollout and Compute objective ###\n",
    "    for kk in range(prerollout+one_period):\n",
    "        if oiter % 50 == 49 and kk == 0 and vis_prerollout:\n",
    "            print(\"kk = 0\")\n",
    "            fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "            ax.imshow(torch.nn.functional.pad(((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min, ((1,3,1,3))).detach().cpu().numpy(), cmap='viridis',\n",
    "                     aspect='auto',\n",
    "                     origin='lower')\n",
    "            plt.show()\n",
    "\n",
    "        testdata, pred = get_data_next_step(model_fno, testdata, use_grads=False, return_data=True, is_y_diff=False)\n",
    "        press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "        \n",
    "        if oiter % 50 == 49 and kk == prerollout and vis_prerollout:\n",
    "            print(\"kk = \" + str(prerollout))\n",
    "            fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "            ax.imshow(torch.nn.functional.pad(press, ((1,3,1,3))).detach().cpu().numpy(), cmap='viridis',\n",
    "                     aspect='auto',\n",
    "                     origin='lower')\n",
    "            plt.show()\n",
    "        \n",
    "        if kk >= prerollout:\n",
    "            testdata, pred = get_data_next_step(model_fno, testdata, use_grads=False, return_data=True, is_y_diff=False)\n",
    "            # press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "            input_press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,-1:])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "            # pdb.set_trace()\n",
    "            \n",
    "            input_node_feature = torch.cat([input_press, cat_opt_mask.reshape(62, 62, 1, 3)], -1).reshape(62, 62, 1, -1)\n",
    "            input_node_feature = torch.permute(input_node_feature, (2, 3, 0, 1))\n",
    "            data_pad = torch.zeros(1, 4, 64, 64).to(input_node_feature.device)\n",
    "            data_pad[ :, :, 1:-1, 1:-1] = input_node_feature\n",
    "            input_node_feature = data_pad\n",
    "            \n",
    "            x_force, y_force = force_model(input_node_feature)[0]\n",
    "            # x_force, y_force = compute_pressForce(torch.nn.functional.pad(press, (1,3,1,3)), raw_bound)\n",
    "            \n",
    "            total_x_force += x_force\n",
    "            total_y_force += y_force\n",
    "\n",
    "    total_x_force = total_x_force/one_period\n",
    "    total_y_force = total_y_force/one_period\n",
    "\n",
    "    list_force.append(total_y_force.item())\n",
    "    list_drag_force.append(total_x_force.item())\n",
    "\n",
    "    # pdb.set_trace()\n",
    "    # updated_len = torch.norm((raw_bound - torch.roll(raw_bound, 1, 0)), p=2, dim=1).clone()\n",
    "    # edge_length_penalty = torch.max(torch.stack([threshold, torch.abs(updated_len - const_len)], -1), 1)[0].sum()\n",
    "    # updated_boundary_area = torch.sum((raw_bound*torch.fliplr(torch.roll(raw_bound, 1, 0)))[:,0] - (raw_bound*torch.fliplr(torch.roll(raw_bound, 1, 0)))[:,1])\n",
    "    \n",
    "    ### Perform optimization ###\n",
    "    # output = total_x_force + 5 * torch.square(-7 - total_y_force) + 0.1*((const_area - updated_boundary_area)**2) + 10*edge_length_penalty\n",
    "    # output = total_x_force + edge_length_penalty\n",
    "    output = total_x_force - total_y_force\n",
    "    optimizer.zero_grad()\n",
    "    output.backward()\n",
    "    # torch.nn.utils.clip_grad_value_(opt_variable, 0.01)\n",
    "    optimizer.step()\n",
    "\n",
    "    # rolled_boundary = torch.roll(bound, -1, 0)\n",
    "    # bd_diff = torch.abs(bound - rolled_boundary)\n",
    "    # if (bd_diff > 2).sum() > 0:\n",
    "    #     import pdb\n",
    "    #     pdb.set_trace()\n",
    "\n",
    "        \n",
    "    ### Visualization ###\n",
    "    if oiter % 50 == 49:\n",
    "        print(\"iteration: \", oiter + 1)\n",
    "        print(\"objective: \", output)\n",
    "        # print(\"threshold: \", updated_len - const_len)\n",
    "        # print(\"boundary area: \", updated_boundary_area)\n",
    "\n",
    "        bd = (((raw_bound.detach().cpu().numpy()/2) + 0.5) * 62) + 0\n",
    "        length, nx, ny, cen = compute_orthonormal(torch.tensor(bd))\n",
    "        cen = cen.to(device)\n",
    "        lin_press = linear_transform(torch.nn.functional.pad(press, (1,3,1,3)), cen)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(18,3), ncols=6)\n",
    "        mappable0 = ax[0].plot(bd[:,0], bd[:,1])\n",
    "        nx = nx.detach().cpu()\n",
    "        ny = ny.detach().cpu()\n",
    "        cen = cen.detach().cpu()\n",
    "        lin_press = lin_press.cpu()\n",
    "        # print(cen.device, normals.device, lin_press.device)\n",
    "        normals = torch.stack((lin_press*nx,lin_press*ny), -1)\n",
    "        for i in range(40):\n",
    "            rel_normals = cen[i,:] + normals[i,:]\n",
    "            ax[0].plot((cen[i,0].numpy(), rel_normals[0].detach().numpy()), (cen[i,1].numpy(), rel_normals[1].detach().numpy()))\n",
    "        ax[0].set_xlim(24, 35)\n",
    "        ax[0].set_ylim(32, 43)\n",
    "        mappable1 = ax[1].imshow(testdata.node_feature[\"n0\"][:,-1,0].reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "                                 aspect='auto',\n",
    "                                 origin='lower')\n",
    "        fig.colorbar(mappable1, ax=ax[1])\n",
    "        vis_offsetmask = torch.where(testdata.node_feature[\"n0\"][:,-1,1]!=0, 1, 0)\n",
    "        mappable2 = ax[2].imshow(testdata.node_feature[\"n0\"][:,-1,1].reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "                                 aspect='auto',\n",
    "                                 origin='lower')        \n",
    "        fig.colorbar(mappable2, ax=ax[2])\n",
    "        mappable3 = ax[3].imshow(testdata.node_feature[\"n0\"][:,-1,2].reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "                                 aspect='auto',\n",
    "                                 origin='lower')        \n",
    "        fig.colorbar(mappable3, ax=ax[3])\n",
    "        mappable4 = ax[4].plot(np.array(list_force)[0::5])\n",
    "        mappable5 = ax[5].plot(np.array(list_drag_force)[0::5])\n",
    "        pdf.savefig()\n",
    "        plt.show()\n",
    "        # print(opt_mask)\n",
    "        # print(\"\")\n",
    "        # print(opt_offset)\n",
    "        \n",
    "    up_opt_mask = torch.clamp(opt_mask, min=0, max=1)\n",
    "    up_opt_offset = torch.clamp(opt_offset, min=-0.5, max=0.5)\n",
    "    cat_opt_mask = torch.concat([up_opt_mask, up_opt_offset], -1)\n",
    "    static_grid = torch.concat([cat_opt_mask for _ in range(4)], -2)\n",
    "    testdata.node_feature[\"n0\"] = torch.concat([static_grid, dynamic_features], -1)\n",
    "\n",
    "    \n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56efbb6-577a-4de0-b688-69c160114e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import compute_binary_pressForce, find_cluster_boundary, reconstruct_boundary\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,4), ncols=3)\n",
    "bd = (((data.param[\"n0\"].detach().cpu().numpy()/2) + 0.5) * 62) + 0\n",
    "mappable0 = ax[0].plot(bd[0,0::2], bd[0,1::2])\n",
    "ax[0].set_xlim(0, 62)\n",
    "ax[0].set_ylim(0, 62)\n",
    "ax[0].set_title('original boundary')\n",
    "\n",
    "data.to(device)        \n",
    "testdata = data.clone()\n",
    "\n",
    "# Reshape boundary mask and offset\n",
    "binary_mask = opt_mask[:, 0, :].reshape(62,62)     # [62, 62]\n",
    "binary_mask = torch.where(binary_mask <= 0.5, 0, 1)\n",
    "bd_offset = opt_offset[:, 0 ,:].reshape(62,62,2)   # [62, 62, 2]\n",
    "\n",
    "print(binary_mask.shape, bd_offset.shape)\n",
    "\n",
    "# Reconstruct boundary points\n",
    "restored_boundary = reconstruct_boundary(binary_mask.detach().cpu(), bd_offset.detach().cpu())\n",
    "\n",
    "# Visualization of original points \n",
    "mappable1 = ax[1].plot(restored_boundary[:,0], restored_boundary[:,1])\n",
    "ax[1].set_xlim(0, 62)\n",
    "ax[1].set_ylim(0, 62)\n",
    "ax[1].set_title(\"reconstructed boundary\")\n",
    "\n",
    "ax[2].plot(bd[0,0::2], bd[0,1::2])\n",
    "ax[2].plot(restored_boundary[:,0], restored_boundary[:,1])\n",
    "ax[2].set_xlim(0, 62)\n",
    "ax[2].set_ylim(0, 62)\n",
    "ax[2].set_title(\"overlapped boundary\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4dd24-8133-4bcd-a0e9-a033b2b25f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_offset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b748951-9138-463d-b53c-bd3cc8acb365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lepde",
   "language": "python",
   "name": "lepde"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
