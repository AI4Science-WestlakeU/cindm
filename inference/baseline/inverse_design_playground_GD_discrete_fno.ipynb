{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41481747-0049-4511-b512-df8489041673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import OrderedDict\n",
    "import datetime\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pylab as plt\n",
    "from numbers import Number\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "pd.options.display.max_rows = 1500\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.width = 1000\n",
    "pd.set_option('max_colwidth', 400)\n",
    "import pdb\n",
    "import pickle\n",
    "import pprint as pp\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from deepsnap.batch import Batch as deepsnap_Batch\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..', '..'))\n",
    "from le_pde.argparser import arg_parse\n",
    "from le_pde.datasets.load_dataset import load_data\n",
    "from le_pde.models import load_model\n",
    "from le_pde.pytorch_net.util import groupby_add_keys, filter_df, get_unique_keys_df, Attr_Dict, Printer, get_num_params, get_machine_name, pload, pdump, to_np_array, get_pdict, reshape_weight_to_matrix, ddeepcopy as deepcopy, plot_vectors, record_data, filter_filename, Early_Stopping, str2bool, get_filename_short, print_banner, plot_matrices, get_num_params, init_args, filter_kwargs, to_string, COLOR_LIST\n",
    "from le_pde.utils import update_legacy_default_hyperparam, EXP_PATH, deepsnap_to_pyg, LpLoss, to_cpu, to_tuple_shape, parse_multi_step, loss_op, get_device, get_data_next_step\n",
    "from utils import compute_pressForce\n",
    "#from le_pde.utils import deepsnap_to_pyg, LpLoss, to_cpu, to_tuple_shape, parse_multi_step, loss_op, get_device, get_data_next_step\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "p = Printer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34edf99f-9265-45b0-906d-650e4261dc77",
   "metadata": {},
   "source": [
    "## 1. Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67193e7b-5777-4aac-9426-f91e6837d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(data_record):\n",
    "    x_axis = np.arange(len(data_record[\"train_loss\"]))\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(x_axis, data_record[\"train_loss\"], label=\"train\")\n",
    "    plt.plot(x_axis, data_record[\"val_loss\"], label=\"val\")\n",
    "    plt.plot(x_axis, data_record[\"test_loss\"], label=\"test\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.semilogy(x_axis, data_record[\"train_loss\"], label=\"train\")\n",
    "    plt.semilogy(x_axis, data_record[\"val_loss\"], label=\"val\")\n",
    "    plt.semilogy(x_axis, data_record[\"test_loss\"], label=\"test\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4494e7-afaf-4d55-a1fc-b32168ca62b5",
   "metadata": {},
   "source": [
    "## 2. Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a74011e-cb80-444a-ae95-6f29d830193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_PATH = \"./results/\"\n",
    "\n",
    "isplot = True\n",
    "all_hash = [\n",
    "    # \"0LVoHLHQ_ampere4\",\n",
    "    # \"zDOCitP9_ampere4\",\n",
    "    # \"6en0gt6G_turing1\",\n",
    "    # \"zHQu3EKe_turing2\",\n",
    "    # \"2okNCadZ_turing3\",\n",
    "    # \"I6EepBQI_turing3\",\n",
    "    # \"clnAWVnz_hyperturing1\",\n",
    "    # \"YDHgg+il_turing3\",\n",
    "    # \"HD2hmsb+_turing3\",\n",
    "    # \"krep6ZNu_turing2\",\n",
    "    \"QvUQ8aaL_turing2\",\n",
    "]\n",
    "hash_str = all_hash[0]\n",
    "dirname = EXP_PATH + \"naca_ellipse_2023-04-30/\"\n",
    "filename = filter_filename(dirname, include=hash_str)\n",
    "if len(filename) == 0:\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    data_record = pload(dirname + filename[0])\n",
    "except Exception as e:\n",
    "    print(f\"error {e}\")\n",
    "    # continue\n",
    "    raise\n",
    "if isplot:\n",
    "    plot_learning_curve(data_record)\n",
    "args = init_args(update_legacy_default_hyperparam(data_record[\"args\"]))\n",
    "args.filename = filename\n",
    "# model = load_model(data_record[\"best_model_dict\"], device=device)\n",
    "model = load_model(data_record[\"model_dict\"][-1], device=device)\n",
    "model.eval()\n",
    "p.print(filename, banner_size=100)\n",
    "\n",
    "# Load test dataset:\n",
    "args_test = deepcopy(args)\n",
    "if args.temporal_bundle_steps == 1:\n",
    "    if args.dataset in [\"fno\", \"fno-2\", \"fno-3\"]:\n",
    "        args_test.multi_step = \"20\"\n",
    "    elif args.dataset in [\"fno-1\"]:\n",
    "        args_test.multi_step = \"40\"\n",
    "    elif args.dataset in [\"fno-4\"]:\n",
    "        args_test.multi_step = \"10\"\n",
    "    elif args.dataset in [\"naca_ellipse_lepde\"]:\n",
    "        args_test.multi_step = \"1\"\n",
    "        args_test.latent_multi_step=\"1\"\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    pass\n",
    "args_test.batch_size = 1\n",
    "args_test.is_test_only=True\n",
    "\n",
    "(dataset_train_val, dataset_test), (train_loader, val_loader, test_loader) = load_data(args_test)\n",
    "test_loader = DataLoader(dataset_test, num_workers=0, collate_fn=deepsnap_Batch.collate(),\n",
    "                         batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcef5c0-42a4-400a-a1b5-42bd157589a7",
   "metadata": {},
   "source": [
    "## 4. inverse optimization with FNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf5d697-782d-43ed-9d1b-0330c7e07ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "isplot = True\n",
    "all_hash = [\n",
    "    #\"Yirzlp+j_ampere4\",\n",
    "    # \"krep6ZNu_turing2\",\n",
    "    # \"8mOGk0n1_turing2\",\n",
    "    # \"97F95ucb_hyperturing1\",\n",
    "    # \"1c66CZ45_hyperturing1\",\n",
    "    # \"HGbjEn3n_hyperturing1\"\n",
    "    # \"0iA6p0Ql_hyperturing2\",\n",
    "    # \"TLOUV2ee_turing2\", <--- newest\n",
    "    \"1trQblwd_whdeng\",\n",
    "]\n",
    "hash_str = all_hash[0]\n",
    "dirname = EXP_PATH + \"naca_ellipse_2023-09-27/\"\n",
    "filename = filter_filename(dirname, include=hash_str)\n",
    "if len(filename) == 0:\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    data_record = pload(dirname + filename[0])\n",
    "except Exception as e:\n",
    "    print(f\"error {e}\")\n",
    "    # continue\n",
    "    raise\n",
    "if isplot:\n",
    "    plot_learning_curve(data_record)\n",
    "args = init_args(update_legacy_default_hyperparam(data_record[\"args\"]))\n",
    "args.filename = filename\n",
    "# model = load_model(data_record[\"best_model_dict\"], device=device)\n",
    "model_fno = load_model(data_record[\"model_dict\"][-1], device=device)\n",
    "model_fno.eval()\n",
    "p.print(filename, banner_size=100)\n",
    "\n",
    "# Load test dataset:\n",
    "args_test = deepcopy(args)\n",
    "if args.temporal_bundle_steps == 1:\n",
    "    if args.dataset in [\"fno\", \"fno-2\", \"fno-3\"]:\n",
    "        args_test.multi_step = \"20\"\n",
    "    elif args.dataset in [\"fno-1\"]:\n",
    "        args_test.multi_step = \"40\"\n",
    "    elif args.dataset in [\"fno-4\"]:\n",
    "        args_test.multi_step = \"10\"\n",
    "    elif args.dataset in [\"naca_ellipse_lepde\"]:\n",
    "        args_test.multi_step = \"1\"\n",
    "        args_test.latent_multi_step=\"1\"\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    pass\n",
    "args_test.batch_size = 1\n",
    "args_test.is_test_only=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ac95c9-0416-43f9-931d-56b5f58bdc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e0452-a0a6-4c77-a42e-9d5f92af0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_2d_boundary_mask import ForceUnet\n",
    "force_model = ForceUnet(\n",
    "    dim = 64,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    channels=4\n",
    ")\n",
    "force_model.load_state_dict(torch.load(\"./dataset/epoch_12.pth\"))\n",
    "force_model.to(device)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c6048-b123-4dd8-b99a-bc2113a12fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for normalization\n",
    "normalization_filename = os.path.join(\"./dataset/naca_ellipse/training_trajectories/\", \"normalization_max_min.p\")\n",
    "normdict = pickle.load(open(normalization_filename, \"rb\"))\n",
    "x_max = normdict[\"x_max\"]\n",
    "x_min = normdict[\"x_min\"]\n",
    "y_max = normdict[\"y_max\"]\n",
    "y_min = normdict[\"y_min\"]\n",
    "p_max = normdict[\"p_max\"]\n",
    "p_min = normdict[\"p_min\"]\n",
    "p_max = p_max.to(device)\n",
    "p_min = p_min.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c5d1a-442c-4be1-ac35-521f8d967a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from le_pde.utils import get_data_next_step_with_static\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from utils import compute_pressForce, compute_orthonormal, linear_transform, update_data\n",
    "        \n",
    "optim_iter = 100\n",
    "\n",
    "prerollout = 0\n",
    "one_period = 6\n",
    "vis_prerollout = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eac3296-fa50-4dde-b67e-2a1128e1020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_list = []\n",
    "# i=0\n",
    "# for data in test_loader:\n",
    "#     # if i == 1900:\n",
    "#     if (i+1)%100 == 0:\n",
    "#         data_list.append(data)\n",
    "#     # if i == 0:\n",
    "#     # if i == 400:\n",
    "#     if i == 2000:\n",
    "#         break\n",
    "#     i+=1\n",
    "\n",
    "    # if i%100 == 0:\n",
    "    #     fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "    #     bd = (((data.param[\"n0\"].detach().cpu().numpy()/2) + 0.5) * 62) + 0\n",
    "    #     mappable0 = ax.plot(bd[0,0::2], bd[0,1::2])\n",
    "    #     ax.set_xlim(0, 62)\n",
    "    #     ax.set_ylim(0, 62)\n",
    "    #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6de632-cc96-4187-b073-2476eb7b0232",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_prerollout = False\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from utils import compute_pressForce, compute_orthonormal, linear_transform, update_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593a4a9f-cb37-400e-991d-e4482e6dbea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone data\n",
    "\n",
    "for testnum in range(10):\n",
    "    print(\"testnum: \", testnum)\n",
    "    data_list = []\n",
    "    i=0\n",
    "    for data in test_loader:\n",
    "        # if i == 1900:\n",
    "        if (i+1)%100 == 0:\n",
    "            data_list.append(data)\n",
    "        # if i == 0:\n",
    "        # if i == 400:\n",
    "        if i == 2000:\n",
    "            break\n",
    "        i+=1\n",
    "\n",
    "    datanum = 0\n",
    "    for data in data_list:\n",
    "        print(\"datanum :\", datanum)\n",
    "        data.to(device)   \n",
    "        testdata = data.clone()\n",
    "        evaldata = data.clone()\n",
    "\n",
    "        opt_mask = testdata.node_feature[\"n0\"][:,-2:-1,0:1].detach().clone()\n",
    "        opt_offset = testdata.node_feature[\"n0\"][:,-2:-1,1:3].detach().clone()\n",
    "        opt_mask.requires_grad=True\n",
    "        opt_offset.requires_grad=True\n",
    "\n",
    "        cat_opt_mask = torch.concat([opt_mask, opt_offset], -1)\n",
    "        static_grid = torch.concat([cat_opt_mask for _ in range(4)], -2)\n",
    "        dynamic_features = testdata.node_feature[\"n0\"][:,:,3:].detach().clone()\n",
    "        dynamic_features.requires_grad=True\n",
    "\n",
    "        testdata.node_feature[\"n0\"] = torch.concat([static_grid, dynamic_features], -1)\n",
    "\n",
    "        optimizer = torch.optim.Adam([opt_mask, opt_offset, dynamic_features], lr=0.0001)\n",
    "\n",
    "        # pdf = PdfPages('./optimized_naca_fno_gradient.pdf')\n",
    "\n",
    "        list_force = []\n",
    "        list_drag_force = []\n",
    "        for oiter in range(optim_iter):\n",
    "            total_x_force = 0\n",
    "            total_y_force = 0\n",
    "\n",
    "            ### Define boundary ###\n",
    "            # bound = torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:].reshape(40,2)\n",
    "\n",
    "            ### update boundary ###\n",
    "            # rec_bound = (((bound/2) + 0.5) * 62) + 0  \n",
    "            # testdata = update_data(rec_bound, testdata, orgdata, const_variable, opt_variable)\n",
    "\n",
    "            raw_bound = (((testdata.param[\"n0\"].reshape(40,2)/2) + 0.5) * 62) + 0\n",
    "            raw_bound.requires_grad = False\n",
    "\n",
    "            if oiter == (optim_iter - 1):\n",
    "                force_list = []\n",
    "\n",
    "            ### Perform rollout and Compute objective ###\n",
    "            for kk in range(prerollout+one_period):\n",
    "                if oiter % 50 == 49 and kk == 0 and vis_prerollout:\n",
    "                    print(\"kk = 0\")\n",
    "                    fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "                    ax.imshow(torch.nn.functional.pad(((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min, ((1,3,1,3))).detach().cpu().numpy(), cmap='viridis',\n",
    "                             aspect='auto',\n",
    "                             origin='lower')\n",
    "                    plt.show()\n",
    "\n",
    "                # testdata, pred = get_data_next_step(model_fno, testdata, use_grads=False, return_data=True, is_y_diff=False)\n",
    "                # press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "\n",
    "                if oiter % 50 == 49 and kk == prerollout and vis_prerollout:\n",
    "                    print(\"kk = \" + str(prerollout))\n",
    "                    fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "                    ax.imshow(torch.nn.functional.pad(press, ((1,3,1,3))).detach().cpu().numpy(), cmap='viridis',\n",
    "                             aspect='auto',\n",
    "                             origin='lower')\n",
    "                    plt.show()\n",
    "\n",
    "                if kk >= prerollout:\n",
    "                    testdata, pred = get_data_next_step(model_fno, testdata, use_grads=False, return_data=True, is_y_diff=False)\n",
    "                    if oiter == optim_iter - 1:\n",
    "                        try:    \n",
    "                            os.makedirs(\"./optimized_traj_fno_BP/test_{:06d}/sim_{:06d}\".format(testnum, datanum))\n",
    "                        except Exception:\n",
    "                            pass   \n",
    "                        with open('./optimized_traj_fno_BP/test_{:06d}/sim_{:06d}/feature_{:06d}.npy'.format(testnum, datanum, kk), 'wb') as f:\n",
    "                            np.save(f, testdata.node_feature[\"n0\"].detach().cpu().numpy())\n",
    "                    # press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "                    input_press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,-1:])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "                    # pdb.set_trace()\n",
    "\n",
    "                    input_node_feature = torch.cat([input_press, cat_opt_mask.reshape(62, 62, 1, 3)], -1).reshape(62, 62, 1, -1)\n",
    "                    input_node_feature = torch.permute(input_node_feature, (2, 3, 0, 1))\n",
    "                    data_pad = torch.zeros(1, 4, 64, 64).to(input_node_feature.device)\n",
    "                    data_pad[ :, :, 1:-1, 1:-1] = input_node_feature\n",
    "                    input_node_feature = data_pad\n",
    "\n",
    "                    x_force, y_force = force_model(input_node_feature)[0]\n",
    "                    # if oiter == optim_iter - 1:\n",
    "                    #     force_list.append(torch.stack([x_force, y_force], - 1))\n",
    "                    # x_force, y_force = compute_pressForce(torch.nn.functional.pad(press, (1,3,1,3)), raw_bound)\n",
    "\n",
    "                    total_x_force += x_force\n",
    "                    total_y_force += y_force\n",
    "\n",
    "            # if oiter == optim_iter - 1:\n",
    "            #     with open(\"./optimized_traj_fno_BP/sim_{:06d}/raw_force.npy\".format(datanum), 'wb') as f:\n",
    "            #         np.save(f, torch.stack(force_list, 0).detach().cpu().numpy())\n",
    "\n",
    "\n",
    "            total_x_force = total_x_force/one_period\n",
    "            total_y_force = total_y_force/one_period\n",
    "\n",
    "            list_force.append(-total_y_force.item())\n",
    "            list_drag_force.append(total_x_force.item())\n",
    "\n",
    "            # pdb.set_trace()\n",
    "            # updated_len = torch.norm((raw_bound - torch.roll(raw_bound, 1, 0)), p=2, dim=1).clone()\n",
    "            # edge_length_penalty = torch.max(torch.stack([threshold, torch.abs(updated_len - const_len)], -1), 1)[0].sum()\n",
    "            # updated_boundary_area = torch.sum((raw_bound*torch.fliplr(torch.roll(raw_bound, 1, 0)))[:,0] - (raw_bound*torch.fliplr(torch.roll(raw_bound, 1, 0)))[:,1])\n",
    "\n",
    "            ### Perform optimization ###\n",
    "            output = torch.abs(total_x_force) + total_y_force\n",
    "            optimizer.zero_grad()\n",
    "            output.backward()\n",
    "            # torch.nn.utils.clip_grad_value_(opt_variable, 0.01)\n",
    "            optimizer.step()\n",
    "\n",
    "            # rolled_boundary = torch.roll(bound, -1, 0)\n",
    "            # bd_diff = torch.abs(bound - rolled_boundary)\n",
    "            # if (bd_diff > 2).sum() > 0:\n",
    "            #     import pdb\n",
    "            #     pdb.set_trace()\n",
    "\n",
    "\n",
    "            ### Visualization ###\n",
    "            if oiter % 50 == 49:\n",
    "                print(\"iteration: \", oiter + 1)\n",
    "    #             print(\"objective: \", total_y_force/total_x_force)\n",
    "    #             # print(\"threshold: \", updated_len - const_len)\n",
    "    #             # print(\"boundary area: \", updated_boundary_area)\n",
    "\n",
    "    #             bd = (((raw_bound.detach().cpu().numpy()/2) + 0.5) * 62) + 0\n",
    "    #             length, nx, ny, cen = compute_orthonormal(torch.tensor(bd))\n",
    "    #             cen = cen.to(device)\n",
    "    #             lin_press = linear_transform(torch.nn.functional.pad(press, (1,3,1,3)), cen)\n",
    "\n",
    "                # fig, ax = plt.subplots(figsize=(18,3), ncols=6)\n",
    "                # # mappable0 = ax[0].plot(bd[:,0], bd[:,1])\n",
    "                # # nx = nx.detach().cpu()\n",
    "                # # ny = ny.detach().cpu()\n",
    "                # # cen = cen.detach().cpu()\n",
    "                # # lin_press = lin_press.cpu()\n",
    "                # # # print(cen.device, normals.device, lin_press.device)\n",
    "                # # normals = torch.stack((lin_press*nx,lin_press*ny), -1)\n",
    "                # # for i in range(40):\n",
    "                # #     rel_normals = cen[i,:] + normals[i,:]\n",
    "                # #     ax[0].plot((cen[i,0].numpy(), rel_normals[0].detach().numpy()), (cen[i,1].numpy(), rel_normals[1].detach().numpy()))\n",
    "                # # ax[0].set_xlim(24, 35)\n",
    "                # # ax[0].set_ylim(32, 43)\n",
    "                # mappable1 = ax[1].imshow(testdata.node_feature[\"n0\"][:,-1,0].reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "                #                          aspect='auto',\n",
    "                #                          origin='lower')\n",
    "                # fig.colorbar(mappable1, ax=ax[1])\n",
    "                # vis_offsetmask = torch.where(testdata.node_feature[\"n0\"][:,-1,1]!=0, 1, 0)\n",
    "                # mappable2 = ax[2].imshow(testdata.node_feature[\"n0\"][:,-1,1].reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "                #                          aspect='auto',\n",
    "                #                          origin='lower')        \n",
    "                # fig.colorbar(mappable2, ax=ax[2])\n",
    "                # mappable3 = ax[3].imshow(testdata.node_feature[\"n0\"][:,-1,2].reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "                #                          aspect='auto',\n",
    "                #                          origin='lower')        \n",
    "                # fig.colorbar(mappable3, ax=ax[3])\n",
    "                # mappable4 = ax[4].plot(np.array(list_force)[0::5])\n",
    "                # mappable5 = ax[5].plot(np.array(list_drag_force)[0::5])\n",
    "                # # pdf.savefig()\n",
    "                # plt.show()\n",
    "                # print(opt_mask)\n",
    "                # print(\"\")\n",
    "                # print(opt_offset)\n",
    "\n",
    "            up_opt_mask = torch.clamp(opt_mask, min=0, max=1)\n",
    "            up_opt_offset = torch.clamp(opt_offset, min=-0.5, max=0.5)\n",
    "            cat_opt_mask = torch.concat([up_opt_mask, up_opt_offset], -1)\n",
    "            static_grid = torch.concat([cat_opt_mask for _ in range(4)], -2)\n",
    "            testdata.node_feature[\"n0\"] = torch.concat([static_grid, dynamic_features], -1)\n",
    "\n",
    "        # print(total_y_force/total_x_force)\n",
    "        # pdf.close()\n",
    "\n",
    "        datanum += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b748951-9138-463d-b53c-bd3cc8acb365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lepde",
   "language": "python",
   "name": "lepde"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
