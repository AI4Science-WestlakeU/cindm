{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41481747-0049-4511-b512-df8489041673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import OrderedDict\n",
    "import datetime\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pylab as plt\n",
    "from numbers import Number\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "pd.options.display.max_rows = 1500\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.width = 1000\n",
    "pd.set_option('max_colwidth', 400)\n",
    "import pdb\n",
    "import pickle\n",
    "import pprint as pp\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from deepsnap.batch import Batch as deepsnap_Batch\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..', '..'))\n",
    "from le_pde.argparser import arg_parse\n",
    "from le_pde.datasets.load_dataset import load_data\n",
    "from le_pde.models import load_model\n",
    "from le_pde.pytorch_net.util import groupby_add_keys, filter_df, get_unique_keys_df, Attr_Dict, Printer, get_num_params, get_machine_name, pload, pdump, to_np_array, get_pdict, reshape_weight_to_matrix, ddeepcopy as deepcopy, plot_vectors, record_data, filter_filename, Early_Stopping, str2bool, get_filename_short, print_banner, plot_matrices, get_num_params, init_args, filter_kwargs, to_string, COLOR_LIST\n",
    "from le_pde.utils import update_legacy_default_hyperparam, EXP_PATH, deepsnap_to_pyg, LpLoss, to_cpu, to_tuple_shape, parse_multi_step, loss_op, get_device, get_data_next_step\n",
    "from utils import compute_pressForce\n",
    "#from le_pde.utils import deepsnap_to_pyg, LpLoss, to_cpu, to_tuple_shape, parse_multi_step, loss_op, get_device, get_data_next_step\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "p = Printer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34edf99f-9265-45b0-906d-650e4261dc77",
   "metadata": {},
   "source": [
    "## 1. Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67193e7b-5777-4aac-9426-f91e6837d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(data_record):\n",
    "    x_axis = np.arange(len(data_record[\"train_loss\"]))\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(x_axis, data_record[\"train_loss\"], label=\"train\")\n",
    "    plt.plot(x_axis, data_record[\"val_loss\"], label=\"val\")\n",
    "    plt.plot(x_axis, data_record[\"test_loss\"], label=\"test\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.semilogy(x_axis, data_record[\"train_loss\"], label=\"train\")\n",
    "    plt.semilogy(x_axis, data_record[\"val_loss\"], label=\"val\")\n",
    "    plt.semilogy(x_axis, data_record[\"test_loss\"], label=\"test\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4494e7-afaf-4d55-a1fc-b32168ca62b5",
   "metadata": {},
   "source": [
    "## 2. Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a74011e-cb80-444a-ae95-6f29d830193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_PATH = \"./results/\"\n",
    "\n",
    "isplot = True\n",
    "all_hash = [\n",
    "    \"clnAWVnz_hyperturing1\",\n",
    "]\n",
    "hash_str = all_hash[0]\n",
    "dirname = EXP_PATH + \"naca_ellipse_2023-06-02/\"\n",
    "filename = filter_filename(dirname, include=hash_str)\n",
    "if len(filename) == 0:\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    data_record = pload(dirname + filename[0])\n",
    "except Exception as e:\n",
    "    print(f\"error {e}\")\n",
    "    # continue\n",
    "    raise\n",
    "if isplot:\n",
    "    plot_learning_curve(data_record)\n",
    "args = init_args(update_legacy_default_hyperparam(data_record[\"args\"]))\n",
    "args.filename = filename\n",
    "model = load_model(data_record[\"model_dict\"][-1], device=device)\n",
    "model.eval()\n",
    "p.print(filename, banner_size=100)\n",
    "\n",
    "# Load test dataset:\n",
    "args_test = deepcopy(args)\n",
    "if args.temporal_bundle_steps == 1:\n",
    "    if args.dataset in [\"fno\", \"fno-2\", \"fno-3\"]:\n",
    "        args_test.multi_step = \"20\"\n",
    "    elif args.dataset in [\"fno-1\"]:\n",
    "        args_test.multi_step = \"40\"\n",
    "    elif args.dataset in [\"fno-4\"]:\n",
    "        args_test.multi_step = \"10\"\n",
    "    elif args.dataset in [\"naca_ellipse_lepde\"]:\n",
    "        args_test.multi_step = \"1\"\n",
    "        args_test.latent_multi_step=\"1\"\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    pass\n",
    "args_test.batch_size = 1\n",
    "args_test.is_test_only=True\n",
    "\n",
    "(dataset_train_val, dataset_test), (train_loader, val_loader, test_loader) = load_data(args_test)\n",
    "test_loader = DataLoader(dataset_test, num_workers=0, collate_fn=deepsnap_Batch.collate(),\n",
    "                         batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749c5974-4afc-41b3-9d23-b174133f43d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i=0\n",
    "# for data in test_loader:\n",
    "#     # if i == 1900:\n",
    "#     # if i == 2500:\n",
    "#     if i == 1200:\n",
    "#     # if i == 0:\n",
    "#     # if i == 400:\n",
    "#         break\n",
    "#     i+=1\n",
    "\n",
    "#     if i%100 == 0:\n",
    "#         fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "#         bd = (((data.param[\"n0\"].detach().cpu().numpy()/2) + 0.5) * 62) + 0\n",
    "#         mappable0 = ax.plot(bd[0,0::2], bd[0,1::2])\n",
    "#         ax.set_xlim(0, 62)\n",
    "#         ax.set_ylim(0, 62)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8656e5-40e6-4649-9930-8ec3b0b346e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to(device)        \n",
    "# testdata = data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13c71e6-2162-4dfe-afa0-e950c7ba9482",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 64; n=64\n",
    "maxnum = 100\n",
    "\n",
    "def discretize_boundary(boundary):\n",
    "    assert boundary.shape[1] == 2\n",
    "    num_bound = boundary.shape[0]\n",
    "    device = boundary.device\n",
    "    p_5 = torch.tensor([0.5], device=device).repeat(num_bound)\n",
    "    x = torch.minimum(torch.maximum(boundary[:, 0], p_5), torch.tensor([n-1.5], device=device).repeat(num_bound))\n",
    "    x_inds = torch.minimum(x.type(torch.int32), torch.tensor([n-2], device=device).repeat(num_bound))\n",
    "\n",
    "    y = torch.minimum(torch.maximum(boundary[:, 1], p_5), torch.tensor([m-1.5], device=device).repeat(num_bound))\n",
    "    y_inds = torch.minimum(y.type(torch.int32), torch.tensor([m-2], device=device).repeat(num_bound))\n",
    "    return x_inds, y_inds\n",
    "\n",
    "def find_orthogonal_line(A, B, C, x0, y0):\n",
    "    m1 = torch.empty((C.shape[0],), device=C.device)\n",
    "    m1[B==0] = float('inf')\n",
    "    m1[B!=0] = (-A/B)[B!=0]\n",
    "\n",
    "    m2 = torch.empty((C.shape[0],), device=C.device)\n",
    "    m2[m1==float('inf')] = 0\n",
    "    m2[m1!=float('inf')] = (-1 / m1)[m1!=float('inf')]\n",
    "\n",
    "    b2 = y0 - m2 * x0  # The y-intercept of L2.\n",
    "\n",
    "    # Return the coefficients A, B, C of the line L2 (Ax + By - C = 0)\n",
    "    return m2, -1, b2\n",
    "\n",
    "def edge_cells(polygon):\n",
    "    num_vertices = len(polygon)\n",
    "    edges = []\n",
    "    for i in range(num_vertices):\n",
    "        v1 = polygon[i]\n",
    "        v2 = polygon[(i + 1) % num_vertices]\n",
    "        edge = sorted([v1, v2], key=lambda x: x[1])\n",
    "        edges.append(edge)\n",
    "    return edges\n",
    "\n",
    "def find_cells_inside_curve(polygon, grid_shape):\n",
    "    def horizontal_intersection(x1, y1, x2, y2, y):\n",
    "        return x1 + (y - y1) * (x2 - x1) / (y2 - y1)\n",
    "    edges = edge_cells(polygon)\n",
    "    grid = np.zeros(grid_shape, dtype=np.uint8)\n",
    "    height, width = grid.shape\n",
    "    \n",
    "    for y in range(height):\n",
    "        intersections = []\n",
    "        for edge in edges:\n",
    "            y1, y2 = edge[0][1], edge[1][1]\n",
    "            if y1 < y <= y2:\n",
    "                x = horizontal_intersection(*edge[0], *edge[1], y)\n",
    "                intersections.append(x)\n",
    "        intersections.sort()\n",
    "        for i in range(0, len(intersections), 2):\n",
    "            x_start, x_end = int(np.ceil(intersections[i])), int(np.floor(intersections[i + 1]))\n",
    "            grid[y, x_start : x_end + 1] = 1\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab1ba61-bf2e-4402-944b-47ec71449ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_static_masks(torch_con_boundary):\n",
    "    x_inds, y_inds = discretize_boundary(torch_con_boundary)\n",
    "    pointy_hash = maxnum*x_inds[20] + y_inds[20]\n",
    "\n",
    "    indices = torch.stack((maxnum*x_inds,y_inds), 0)\n",
    "    sum_indices = indices.sum(0)\n",
    "    ind_unique = torch.unique(sum_indices, sorted=True) #, return_inverse=True)\n",
    "    x_idx = (torch.cat([(sum_indices==ind_u).nonzero()[0] for ind_u in ind_unique])).sort()[0]\n",
    "    repeat_sum_indices = torch.tile(sum_indices, (ind_unique.shape[0],1))\n",
    "    repeat_ind_unique = torch.tile(sum_indices[x_idx].reshape(ind_unique.shape[0], 1), (1, sum_indices.shape[0]))\n",
    "    org_mask = (repeat_ind_unique == repeat_sum_indices)\n",
    "    fatted_mask = torch.roll(org_mask, 1, 1) + torch.roll(org_mask, -1, 1)\n",
    "\n",
    "    relvecs = []\n",
    "    base_pts = []\n",
    "    base_nums = []\n",
    "    for bdpt in range(sum_indices[x_idx].shape[0]):\n",
    "        if pointy_hash == sum_indices[x_idx][bdpt]:\n",
    "            base_pt = torch.stack([x_inds[org_mask[bdpt]][0], y_inds[org_mask[bdpt]][0]]) + 0.5\n",
    "            base_pts.append(base_pt)\n",
    "            relvec = torch_con_boundary[20] - base_pt\n",
    "            relvecs.append(relvec)\n",
    "        elif torch.sum(org_mask[bdpt]) >= 4:\n",
    "            base_pt = torch.stack([x_inds[org_mask[bdpt]][0], y_inds[org_mask[bdpt]][0]]) + 0.5\n",
    "            base_pts.append(base_pt)\n",
    "            relvec = torch_con_boundary[org_mask[bdpt]] - base_pt.repeat(torch_con_boundary[org_mask[bdpt]].shape[0], 1)\n",
    "            ind = torch.argmin(torch.norm(relvec, dim=1))\n",
    "            relvecs.append(relvec[ind])\n",
    "        elif torch.sum(fatted_mask[bdpt] * torch.logical_not(org_mask[bdpt])) > 2:\n",
    "            base_pt = torch.stack([x_inds[org_mask[bdpt]][0], y_inds[org_mask[bdpt]][0]]) + 0.5\n",
    "            relvec = torch_con_boundary[org_mask[bdpt]] - base_pt.repeat(torch_con_boundary[org_mask[bdpt]].shape[0], 1)\n",
    "            if len(relvec.shape) == 2:\n",
    "                relvecs.append(relvec[-1])\n",
    "                base_pts.append(base_pt)\n",
    "            else:\n",
    "                relvecs.append(relvec)\n",
    "                base_pts.append(base_pt)\n",
    "        elif torch.sum(org_mask[bdpt]) == 1:\n",
    "            base_pt = torch.stack([x_inds[org_mask[bdpt]][0], y_inds[org_mask[bdpt]][0]]) + 0.5\n",
    "            base_pts.append(base_pt)\n",
    "            relvec = torch_con_boundary[org_mask[bdpt]] - base_pt\n",
    "            relvecs.append(relvec[0])\n",
    "        else:    \n",
    "            if fatted_mask[bdpt][0] and fatted_mask[bdpt][-1]:\n",
    "                rollnum = 1\n",
    "                for _ in range(0, 100):\n",
    "                    temprole = torch.roll(fatted_mask[bdpt], rollnum, 0)\n",
    "                    if temprole[0] and temprole[-1]:\n",
    "                        rollnum += 1    \n",
    "                    else:\n",
    "                        break\n",
    "                x_pts = torch.roll(torch_con_boundary[fatted_mask[bdpt]], rollnum, 0)            \n",
    "            else:\n",
    "                x_pts = torch_con_boundary[fatted_mask[bdpt]]\n",
    "\n",
    "            bd_points = torch.cat([x_pts[0:1], x_pts[1:-1].repeat(1, 2).reshape(-1,2), x_pts[-1:]], dim=0)\n",
    "            dire_vec = bd_points[0::2] - bd_points[1::2]\n",
    "            const = bd_points[0::2, 1] - bd_points[0::2, 0] * dire_vec[:,1]/dire_vec[:,0]\n",
    "\n",
    "            base_pt = torch.stack([x_inds[org_mask[bdpt]][0], y_inds[org_mask[bdpt]][0]]) + 0.5\n",
    "            base_pts.append(base_pt)\n",
    "            base_points = base_pt.repeat(const.shape[0], 1)\n",
    "            slope = dire_vec[:,1]/dire_vec[:,0]\n",
    "            ax, by, con = find_orthogonal_line(slope, -torch.ones((const.shape[0],), device=torch_con_boundary.device), const, base_points[:,0], base_points[:,1])\n",
    "\n",
    "            al = -ax/by\n",
    "            bl = con\n",
    "            cl = dire_vec[:,1]/dire_vec[:,0]\n",
    "            dl = const\n",
    "\n",
    "            intersection = torch.stack([(dl - bl)/(al - cl), (al*dl - bl*cl)/(al - cl)]).t()\n",
    "\n",
    "            relvec = intersection - torch.tile(base_pt, (intersection.shape[0], 1))\n",
    "            relvecs.append(relvec.sum(0)/relvec.shape[0])\n",
    "\n",
    "    ### Check number of offset vectors is same as that of boundary cells of solid\n",
    "    assert len(base_pts) == sum_indices[x_idx].shape[0]\n",
    "    \n",
    "    bd_offset = torch.stack(relvecs)\n",
    "    offset_grid_bound = torch.zeros((62, 62, 2), device=torch_con_boundary.device)\n",
    "    offset_grid_bound[x_inds, y_inds] = torch.tensor([1, 1], dtype=torch.float32, device=torch_con_boundary.device)\n",
    "    offset_grid_bound = offset_grid_bound.transpose(1,0)\n",
    "\n",
    "    offset_grid = find_cells_inside_curve(torch.stack((x_inds, y_inds), -1).detach().cpu().tolist(), (62, 62))\n",
    "    inner_solid_mask = np.copy(offset_grid)\n",
    "    offset_grid = offset_grid.reshape(62, 62, 1)\n",
    "    offset_grid = np.concatenate([offset_grid, offset_grid], -1)\n",
    "\n",
    "    offset_union = offset_grid_bound + torch.tensor(offset_grid, device=torch_con_boundary.device)\n",
    "    offset_union[(offset_union.sum(-1) > 2),:] = torch.tensor([1, 1], dtype=torch.float32, device=torch_con_boundary.device)\n",
    "    offset_union.index_put_((y_inds[x_idx], x_inds[x_idx]), bd_offset)    \n",
    "\n",
    "    grid_bound = torch.zeros((62, 62), device=torch_con_boundary.device)\n",
    "    grid_bound[x_inds, y_inds] = 1\n",
    "    union = grid_bound.transpose(1,0) + torch.tensor(inner_solid_mask, device=torch_con_boundary.device)\n",
    "    union[union == 2] = 1\n",
    "\n",
    "    updated_solid_mask = union\n",
    "    \n",
    "    return updated_solid_mask, offset_union "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c39b200-676e-480b-97c1-860885a0baf1",
   "metadata": {},
   "source": [
    "## 3. inverse optimization with LE-PDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b655941-d5e0-4e70-9311-2602bf16e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "isplot = True\n",
    "all_hash = [\n",
    "    # \"Yirzlp+j_ampere4\",\n",
    "    # \"QvUQ8aaL_turing2\",\n",
    "    \"YpkNljy1_whdeng\",\n",
    "]\n",
    "hash_str = all_hash[0]\n",
    "dirname = EXP_PATH + \"naca_ellipse_2023-09-27/\"\n",
    "filename = filter_filename(dirname, include=hash_str)\n",
    "if len(filename) == 0:\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    data_record = pload(dirname + filename[0])\n",
    "except Exception as e:\n",
    "    print(f\"error {e}\")\n",
    "    raise\n",
    "if isplot:\n",
    "    plot_learning_curve(data_record)\n",
    "args = init_args(update_legacy_default_hyperparam(data_record[\"args\"]))\n",
    "args.filename = filename\n",
    "model_lepde = load_model(data_record[\"model_dict\"][-1], device=device)\n",
    "model_lepde.eval()\n",
    "p.print(filename, banner_size=100)\n",
    "\n",
    "# Load test dataset:\n",
    "args_test = deepcopy(args)\n",
    "if args.temporal_bundle_steps == 1:\n",
    "    if args.dataset in [\"fno\", \"fno-2\", \"fno-3\"]:\n",
    "        args_test.multi_step = \"20\"\n",
    "    elif args.dataset in [\"fno-1\"]:\n",
    "        args_test.multi_step = \"40\"\n",
    "    elif args.dataset in [\"fno-4\"]:\n",
    "        args_test.multi_step = \"10\"\n",
    "    elif args.dataset in [\"naca_ellipse_lepde\"]:\n",
    "        args_test.multi_step = \"1\"\n",
    "        args_test.latent_multi_step=\"1\"\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    pass\n",
    "args_test.batch_size = 1\n",
    "args_test.is_test_only=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94522213-06a2-44da-ae27-1b4be408f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_2d_boundary_mask import ForceUnet\n",
    "force_model = ForceUnet(\n",
    "    dim = 64,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    channels=4\n",
    ")\n",
    "# force_model.load_state_dict(torch.load(\"./dataset/epoch_29.pth\"))\n",
    "force_model.load_state_dict(torch.load(\"./dataset/epoch_12.pth\"))\n",
    "force_model.to(device)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd62554-884b-4f1a-9393-7f11cf058712",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_filename = os.path.join(\"./dataset/naca_ellipse/training_trajectories/\", \"normalization_max_min.p\")\n",
    "normdict = pickle.load(open(normalization_filename, \"rb\"))\n",
    "x_max = normdict[\"x_max\"]\n",
    "x_min = normdict[\"x_min\"]\n",
    "y_max = normdict[\"y_max\"]\n",
    "y_min = normdict[\"y_min\"]\n",
    "p_max = normdict[\"p_max\"]\n",
    "p_min = normdict[\"p_min\"]\n",
    "p_max = p_max.to(device)\n",
    "p_min = p_min.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84fa8b-afc1-44ee-93c1-32ceabf87017",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_elite = 2\n",
    "num_sample = 20\n",
    "smoothing_coef = 0.001\n",
    "lamb = 1.\n",
    "\n",
    "optim_iter = 100\n",
    "optim_iter_mask = 50\n",
    "prerollout = 0\n",
    "one_period = 6\n",
    "vis_prerollout = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c82246-9485-4f96-bb27-40ddbefefa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from le_pde.utils import get_data_next_step_with_static\n",
    "\n",
    "for testnum in range(10):\n",
    "    print(\"testnum: \", testnum)\n",
    "    data_list = []\n",
    "    i=0\n",
    "    for data in test_loader:\n",
    "        if (i+1)%100 == 0:\n",
    "            data_list.append(data)\n",
    "        if i == 2000:\n",
    "            break\n",
    "        i+=1\n",
    "\n",
    "    # force_ratio = []\n",
    "    # Hyper parameter for CEM\n",
    "\n",
    "    datanum = 0\n",
    "    for data in data_list:\n",
    "        print(\"datanum: \", datanum)\n",
    "        data.to(device) \n",
    "        testdata = data.clone()\n",
    "        static_data = data.clone()\n",
    "        evaldata = data.clone()\n",
    "\n",
    "        opt_mask = testdata.node_feature[\"n0\"][:,-2:-1,0:1].clone()\n",
    "        opt_offset = testdata.node_feature[\"n0\"][:,-2:-1,1:3].clone()\n",
    "\n",
    "        mask_list = []\n",
    "        for i in range(62*62):\n",
    "            if opt_mask.flatten()[i] == 1:\n",
    "                mask_list.append([[0.99]])\n",
    "            else:    \n",
    "                mask_list.append([[0.01]])\n",
    "        soft_opt_mask = torch.tensor(mask_list, device=opt_mask.device).reshape(opt_mask.shape)\n",
    "        soft_opt_mask.requires_grad = True\n",
    "\n",
    "        cat_opt_mask = torch.concat([opt_mask, opt_offset], -1)\n",
    "        static_grid = torch.concat([cat_opt_mask for _ in range(4)], -2)\n",
    "        opt_dynamic_features = torch.clamp(testdata.node_feature[\"n0\"][:,:,3:].detach().clone() + torch.randn([62*62, 4, 3], device=opt_mask.device), -1, 1)\n",
    "        dynamic_features = opt_dynamic_features #.clone()\n",
    "\n",
    "        # testdata.node_feature[\"n0\"] = torch.concat([static_grid, dynamic_features], -1)\n",
    "        testdata.node_feature[\"n0\"] = torch.cat([static_grid, dynamic_features], dim=-1)\n",
    "        static_data.node_feature[\"n0\"] = static_grid\n",
    "\n",
    "        # prerollout = 36\n",
    "        stds = torch.where(opt_offset==1, 0.01, 0.01)\n",
    "        stds_dynamic = torch.full(dynamic_features.shape, 0.01, device=opt_mask.device)\n",
    "        # print(stds_dynamic)\n",
    "\n",
    "        optimizer_mask = torch.optim.Adam([soft_opt_mask], lr=0.001)        \n",
    "\n",
    "        list_force = []\n",
    "        list_drag_force = []\n",
    "        for oiter in range(optim_iter):\n",
    "            total_x_force = 0\n",
    "            total_y_force = 0\n",
    "\n",
    "            candidate_boundaries_offset = []\n",
    "            candidate_boundaries_mask = []\n",
    "            candidate_dynamics = []\n",
    "            candidate_xforces = []\n",
    "            candidate_yforces = []\n",
    "            scores = []\n",
    "\n",
    "            if oiter == (optim_iter - 1):\n",
    "                force_list = []\n",
    "            ### CEM Loop ###\n",
    "            # pdb.set_trace()\n",
    "            for s in range(num_sample):\n",
    "                # testdata = data.clone()\n",
    "\n",
    "                # Generate random sample for offset\n",
    "                clamp_soft_opt_mask = torch.clamp(soft_opt_mask, 0, 1)\n",
    "                perturbed_boundary_mask = torch.bernoulli(clamp_soft_opt_mask)\n",
    "                candidate_boundaries_mask.append(perturbed_boundary_mask)\n",
    "                perturbed_boundary_offset = torch.normal(mean=opt_offset, std=stds)\n",
    "                candidate_boundaries_offset.append(perturbed_boundary_mask)\n",
    "                perturbed_dynamics = torch.clamp(torch.normal(mean=opt_dynamic_features, std=stds_dynamic), -1, 1)\n",
    "                candidate_dynamics.append(perturbed_dynamics[...,None])\n",
    "\n",
    "                #Update boundary feature\n",
    "                perturbed_mask = torch.concat([perturbed_boundary_mask, perturbed_boundary_offset], -1)\n",
    "                static_grid = perturbed_mask.repeat(1, 4, 1)\n",
    "                # static_grid = torch.concat([perturbed_mask for _ in range(4)], -2)\n",
    "                # dynamic_features = testdata.node_feature[\"n0\"][:,:,3:].detach().clone()\n",
    "\n",
    "                testdata.node_feature[\"n0\"] = torch.concat([static_grid, perturbed_dynamics], -1)\n",
    "                static_data.node_feature[\"n0\"] = static_grid\n",
    "\n",
    "                # with torch.enable_grad():\n",
    "                ### Perform rollout ###\n",
    "                total_x_force = 0\n",
    "                total_y_force = 0\n",
    "                final_objective = 0\n",
    "                for kk in range(prerollout+one_period):\n",
    "                    if kk < prerollout:\n",
    "                        testdata, _ = get_data_next_step_with_static(model_lepde, testdata, static_data, use_grads=False, return_data=True, is_y_diff=False, is_rollout=True)\n",
    "                        # raw_bound = (((testdata.param[\"n0\"].reshape(40,2)/2) + 0.5) * 62) + 0\n",
    "                    # if kk == prerollout:\n",
    "                    #     length, nx, ny, cen = compute_orthonormal(raw_bound)\n",
    "                        # cen = cen.to(device)       \n",
    "                    elif kk >= prerollout:\n",
    "                        testdata, pred = get_data_next_step_with_static(model_lepde, testdata, static_data, use_grads=False, return_data=True, is_y_diff=False, is_rollout=True)\n",
    "                        input_press = torch.clamp(((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,-1:])/2) + 0.5) * (p_max-p_min)) + p_min, -1, 1)\n",
    "\n",
    "                        input_node_feature = torch.cat([input_press, cat_opt_mask.reshape(62, 62, 1, 3)], -1).reshape(62, 62, 1, -1)\n",
    "                        input_node_feature = torch.permute(input_node_feature, (2, 3, 0, 1))\n",
    "                        data_pad = torch.zeros(1, 4, 64, 64).to(input_node_feature.device)\n",
    "                        data_pad[ :, :, 1:-1, 1:-1] = input_node_feature\n",
    "                        input_node_feature = data_pad\n",
    "\n",
    "                        # print(data_pad)\n",
    "                        # print(input_node_feature)\n",
    "                        with torch.no_grad():\n",
    "                            x_force, y_force = force_model(input_node_feature)[0]\n",
    "                        # x_force, y_force = compute_pressForce(torch.nn.functional.pad(press, (1,3,1,3)), raw_bound)                \n",
    "                        # final_objective += -1/x_force + 10 * torch.square(-7.5*one_period - y_force)\n",
    "                        total_x_force += x_force\n",
    "                        total_y_force += y_force\n",
    "\n",
    "                        del data_pad\n",
    "                        del input_node_feature\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "                total_x_force = total_x_force/one_period\n",
    "                total_y_force = total_y_force/one_period\n",
    "\n",
    "                candidate_xforces.append(total_x_force)\n",
    "                candidate_yforces.append(total_y_force)\n",
    "\n",
    "                scores.append(lamb * torch.abs(total_x_force) + total_y_force)\n",
    "                # scores.append(lamb * total_x_force + total_y_force)\n",
    "\n",
    "            index = torch.argsort(torch.tensor(scores))\n",
    "\n",
    "            # pdb.set_trace()\n",
    "            ### Select elite samples and compute next mean and variance ###\n",
    "            elites_mask = torch.cat(candidate_boundaries_mask, dim=1)[:, index, :][:, :num_elite, :]\n",
    "            for _ in range(optim_iter_mask):\n",
    "                # print(\"log min and max: \", soft_opt_mask.min(), soft_opt_mask.max())\n",
    "                output_mask = (1/num_elite) * (-torch.log(torch.cat([clamp_soft_opt_mask for _ in range(num_elite)], dim=1)[elites_mask==1]).sum() - torch.log(1 - torch.cat([clamp_soft_opt_mask for _ in range(num_elite)], dim=1)[elites_mask==0]).sum())\n",
    "                optimizer_mask.zero_grad()\n",
    "                output_mask.backward()\n",
    "                optimizer_mask.step()\n",
    "                clamp_soft_opt_mask = torch.clamp(soft_opt_mask, 0, 1)\n",
    "                del output_mask\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            # pdb.set_trace()\n",
    "            ### Smooth mean and variance ###\n",
    "            elites_offset = torch.cat(candidate_boundaries_offset, dim=1)[:, index, :][:, :num_elite, :]\n",
    "            next_mean = torch.mean(elites_offset, dim=1, keepdim=True)\n",
    "            next_vari = torch.var(elites_offset, dim=1, correction=0, keepdim=True)\n",
    "            opt_offset = smoothing_coef * torch.clamp(next_mean, -0.5, 0.5) + (1 - smoothing_coef) * opt_offset\n",
    "            stds = smoothing_coef * next_vari + (1 - smoothing_coef) * stds\n",
    "\n",
    "            # pdb.set_trace()\n",
    "            elites_dynamic = torch.cat(candidate_dynamics, dim=-1)[...,index][...,:num_elite]\n",
    "            next_mean_dynam = torch.mean(elites_dynamic, dim=-1, keepdim=True)\n",
    "            next_vari_dynam = torch.var(elites_dynamic, dim=-1, correction=0, keepdim=True)\n",
    "            opt_dynamic_features = smoothing_coef * torch.clamp(next_mean_dynam[...,0], -1, 1) + (1 - smoothing_coef) * opt_dynamic_features\n",
    "            stds_dynamic = smoothing_coef * next_vari_dynam[...,0] + (1 - smoothing_coef) * stds_dynamic\n",
    "\n",
    "            # pdb.set_trace()\n",
    "            # Generate random sample for offset\n",
    "            # pdb.set_trace()\n",
    "            opt_mask = torch.bernoulli(clamp_soft_opt_mask)\n",
    "            opt_offset = torch.normal(mean=opt_offset, std=stds)\n",
    "            opt_dynamic_features = torch.normal(mean=opt_dynamic_features, std=stds_dynamic)\n",
    "\n",
    "            #Update boundary feature\n",
    "            cat_opt_mask = torch.concat([opt_mask, opt_offset], -1)\n",
    "            static_grid = torch.concat([cat_opt_mask for _ in range(4)], -2)\n",
    "            # dynamic_features = evaldata.node_feature[\"n0\"][:,:,3:]\n",
    "            evaldata = data.clone()\n",
    "            evaldata.node_feature[\"n0\"] = torch.cat([static_grid, opt_dynamic_features], dim=-1)\n",
    "            static_data.node_feature[\"n0\"] = static_grid\n",
    "            # evaldata=evaldata.clone()\n",
    "\n",
    "            # pdb.set_trace()\n",
    "            ### Perform evaluation with updated boundary  ###\n",
    "            for kk in range(prerollout+one_period):\n",
    "                if kk < prerollout:\n",
    "                    # pdb.set_trace()            \n",
    "                    evaldata, pred = get_data_next_step_with_static(model_lepde, evaldata, static_data, use_grads=False, return_data=True, is_y_diff=False, is_rollout=True)\n",
    "                    # press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "                    # raw_bound = (((evaldata.param[\"n0\"].reshape(40,2)/2) + 0.5) * 62) + 0\n",
    "    #             if kk == prerollout:\n",
    "    #                 # pdb.set_trace()            \n",
    "    #                 length, nx, ny, cen = compute_orthonormal(raw_bound)\n",
    "    #                 # cen = cen.to(device)       \n",
    "                if kk >= prerollout:\n",
    "                    # pdb.set_trace()            \n",
    "                    evaldata, pred = get_data_next_step_with_static(model_lepde, evaldata, static_data, use_grads=False, return_data=True, is_y_diff=False, is_rollout=True)\n",
    "                    if oiter == optim_iter - 1:\n",
    "                        try:    \n",
    "                            os.makedirs(\"./optimized_traj_lepde_CEM/test_{:06d}/sim_{:06d}\".format(testnum, datanum))\n",
    "                        except Exception:\n",
    "                            pass   \n",
    "                        with open('./optimized_traj_lepde_CEM/test_{:06d}/sim_{:06d}/feature_{:06d}.npy'.format(testnum, datanum, kk), 'wb') as f:\n",
    "                            np.save(f, evaldata.node_feature[\"n0\"].detach().cpu().numpy())\n",
    "\n",
    "                    input_press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,-1:])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "                    input_node_feature = torch.cat([input_press, cat_opt_mask.reshape(62, 62, 1, 3)], -1).reshape(62, 62, 1, -1)\n",
    "                    input_node_feature = torch.permute(input_node_feature, (2, 3, 0, 1))\n",
    "                    data_pad = torch.zeros(1, 4, 64, 64).to(input_node_feature.device)\n",
    "                    data_pad[ :, :, 1:-1, 1:-1] = input_node_feature\n",
    "                    input_node_feature = data_pad\n",
    "                    del data_pad\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        x_force, y_force = force_model(input_node_feature)[0]\n",
    "                    # press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "                    # # lin_press = linear_transform(torch.nn.functional.pad(press, (1,3,1,3)), cen)\n",
    "                    # x_force, y_force = compute_pressForce(torch.nn.functional.pad(press, (1,3,1,3)), raw_bound)\n",
    "                    # ### Need to update, object should be defined here ###\n",
    "                    # if oiter == optim_iter - 1:\n",
    "                    #     force_list.append(torch.stack([x_force, y_force], - 1))                    \n",
    "\n",
    "                    total_x_force += x_force\n",
    "                    total_y_force += y_force\n",
    "\n",
    "                    del input_node_feature\n",
    "                    torch.cuda.empty_cache()\n",
    "                    # print(data_pad)\n",
    "\n",
    "            # elite_xforces = torch.stack(candidate_xforces, dim=-1)[...,index][...,:num_elite]\n",
    "            # total_x_force = torch.mean(elite_xforces, dim=-1, keepdim=True)[...,0]\n",
    "            # elite_yforces = torch.stack(candidate_yforces, dim=-1)[...,index][...,:num_elite]\n",
    "            # total_y_force = torch.mean(elite_yforces, dim=-1, keepdim=True)[...,0]\n",
    "            # if oiter == optim_iter - 1:\n",
    "            #     with open(\"./optimized_traj_lepde_CEM/sim_{:06d}/raw_force.npy\".format(datanum), 'wb') as f:\n",
    "            #         np.save(f, torch.stack(force_list, 0).detach().cpu().numpy())    \n",
    "\n",
    "            total_x_force = total_x_force/one_period\n",
    "            total_y_force = total_y_force/one_period\n",
    "\n",
    "            list_force.append(-total_y_force.item())\n",
    "            list_drag_force.append(total_x_force.item())\n",
    "\n",
    "\n",
    "            ### Visualization of updated boundary \"\"\"\n",
    "            if oiter % 50 == 49:\n",
    "                print(\"iteration: \", oiter)\n",
    "\n",
    "        del data\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "        # with open('./optimized_boundary_lepde_CEM/boundary_{:06d}.npy'.format(datanum), 'wb') as f:\n",
    "        #     np.save(f, evaldata.node_feature[\"n0\"][:,-1,:3].detach().cpu().numpy())\n",
    "\n",
    "        datanum += 1\n",
    "\n",
    "    # print(force_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea66762-f0e3-4d73-9c13-7eaa14dee6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.load('./optimized_traj_lepde_CEM/test_{:06d}/sim_{:06d}/feature_{:06d}.npy'.format(1, 2, 3))\n",
    "# b = np.load('./optimized_traj_lepde_CEM/test_{:06d}/sim_{:06d}/feature_{:06d}.npy'.format(1, 3, 2))\n",
    "# (a - b).shape\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(18,3), ncols=6)\n",
    "# #         mappable0 = ax[0].plot(bd[:,0], bd[:,1])\n",
    "# #         nx = nx.detach().cpu()\n",
    "# #         ny = ny.detach().cpu()\n",
    "# #         cen = cen.detach().cpu()\n",
    "# #         lin_press = lin_press.cpu()\n",
    "# #         normals = torch.stack((lin_press*nx,lin_press*ny), -1)#.to(device)\n",
    "# #         for i in range(40):\n",
    "# #             rel_normals = cen[i,:] + normals[i,:]\n",
    "# #             ax[0].plot((cen[i,0].numpy(), rel_normals[0].detach().numpy()), (cen[i,1].numpy(), rel_normals[1].detach().numpy()))\n",
    "# #         ax[0].set_xlim(24, 35)\n",
    "# #         ax[0].set_ylim(32, 43)\n",
    "# mappable1 = ax[1].imshow(a[:,-1,0].reshape(62,62), cmap='viridis',\n",
    "#                          aspect='auto',\n",
    "#                          origin='lower')\n",
    "# # vis_offsetmask = torch.where(evaldata.node_feature[\"n0\"][:,-1,1]!=0, 1, 0)\n",
    "# mappable2 = ax[2].imshow(b[:,-1,0].reshape(62,62), cmap='viridis',\n",
    "#                          aspect='auto',\n",
    "#                          origin='lower')        \n",
    "# mappable3 = ax[3].imshow((a[:,-1,0] - b[:,-1,0]).reshape(62,62), cmap='viridis',\n",
    "#                          aspect='auto',\n",
    "#                          origin='lower')        \n",
    "# # mappable4 = ax[4].plot(np.array(list_force)[0::5])\n",
    "# # mappable5 = ax[5].plot(np.array(list_drag_force)[0::5])\n",
    "#  # pdf.savefig()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19116c67-9ac8-400e-97cd-3210e2c8be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_list = []\n",
    "# i=0\n",
    "# for data in test_loader:\n",
    "#     # if i == 1900:\n",
    "#     if (i+1)%100 == 0:\n",
    "#         data_list.append(data)\n",
    "#     # if i == 0:\n",
    "#     # if i == 400:\n",
    "#     if i == 2000:\n",
    "#         break\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78562dc-40e9-46f6-99fa-11d8ef3d6485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from le_pde.utils import get_data_next_step_with_static\n",
    "\n",
    "# num_elite = 2\n",
    "# num_sample = 20\n",
    "# smoothing_coef = 0.001\n",
    "# lamb = 1.\n",
    "\n",
    "# optim_iter = 100\n",
    "# optim_iter_mask = 50\n",
    "# prerollout = 0\n",
    "# one_period = 6\n",
    "# vis_prerollout = False\n",
    "\n",
    "# # force_ratio = []\n",
    "# # Hyper parameter for CEM\n",
    "\n",
    "# datanum = 0\n",
    "# for data in data_list:\n",
    "#     data.to(device) \n",
    "#     testdata = data.clone()\n",
    "#     static_data = data.clone()\n",
    "#     evaldata = data.clone()\n",
    "\n",
    "#     opt_mask = testdata.node_feature[\"n0\"][:,-2:-1,0:1].clone()\n",
    "#     opt_offset = testdata.node_feature[\"n0\"][:,-2:-1,1:3].clone()\n",
    "\n",
    "#     mask_list = []\n",
    "#     for i in range(62*62):\n",
    "#         if opt_mask.flatten()[i] == 1:\n",
    "#             mask_list.append([[0.99]])\n",
    "#         else:    \n",
    "#             mask_list.append([[0.01]])\n",
    "#     soft_opt_mask = torch.tensor(mask_list, device=opt_mask.device).reshape(opt_mask.shape)\n",
    "#     soft_opt_mask.requires_grad = True\n",
    "\n",
    "#     cat_opt_mask = torch.concat([opt_mask, opt_offset], -1)\n",
    "#     static_grid = torch.concat([cat_opt_mask for _ in range(4)], -2)\n",
    "#     opt_dynamic_features = torch.clamp(testdata.node_feature[\"n0\"][:,:,3:].detach().clone() + torch.randn([62*62, 4, 3], device=opt_mask.device), -1, 1)\n",
    "#     dynamic_features = opt_dynamic_features #.clone()\n",
    "\n",
    "#     # testdata.node_feature[\"n0\"] = torch.concat([static_grid, dynamic_features], -1)\n",
    "#     testdata.node_feature[\"n0\"] = torch.cat([static_grid, dynamic_features], dim=-1)\n",
    "#     static_data.node_feature[\"n0\"] = static_grid\n",
    "    \n",
    "#     # prerollout = 36\n",
    "#     stds = torch.where(opt_offset==1, 0.01, 0.01)\n",
    "#     stds_dynamic = torch.full(dynamic_features.shape, 0.01, device=opt_mask.device)\n",
    "#     # print(stds_dynamic)\n",
    "\n",
    "#     optimizer_mask = torch.optim.Adam([soft_opt_mask], lr=0.001)        \n",
    "\n",
    "#     list_force = []\n",
    "#     list_drag_force = []\n",
    "#     for oiter in range(optim_iter):\n",
    "#         total_x_force = 0\n",
    "#         total_y_force = 0\n",
    "\n",
    "#         candidate_boundaries_offset = []\n",
    "#         candidate_boundaries_mask = []\n",
    "#         candidate_dynamics = []\n",
    "#         candidate_xforces = []\n",
    "#         candidate_yforces = []\n",
    "#         scores = []\n",
    "\n",
    "#         if oiter == (optim_iter - 1):\n",
    "#             force_list = []\n",
    "#         ### CEM Loop ###\n",
    "#         # pdb.set_trace()\n",
    "#         for s in range(num_sample):\n",
    "#             # testdata = data.clone()\n",
    "\n",
    "#             # Generate random sample for offset\n",
    "#             clamp_soft_opt_mask = torch.clamp(soft_opt_mask, 0, 1)\n",
    "#             perturbed_boundary_mask = torch.bernoulli(clamp_soft_opt_mask)\n",
    "#             candidate_boundaries_mask.append(perturbed_boundary_mask)\n",
    "#             perturbed_boundary_offset = torch.normal(mean=opt_offset, std=stds)\n",
    "#             candidate_boundaries_offset.append(perturbed_boundary_mask)\n",
    "#             perturbed_dynamics = torch.clamp(torch.normal(mean=opt_dynamic_features, std=stds_dynamic), -1, 1)\n",
    "#             candidate_dynamics.append(perturbed_dynamics[...,None])\n",
    "            \n",
    "#             #Update boundary feature\n",
    "#             perturbed_mask = torch.concat([perturbed_boundary_mask, perturbed_boundary_offset], -1)\n",
    "#             static_grid = perturbed_mask.repeat(1, 4, 1)\n",
    "#             # static_grid = torch.concat([perturbed_mask for _ in range(4)], -2)\n",
    "#             # dynamic_features = testdata.node_feature[\"n0\"][:,:,3:].detach().clone()\n",
    "        \n",
    "#             testdata.node_feature[\"n0\"] = torch.concat([static_grid, perturbed_dynamics], -1)\n",
    "#             static_data.node_feature[\"n0\"] = static_grid\n",
    "\n",
    "#             # with torch.enable_grad():\n",
    "#             ### Perform rollout ###\n",
    "#             total_x_force = 0\n",
    "#             total_y_force = 0\n",
    "#             final_objective = 0\n",
    "#             for kk in range(prerollout+one_period):\n",
    "#                 if kk < prerollout:\n",
    "#                     testdata, _ = get_data_next_step_with_static(model_lepde, testdata, static_data, use_grads=False, return_data=True, is_y_diff=False, is_rollout=True)\n",
    "#                     # raw_bound = (((testdata.param[\"n0\"].reshape(40,2)/2) + 0.5) * 62) + 0\n",
    "#                 # if kk == prerollout:\n",
    "#                 #     length, nx, ny, cen = compute_orthonormal(raw_bound)\n",
    "#                     # cen = cen.to(device)       \n",
    "#                 elif kk >= prerollout:\n",
    "#                     testdata, pred = get_data_next_step_with_static(model_lepde, testdata, static_data, use_grads=False, return_data=True, is_y_diff=False, is_rollout=True)\n",
    "#                     input_press = torch.clamp(((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,-1:])/2) + 0.5) * (p_max-p_min)) + p_min, -1, 1)\n",
    "\n",
    "#                     input_node_feature = torch.cat([input_press, cat_opt_mask.reshape(62, 62, 1, 3)], -1).reshape(62, 62, 1, -1)\n",
    "#                     input_node_feature = torch.permute(input_node_feature, (2, 3, 0, 1))\n",
    "#                     data_pad = torch.zeros(1, 4, 64, 64).to(input_node_feature.device)\n",
    "#                     data_pad[ :, :, 1:-1, 1:-1] = input_node_feature\n",
    "#                     input_node_feature = data_pad\n",
    "                    \n",
    "#                     # print(data_pad)\n",
    "#                     # print(input_node_feature)\n",
    "#                     # with torch.no_grad():\n",
    "#                     #     x_force, y_force = force_model(input_node_feature)[0]\n",
    "#                     # x_force, y_force = compute_pressForce(torch.nn.functional.pad(press, (1,3,1,3)), raw_bound)                \n",
    "#                     # final_objective += -1/x_force + 10 * torch.square(-7.5*one_period - y_force)\n",
    "#                     total_x_force += x_force\n",
    "#                     total_y_force += y_force\n",
    "                    \n",
    "#                     del data_pad\n",
    "#                     del input_node_feature\n",
    "#                     torch.cuda.empty_cache()\n",
    "                    \n",
    "#             total_x_force = total_x_force/one_period\n",
    "#             total_y_force = total_y_force/one_period\n",
    "            \n",
    "#             candidate_xforces.append(total_x_force)\n",
    "#             candidate_yforces.append(total_y_force)\n",
    "            \n",
    "#             scores.append(lamb * total_x_force + total_y_force)\n",
    "\n",
    "#         index = torch.argsort(torch.tensor(scores))\n",
    "\n",
    "#         # pdb.set_trace()\n",
    "#         ### Select elite samples and compute next mean and variance ###\n",
    "#         elites_mask = torch.cat(candidate_boundaries_mask, dim=1)[:, index, :][:, :num_elite, :]\n",
    "#         for _ in range(optim_iter_mask):\n",
    "#             # print(\"log min and max: \", soft_opt_mask.min(), soft_opt_mask.max())\n",
    "#             output_mask = (1/num_elite) * (-torch.log(torch.cat([clamp_soft_opt_mask for _ in range(num_elite)], dim=1)[elites_mask==1]).sum() - torch.log(1 - torch.cat([clamp_soft_opt_mask for _ in range(num_elite)], dim=1)[elites_mask==0]).sum())\n",
    "#             optimizer_mask.zero_grad()\n",
    "#             output_mask.backward()\n",
    "#             optimizer_mask.step()\n",
    "#             clamp_soft_opt_mask = torch.clamp(soft_opt_mask, 0, 1)\n",
    "#             del output_mask\n",
    "#             torch.cuda.empty_cache()\n",
    "\n",
    "#         # pdb.set_trace()\n",
    "#         ### Smooth mean and variance ###\n",
    "#         elites_offset = torch.cat(candidate_boundaries_offset, dim=1)[:, index, :][:, :num_elite, :]\n",
    "#         next_mean = torch.mean(elites_offset, dim=1, keepdim=True)\n",
    "#         next_vari = torch.var(elites_offset, dim=1, correction=0, keepdim=True)\n",
    "#         opt_offset = smoothing_coef * torch.clamp(next_mean, -0.5, 0.5) + (1 - smoothing_coef) * opt_offset\n",
    "#         stds = smoothing_coef * next_vari + (1 - smoothing_coef) * stds\n",
    "\n",
    "#         # pdb.set_trace()\n",
    "#         elites_dynamic = torch.cat(candidate_dynamics, dim=-1)[...,index][...,:num_elite]\n",
    "#         next_mean_dynam = torch.mean(elites_dynamic, dim=-1, keepdim=True)\n",
    "#         next_vari_dynam = torch.var(elites_dynamic, dim=-1, correction=0, keepdim=True)\n",
    "#         opt_dynamic_features = smoothing_coef * torch.clamp(next_mean_dynam[...,0], -1, 1) + (1 - smoothing_coef) * opt_dynamic_features\n",
    "#         stds_dynamic = smoothing_coef * next_vari_dynam[...,0] + (1 - smoothing_coef) * stds_dynamic\n",
    "\n",
    "#         # pdb.set_trace()\n",
    "#         # Generate random sample for offset\n",
    "#         # pdb.set_trace()\n",
    "#         opt_mask = torch.bernoulli(clamp_soft_opt_mask)\n",
    "#         opt_offset = torch.normal(mean=opt_offset, std=stds)\n",
    "#         opt_dynamic_features = torch.normal(mean=opt_dynamic_features, std=stds_dynamic)\n",
    "\n",
    "#         #Update boundary feature\n",
    "#         cat_opt_mask = torch.concat([opt_mask, opt_offset], -1)\n",
    "#         static_grid = torch.concat([cat_opt_mask for _ in range(4)], -2)\n",
    "#         # dynamic_features = evaldata.node_feature[\"n0\"][:,:,3:]\n",
    "#         evaldata = data.clone()\n",
    "#         evaldata.node_feature[\"n0\"] = torch.cat([static_grid, opt_dynamic_features], dim=-1)\n",
    "#         static_data.node_feature[\"n0\"] = static_grid\n",
    "#         # evaldata=evaldata.clone()\n",
    "\n",
    "#         # pdb.set_trace()\n",
    "#         ### Perform evaluation with updated boundary  ###\n",
    "#         for kk in range(prerollout+one_period):\n",
    "#             if kk < prerollout:\n",
    "#                 # pdb.set_trace()            \n",
    "#                 evaldata, pred = get_data_next_step_with_static(model_lepde, evaldata, static_data, use_grads=False, return_data=True, is_y_diff=False, is_rollout=True)\n",
    "#                 # press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "#                 # raw_bound = (((evaldata.param[\"n0\"].reshape(40,2)/2) + 0.5) * 62) + 0\n",
    "# #             if kk == prerollout:\n",
    "# #                 # pdb.set_trace()            \n",
    "# #                 length, nx, ny, cen = compute_orthonormal(raw_bound)\n",
    "# #                 # cen = cen.to(device)       \n",
    "#             if kk >= prerollout:\n",
    "#                 # pdb.set_trace()            \n",
    "#                 evaldata, pred = get_data_next_step_with_static(model_lepde, evaldata, static_data, use_grads=False, return_data=True, is_y_diff=False, is_rollout=True)\n",
    "#                 if oiter == optim_iter - 1:\n",
    "#                     try:    \n",
    "#                         os.makedirs(\"./optimized_traj_lepde_CEM/sim_{:06d}\".format(datanum))\n",
    "#                     except Exception:\n",
    "#                         pass   \n",
    "#                     with open('./optimized_traj_lepde_CEM/sim_{:06d}/feature_{:06d}.npy'.format(datanum, kk), 'wb') as f:\n",
    "#                         np.save(f, evaldata.node_feature[\"n0\"].detach().cpu().numpy())\n",
    "\n",
    "#                 input_press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,-1:])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "#                 input_node_feature = torch.cat([input_press, cat_opt_mask.reshape(62, 62, 1, 3)], -1).reshape(62, 62, 1, -1)\n",
    "#                 input_node_feature = torch.permute(input_node_feature, (2, 3, 0, 1))\n",
    "#                 data_pad = torch.zeros(1, 4, 64, 64).to(input_node_feature.device)\n",
    "#                 data_pad[ :, :, 1:-1, 1:-1] = input_node_feature\n",
    "#                 input_node_feature = data_pad\n",
    "#                 del data_pad\n",
    "                \n",
    "#                 with torch.no_grad():\n",
    "#                     x_force, y_force = force_model(input_node_feature)[0]\n",
    "#                 # press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "#                 # # lin_press = linear_transform(torch.nn.functional.pad(press, (1,3,1,3)), cen)\n",
    "#                 # x_force, y_force = compute_pressForce(torch.nn.functional.pad(press, (1,3,1,3)), raw_bound)\n",
    "#                 # ### Need to update, object should be defined here ###\n",
    "#                 if oiter == optim_iter - 1:\n",
    "#                     force_list.append(torch.stack([x_force, y_force], - 1))                    \n",
    "                \n",
    "#                 total_x_force += x_force\n",
    "#                 total_y_force += y_force\n",
    "                \n",
    "#                 del input_node_feature\n",
    "#                 torch.cuda.empty_cache()\n",
    "#                 # print(data_pad)\n",
    "\n",
    "#         # elite_xforces = torch.stack(candidate_xforces, dim=-1)[...,index][...,:num_elite]\n",
    "#         # total_x_force = torch.mean(elite_xforces, dim=-1, keepdim=True)[...,0]\n",
    "#         # elite_yforces = torch.stack(candidate_yforces, dim=-1)[...,index][...,:num_elite]\n",
    "#         # total_y_force = torch.mean(elite_yforces, dim=-1, keepdim=True)[...,0]\n",
    "#         # if oiter == optim_iter - 1:\n",
    "#         #     with open(\"./optimized_traj_lepde_CEM/sim_{:06d}/raw_force.npy\".format(datanum), 'wb') as f:\n",
    "#         #         np.save(f, torch.stack(force_list, 0).detach().cpu().numpy())    \n",
    "\n",
    "#         total_x_force = total_x_force/one_period\n",
    "#         total_y_force = total_y_force/one_period\n",
    "\n",
    "#         list_force.append(-total_y_force.item())\n",
    "#         list_drag_force.append(total_x_force.item())\n",
    "\n",
    "\n",
    "#         ### Visualization of updated boundary \"\"\"\n",
    "#         if oiter % 50 == 49:\n",
    "#     #     if True:\n",
    "#             print(\"iteration: \", oiter)\n",
    "#     #         bound = torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:].reshape(40,2)\n",
    "#     #         bd = (((bound.detach().cpu().numpy()/2) + 0.5) * 62) + 0        \n",
    "#     #         length, nx, ny, cen = compute_orthonormal(torch.tensor(bd))\n",
    "\n",
    "#             fig, ax = plt.subplots(figsize=(18,3), ncols=6)\n",
    "#     #         mappable0 = ax[0].plot(bd[:,0], bd[:,1])\n",
    "#     #         nx = nx.detach().cpu()\n",
    "#     #         ny = ny.detach().cpu()\n",
    "#     #         cen = cen.detach().cpu()\n",
    "#     #         lin_press = lin_press.cpu()\n",
    "#     #         normals = torch.stack((lin_press*nx,lin_press*ny), -1)#.to(device)\n",
    "#     #         for i in range(40):\n",
    "#     #             rel_normals = cen[i,:] + normals[i,:]\n",
    "#     #             ax[0].plot((cen[i,0].numpy(), rel_normals[0].detach().numpy()), (cen[i,1].numpy(), rel_normals[1].detach().numpy()))\n",
    "#     #         ax[0].set_xlim(24, 35)\n",
    "#     #         ax[0].set_ylim(32, 43)\n",
    "#             mappable1 = ax[1].imshow(evaldata.node_feature[\"n0\"][:,-1,0].reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "#                                      aspect='auto',\n",
    "#                                      origin='lower')\n",
    "#             vis_offsetmask = torch.where(evaldata.node_feature[\"n0\"][:,-1,1]!=0, 1, 0)\n",
    "#             mappable2 = ax[2].imshow(vis_offsetmask.reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "#                                      aspect='auto',\n",
    "#                                      origin='lower')        \n",
    "#             mappable3 = ax[3].imshow(evaldata.node_feature[\"n0\"][:,-1,0].reshape(62,62).detach().cpu().numpy()-vis_offsetmask.reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "#                                      aspect='auto',\n",
    "#                                      origin='lower')        \n",
    "#             mappable4 = ax[4].plot(np.array(list_force)[0::5])\n",
    "#             mappable5 = ax[5].plot(np.array(list_drag_force)[0::5])\n",
    "#              # pdf.savefig()\n",
    "#             plt.show()\n",
    "\n",
    "\n",
    "#     # pdf.close()\n",
    "#     force_ratio.append(total_y_force/total_x_force)\n",
    "#     print(total_y_force/total_x_force)\n",
    "#     # pdf.close()\n",
    "    \n",
    "#     del data\n",
    "#     torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "#     # with open('./optimized_boundary_lepde_CEM/boundary_{:06d}.npy'.format(datanum), 'wb') as f:\n",
    "#     #     np.save(f, evaldata.node_feature[\"n0\"][:,-1,:3].detach().cpu().numpy())\n",
    "    \n",
    "#     datanum += 1\n",
    "    \n",
    "# print(force_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13010f67-b82b-4c60-b13d-97a21212ff41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58817110-6aa4-4dd8-ba2e-66581c07f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"Finish inverse design with CEM x LEPDE!\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f7a8f4-984e-4c11-aa2a-8d16ace143bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e071fe-0e60-4ce0-91fc-9db531573641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lepde",
   "language": "python",
   "name": "lepde"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
