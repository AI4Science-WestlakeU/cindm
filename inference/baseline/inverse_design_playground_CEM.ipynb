{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41481747-0049-4511-b512-df8489041673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import OrderedDict\n",
    "import datetime\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pylab as plt\n",
    "from numbers import Number\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "pd.options.display.max_rows = 1500\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.width = 1000\n",
    "pd.set_option('max_colwidth', 400)\n",
    "import pdb\n",
    "import pickle\n",
    "import pprint as pp\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from deepsnap.batch import Batch as deepsnap_Batch\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..', '..'))\n",
    "from le_pde.argparser import arg_parse\n",
    "from le_pde.datasets.load_dataset import load_data\n",
    "from le_pde.models import load_model\n",
    "from le_pde.pytorch_net.util import groupby_add_keys, filter_df, get_unique_keys_df, Attr_Dict, Printer, get_num_params, get_machine_name, pload, pdump, to_np_array, get_pdict, reshape_weight_to_matrix, ddeepcopy as deepcopy, plot_vectors, record_data, filter_filename, Early_Stopping, str2bool, get_filename_short, print_banner, plot_matrices, get_num_params, init_args, filter_kwargs, to_string, COLOR_LIST\n",
    "from le_pde.utils import update_legacy_default_hyperparam, EXP_PATH, deepsnap_to_pyg, LpLoss, to_cpu, to_tuple_shape, parse_multi_step, loss_op, get_device, get_data_next_step\n",
    "from utils import compute_pressForce\n",
    "#from le_pde.utils import deepsnap_to_pyg, LpLoss, to_cpu, to_tuple_shape, parse_multi_step, loss_op, get_device, get_data_next_step\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "p = Printer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34edf99f-9265-45b0-906d-650e4261dc77",
   "metadata": {},
   "source": [
    "## 1. Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67193e7b-5777-4aac-9426-f91e6837d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(data_record):\n",
    "    x_axis = np.arange(len(data_record[\"train_loss\"]))\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(x_axis, data_record[\"train_loss\"], label=\"train\")\n",
    "    plt.plot(x_axis, data_record[\"val_loss\"], label=\"val\")\n",
    "    plt.plot(x_axis, data_record[\"test_loss\"], label=\"test\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.semilogy(x_axis, data_record[\"train_loss\"], label=\"train\")\n",
    "    plt.semilogy(x_axis, data_record[\"val_loss\"], label=\"val\")\n",
    "    plt.semilogy(x_axis, data_record[\"test_loss\"], label=\"test\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4494e7-afaf-4d55-a1fc-b32168ca62b5",
   "metadata": {},
   "source": [
    "## 2. Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a74011e-cb80-444a-ae95-6f29d830193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_PATH = \"./results/\"\n",
    "\n",
    "isplot = True\n",
    "all_hash = [\n",
    "    \"clnAWVnz_hyperturing1\",\n",
    "]\n",
    "hash_str = all_hash[0]\n",
    "dirname = EXP_PATH + \"naca_ellipse_2023-06-02/\"\n",
    "filename = filter_filename(dirname, include=hash_str)\n",
    "if len(filename) == 0:\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    data_record = pload(dirname + filename[0])\n",
    "except Exception as e:\n",
    "    print(f\"error {e}\")\n",
    "    # continue\n",
    "    raise\n",
    "if isplot:\n",
    "    plot_learning_curve(data_record)\n",
    "args = init_args(update_legacy_default_hyperparam(data_record[\"args\"]))\n",
    "args.filename = filename\n",
    "model = load_model(data_record[\"model_dict\"][-1], device=device)\n",
    "model.eval()\n",
    "p.print(filename, banner_size=100)\n",
    "\n",
    "# Load test dataset:\n",
    "args_test = deepcopy(args)\n",
    "if args.temporal_bundle_steps == 1:\n",
    "    if args.dataset in [\"fno\", \"fno-2\", \"fno-3\"]:\n",
    "        args_test.multi_step = \"20\"\n",
    "    elif args.dataset in [\"fno-1\"]:\n",
    "        args_test.multi_step = \"40\"\n",
    "    elif args.dataset in [\"fno-4\"]:\n",
    "        args_test.multi_step = \"10\"\n",
    "    elif args.dataset in [\"naca_ellipse_lepde\"]:\n",
    "        args_test.multi_step = \"1\"\n",
    "        args_test.latent_multi_step=\"1\"\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    pass\n",
    "args_test.batch_size = 1\n",
    "args_test.is_test_only=True\n",
    "\n",
    "(dataset_train_val, dataset_test), (train_loader, val_loader, test_loader) = load_data(args_test)\n",
    "test_loader = DataLoader(dataset_test, num_workers=0, collate_fn=deepsnap_Batch.collate(),\n",
    "                         batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749c5974-4afc-41b3-9d23-b174133f43d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "for data in test_loader:\n",
    "    # if i == 1900:\n",
    "    # if i == 2500:\n",
    "    if i == 1200:\n",
    "    # if i == 0:\n",
    "    # if i == 400:\n",
    "        break\n",
    "    i+=1\n",
    "\n",
    "    if i%100 == 0:\n",
    "        fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "        bd = (((data.param[\"n0\"].detach().cpu().numpy()/2) + 0.5) * 62) + 0\n",
    "        mappable0 = ax.plot(bd[0,0::2], bd[0,1::2])\n",
    "        ax.set_xlim(0, 62)\n",
    "        ax.set_ylim(0, 62)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8656e5-40e6-4649-9930-8ec3b0b346e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to(device)        \n",
    "testdata = data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13c71e6-2162-4dfe-afa0-e950c7ba9482",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 64; n=64\n",
    "maxnum = 100\n",
    "\n",
    "def discretize_boundary(boundary):\n",
    "    assert boundary.shape[1] == 2\n",
    "    num_bound = boundary.shape[0]\n",
    "    device = boundary.device\n",
    "    p_5 = torch.tensor([0.5], device=device).repeat(num_bound)\n",
    "    x = torch.minimum(torch.maximum(boundary[:, 0], p_5), torch.tensor([n-1.5], device=device).repeat(num_bound))\n",
    "    x_inds = torch.minimum(x.type(torch.int32), torch.tensor([n-2], device=device).repeat(num_bound))\n",
    "\n",
    "    y = torch.minimum(torch.maximum(boundary[:, 1], p_5), torch.tensor([m-1.5], device=device).repeat(num_bound))\n",
    "    y_inds = torch.minimum(y.type(torch.int32), torch.tensor([m-2], device=device).repeat(num_bound))\n",
    "    return x_inds, y_inds\n",
    "\n",
    "def find_orthogonal_line(A, B, C, x0, y0):\n",
    "    m1 = torch.empty((C.shape[0],), device=C.device)\n",
    "    m1[B==0] = float('inf')\n",
    "    m1[B!=0] = (-A/B)[B!=0]\n",
    "\n",
    "    m2 = torch.empty((C.shape[0],), device=C.device)\n",
    "    m2[m1==float('inf')] = 0\n",
    "    m2[m1!=float('inf')] = (-1 / m1)[m1!=float('inf')]\n",
    "\n",
    "    b2 = y0 - m2 * x0  # The y-intercept of L2.\n",
    "\n",
    "    # Return the coefficients A, B, C of the line L2 (Ax + By - C = 0)\n",
    "    return m2, -1, b2\n",
    "\n",
    "def edge_cells(polygon):\n",
    "    num_vertices = len(polygon)\n",
    "    edges = []\n",
    "    for i in range(num_vertices):\n",
    "        v1 = polygon[i]\n",
    "        v2 = polygon[(i + 1) % num_vertices]\n",
    "        edge = sorted([v1, v2], key=lambda x: x[1])\n",
    "        edges.append(edge)\n",
    "    return edges\n",
    "\n",
    "def find_cells_inside_curve(polygon, grid_shape):\n",
    "    def horizontal_intersection(x1, y1, x2, y2, y):\n",
    "        return x1 + (y - y1) * (x2 - x1) / (y2 - y1)\n",
    "    edges = edge_cells(polygon)\n",
    "    grid = np.zeros(grid_shape, dtype=np.uint8)\n",
    "    height, width = grid.shape\n",
    "    \n",
    "    for y in range(height):\n",
    "        intersections = []\n",
    "        for edge in edges:\n",
    "            y1, y2 = edge[0][1], edge[1][1]\n",
    "            if y1 < y <= y2:\n",
    "                x = horizontal_intersection(*edge[0], *edge[1], y)\n",
    "                intersections.append(x)\n",
    "        intersections.sort()\n",
    "        for i in range(0, len(intersections), 2):\n",
    "            x_start, x_end = int(np.ceil(intersections[i])), int(np.floor(intersections[i + 1]))\n",
    "            grid[y, x_start : x_end + 1] = 1\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab1ba61-bf2e-4402-944b-47ec71449ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_static_masks(torch_con_boundary):\n",
    "    x_inds, y_inds = discretize_boundary(torch_con_boundary)\n",
    "    pointy_hash = maxnum*x_inds[20] + y_inds[20]\n",
    "\n",
    "    indices = torch.stack((maxnum*x_inds,y_inds), 0)\n",
    "    sum_indices = indices.sum(0)\n",
    "    ind_unique = torch.unique(sum_indices, sorted=True) #, return_inverse=True)\n",
    "    x_idx = (torch.cat([(sum_indices==ind_u).nonzero()[0] for ind_u in ind_unique])).sort()[0]\n",
    "    repeat_sum_indices = torch.tile(sum_indices, (ind_unique.shape[0],1))\n",
    "    repeat_ind_unique = torch.tile(sum_indices[x_idx].reshape(ind_unique.shape[0], 1), (1, sum_indices.shape[0]))\n",
    "    org_mask = (repeat_ind_unique == repeat_sum_indices)\n",
    "    fatted_mask = torch.roll(org_mask, 1, 1) + torch.roll(org_mask, -1, 1)\n",
    "\n",
    "    relvecs = []\n",
    "    base_pts = []\n",
    "    base_nums = []\n",
    "    for bdpt in range(sum_indices[x_idx].shape[0]):\n",
    "        if pointy_hash == sum_indices[x_idx][bdpt]:\n",
    "            base_pt = torch.stack([x_inds[org_mask[bdpt]][0], y_inds[org_mask[bdpt]][0]]) + 0.5\n",
    "            base_pts.append(base_pt)\n",
    "            relvec = torch_con_boundary[20] - base_pt\n",
    "            relvecs.append(relvec)\n",
    "        elif torch.sum(org_mask[bdpt]) >= 4:\n",
    "            base_pt = torch.stack([x_inds[org_mask[bdpt]][0], y_inds[org_mask[bdpt]][0]]) + 0.5\n",
    "            base_pts.append(base_pt)\n",
    "            relvec = torch_con_boundary[org_mask[bdpt]] - base_pt.repeat(torch_con_boundary[org_mask[bdpt]].shape[0], 1)\n",
    "            ind = torch.argmin(torch.norm(relvec, dim=1))\n",
    "            relvecs.append(relvec[ind])\n",
    "        elif torch.sum(fatted_mask[bdpt] * torch.logical_not(org_mask[bdpt])) > 2:\n",
    "            base_pt = torch.stack([x_inds[org_mask[bdpt]][0], y_inds[org_mask[bdpt]][0]]) + 0.5\n",
    "            relvec = torch_con_boundary[org_mask[bdpt]] - base_pt.repeat(torch_con_boundary[org_mask[bdpt]].shape[0], 1)\n",
    "            if len(relvec.shape) == 2:\n",
    "                relvecs.append(relvec[-1])\n",
    "                base_pts.append(base_pt)\n",
    "            else:\n",
    "                relvecs.append(relvec)\n",
    "                base_pts.append(base_pt)\n",
    "        elif torch.sum(org_mask[bdpt]) == 1:\n",
    "            base_pt = torch.stack([x_inds[org_mask[bdpt]][0], y_inds[org_mask[bdpt]][0]]) + 0.5\n",
    "            base_pts.append(base_pt)\n",
    "            relvec = torch_con_boundary[org_mask[bdpt]] - base_pt\n",
    "            relvecs.append(relvec[0])\n",
    "        else:    \n",
    "            if fatted_mask[bdpt][0] and fatted_mask[bdpt][-1]:\n",
    "                rollnum = 1\n",
    "                for _ in range(0, 100):\n",
    "                    temprole = torch.roll(fatted_mask[bdpt], rollnum, 0)\n",
    "                    if temprole[0] and temprole[-1]:\n",
    "                        rollnum += 1    \n",
    "                    else:\n",
    "                        break\n",
    "                x_pts = torch.roll(torch_con_boundary[fatted_mask[bdpt]], rollnum, 0)            \n",
    "            else:\n",
    "                x_pts = torch_con_boundary[fatted_mask[bdpt]]\n",
    "\n",
    "            bd_points = torch.cat([x_pts[0:1], x_pts[1:-1].repeat(1, 2).reshape(-1,2), x_pts[-1:]], dim=0)\n",
    "            dire_vec = bd_points[0::2] - bd_points[1::2]\n",
    "            const = bd_points[0::2, 1] - bd_points[0::2, 0] * dire_vec[:,1]/dire_vec[:,0]\n",
    "\n",
    "            base_pt = torch.stack([x_inds[org_mask[bdpt]][0], y_inds[org_mask[bdpt]][0]]) + 0.5\n",
    "            base_pts.append(base_pt)\n",
    "            base_points = base_pt.repeat(const.shape[0], 1)\n",
    "            slope = dire_vec[:,1]/dire_vec[:,0]\n",
    "            ax, by, con = find_orthogonal_line(slope, -torch.ones((const.shape[0],), device=torch_con_boundary.device), const, base_points[:,0], base_points[:,1])\n",
    "\n",
    "            al = -ax/by\n",
    "            bl = con\n",
    "            cl = dire_vec[:,1]/dire_vec[:,0]\n",
    "            dl = const\n",
    "\n",
    "            intersection = torch.stack([(dl - bl)/(al - cl), (al*dl - bl*cl)/(al - cl)]).t()\n",
    "\n",
    "            relvec = intersection - torch.tile(base_pt, (intersection.shape[0], 1))\n",
    "            relvecs.append(relvec.sum(0)/relvec.shape[0])\n",
    "\n",
    "    ### Check number of offset vectors is same as that of boundary cells of solid\n",
    "    assert len(base_pts) == sum_indices[x_idx].shape[0]\n",
    "    \n",
    "    bd_offset = torch.stack(relvecs)\n",
    "    offset_grid_bound = torch.zeros((62, 62, 2), device=torch_con_boundary.device)\n",
    "    offset_grid_bound[x_inds, y_inds] = torch.tensor([1, 1], dtype=torch.float32, device=torch_con_boundary.device)\n",
    "    offset_grid_bound = offset_grid_bound.transpose(1,0)\n",
    "\n",
    "    offset_grid = find_cells_inside_curve(torch.stack((x_inds, y_inds), -1).detach().cpu().tolist(), (62, 62))\n",
    "    inner_solid_mask = np.copy(offset_grid)\n",
    "    offset_grid = offset_grid.reshape(62, 62, 1)\n",
    "    offset_grid = np.concatenate([offset_grid, offset_grid], -1)\n",
    "\n",
    "    offset_union = offset_grid_bound + torch.tensor(offset_grid, device=torch_con_boundary.device)\n",
    "    offset_union[(offset_union.sum(-1) > 2),:] = torch.tensor([1, 1], dtype=torch.float32, device=torch_con_boundary.device)\n",
    "    offset_union.index_put_((y_inds[x_idx], x_inds[x_idx]), bd_offset)    \n",
    "\n",
    "    grid_bound = torch.zeros((62, 62), device=torch_con_boundary.device)\n",
    "    grid_bound[x_inds, y_inds] = 1\n",
    "    union = grid_bound.transpose(1,0) + torch.tensor(inner_solid_mask, device=torch_con_boundary.device)\n",
    "    union[union == 2] = 1\n",
    "\n",
    "    updated_solid_mask = union\n",
    "    \n",
    "    return updated_solid_mask, offset_union "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcef5c0-42a4-400a-a1b5-42bd157589a7",
   "metadata": {},
   "source": [
    "## 3. inverse optimization with FNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf5d697-782d-43ed-9d1b-0330c7e07ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "isplot = True\n",
    "all_hash = [\n",
    "    #\"Yirzlp+j_ampere4\",\n",
    "    \"clnAWVnz_hyperturing1\",\n",
    "]\n",
    "hash_str = all_hash[0]\n",
    "dirname = EXP_PATH + \"naca_ellipse_2023-06-02/\"\n",
    "filename = filter_filename(dirname, include=hash_str)\n",
    "if len(filename) == 0:\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    data_record = pload(dirname + filename[0])\n",
    "except Exception as e:\n",
    "    print(f\"error {e}\")\n",
    "    raise\n",
    "if isplot:\n",
    "    plot_learning_curve(data_record)\n",
    "args = init_args(update_legacy_default_hyperparam(data_record[\"args\"]))\n",
    "args.filename = filename\n",
    "model_fno = load_model(data_record[\"model_dict\"][-1], device=device)\n",
    "model_fno.eval()\n",
    "p.print(filename, banner_size=100)\n",
    "\n",
    "# Load test dataset:\n",
    "args_test = deepcopy(args)\n",
    "if args.temporal_bundle_steps == 1:\n",
    "    if args.dataset in [\"fno\", \"fno-2\", \"fno-3\"]:\n",
    "        args_test.multi_step = \"20\"\n",
    "    elif args.dataset in [\"fno-1\"]:\n",
    "        args_test.multi_step = \"40\"\n",
    "    elif args.dataset in [\"fno-4\"]:\n",
    "        args_test.multi_step = \"10\"\n",
    "    elif args.dataset in [\"naca_ellipse_lepde\"]:\n",
    "        args_test.multi_step = \"1\"\n",
    "        args_test.latent_multi_step=\"1\"\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    pass\n",
    "args_test.batch_size = 1\n",
    "args_test.is_test_only=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e012d-ad9b-46e1-9be5-3207af8a002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_filename = os.path.join(\"./dataset/naca_ellipse/training_trajectories/\", \"normalization_max_min.p\")\n",
    "normdict = pickle.load(open(normalization_filename, \"rb\"))\n",
    "x_max = normdict[\"x_max\"]\n",
    "x_min = normdict[\"x_min\"]\n",
    "y_max = normdict[\"y_max\"]\n",
    "y_min = normdict[\"y_min\"]\n",
    "p_max = normdict[\"p_max\"]\n",
    "p_min = normdict[\"p_min\"]\n",
    "p_max = p_max.to(device)\n",
    "p_min = p_min.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38aded-ebe8-4906-8822-1ea7862752f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from utils import compute_orthonormal, linear_transform, compute_pressForce, compute_orthonormal\n",
    "\n",
    "def update_bdfeature (reconstructed_boundary):\n",
    "    upd_solid_mask, upd_solid_offset = update_static_masks(reconstructed_boundary)\n",
    "    torch_batch_mask = torch.where(upd_solid_mask==1, False, True).clone().flatten()\n",
    "    upd_solid_mask = upd_solid_mask[...,None]\n",
    "    static_feature = torch.cat((upd_solid_mask, upd_solid_offset), -1)\n",
    "    multi_static_feat = torch.stack([static_feature for _ in range(4)], -2).reshape(-1,4,3)\n",
    "    return multi_static_feat, torch_batch_mask\n",
    "\n",
    "# Hyper parameter for CEM\n",
    "\n",
    "\n",
    "orgdata = data.clone()\n",
    "testdata = data.clone()\n",
    "const_variable = testdata.param[\"n0\"][:,0::2].detach().clone()\n",
    "opt_variable = testdata.param[\"n0\"][:,1::2].detach().clone()\n",
    "opt_variable.requires_grad=False\n",
    "\n",
    "### Best configuration so far ###\n",
    "# num_elite = 2\n",
    "# num_sample = 20\n",
    "# smoothing_coef = 0.01\n",
    "\n",
    "# optim_iter = 1000\n",
    "# # prerollout = 36\n",
    "# prerollout = 20\n",
    "# one_period = 4\n",
    "# vis_prerollout = False\n",
    "# stds = torch.tensor([0.5 for _ in range(40)], device=opt_variable.device).reshape(40, 1)\n",
    "###\n",
    "\n",
    "num_elite = 2\n",
    "num_sample = 30\n",
    "smoothing_coef = 0.001\n",
    "\n",
    "optim_iter = 3000\n",
    "# prerollout = 36\n",
    "prerollout = 20\n",
    "one_period = 4\n",
    "vis_prerollout = False\n",
    "stds = torch.tensor([2 for _ in range(40)], device=opt_variable.device).reshape(40, 1)\n",
    "\n",
    "\n",
    "\n",
    "testdata.param[\"n0\"] = torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9912b7d-a3df-4680-aff9-d94ef29f0778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot initial boundary\n",
    "fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "bd = testdata.param[\"n0\"].reshape(40,2).detach().cpu().numpy()\n",
    "bd = (((bd/2) + 0.5) * 62) + 0\n",
    "mappable0 = ax.plot(bd[:,0], bd[:,1])\n",
    "ax.set_xlim(0, 62)\n",
    "ax.set_ylim(0, 62)\n",
    "plt.show()\n",
    "\n",
    "# Visualize input pressure\n",
    "fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "ax.imshow(testdata.node_feature[\"n0\"][:,-1,-1].reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "         aspect='auto',\n",
    "         origin='lower')\n",
    "plt.show()\n",
    "\n",
    "# Plot initial boundary with normal vectors\n",
    "fig, ax = plt.subplots(figsize=(8,8), ncols=1)\n",
    "length, nx, ny, cen = compute_orthonormal(torch.tensor(bd))\n",
    "rec_press = ((((testdata.node_label[\"n0\"][:,-1,-1].reshape(62,62)/2) + 0.5) * (p_max-p_min)) + p_min).detach().cpu()\n",
    "lin_press = linear_transform(torch.nn.functional.pad(rec_press, (1,3,1,3)), cen) #* (-1)\n",
    "mappable0 = ax.plot(bd[:,0], bd[:,1])\n",
    "normals = torch.stack((lin_press*nx,lin_press*ny), -1)\n",
    "for i in range(40):\n",
    "    rel_normals = cen[i,:] + normals[i,:]\n",
    "    ax.plot((cen[i,0], rel_normals[0]), (cen[i,1], rel_normals[1]))\n",
    "ax.set_xlim(24, 35)\n",
    "ax.set_ylim(32, 43)\n",
    "plt.show()\n",
    "\n",
    "pdf = PdfPages('./optimized_naca_fno_CEM.pdf')\n",
    "list_force = []\n",
    "list_drag_force = []\n",
    "for oiter in range(optim_iter):\n",
    "    total_x_force = 0\n",
    "    total_y_force = 0\n",
    "    \n",
    "\n",
    "    candidate_boundaries = []\n",
    "    scores = []\n",
    "\n",
    "    ### CEM Loop ###\n",
    "    for s in range(num_sample):\n",
    "        # Reconstruct boundary\n",
    "        bound = torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:].reshape(40,2)\n",
    "        rec_bound = (((bound/2) + 0.5) * 62) + 0\n",
    "\n",
    "        # Generate random sample\n",
    "        perturbed_boundary = torch.normal(mean=rec_bound[:,-1:].detach().clone(), std=stds)\n",
    "        candidate_boundaries.append(perturbed_boundary)\n",
    "        rescale_perturbedbd = (torch.clamp((perturbed_boundary - 0) / 62, 0, 1) - 0.5) * 2\n",
    "        rescale_perturbedbd = rescale_perturbedbd.reshape(1, 40)\n",
    "        \n",
    "        #Update boundary feature\n",
    "        rec_bound[:,1] = perturbed_boundary[:,0]\n",
    "        mul_static_feat, tor_batch_mask = update_bdfeature(rec_bound) \n",
    "                \n",
    "        a = deepsnap_Batch\n",
    "        batch, _ = a._init_batch_fields(testdata.keys, [])\n",
    "        batch.batch = testdata.batch.clone()\n",
    "        batch.compute_func = testdata.compute_func\n",
    "        batch.directed = testdata.directed.detach().clone()\n",
    "        batch.dyn_dims = testdata.dyn_dims\n",
    "        batch.edge_attr = testdata.edge_attr\n",
    "        batch.edge_index = {('n0','0','n0'): testdata.edge_index[('n0','0','n0')].detach().clone()}\n",
    "        batch.edge_label_index = {('n0','0','n0'): testdata.edge_label_index[('n0','0','n0')].detach().clone()}\n",
    "        batch.grid_keys = testdata.grid_keys\n",
    "        batch.mask = {\"n0\": tor_batch_mask.detach()}\n",
    "        batch.node_feature = {\"n0\": torch.cat((mul_static_feat, orgdata.node_feature[\"n0\"][...,3:]), -1).detach()}\n",
    "        batch.node_label = {\"n0\": testdata.node_label[\"n0\"].detach().clone()}\n",
    "        batch.node_label_index = {\"n0\": testdata.node_label_index[\"n0\"].detach().clone()}\n",
    "        batch.node_pos = {\"n0\": testdata.node_pos[\"n0\"].detach().clone()}\n",
    "        batch.original_shape = testdata.original_shape\n",
    "        batch.param = {\"n0\": torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:]}\n",
    "        batch.params = testdata.params\n",
    "        batch.part_keys = testdata.part_keys\n",
    "        batch.task = testdata.task\n",
    "        testdata = batch    \n",
    "       \n",
    "        ### Perform rollout ###\n",
    "        final_objective = 0\n",
    "        for kk in range(prerollout+one_period):\n",
    "            if kk < prerollout:\n",
    "                testdata, pred = get_data_next_step(model_fno, testdata, use_grads=False, return_data=True, is_y_diff=False)\n",
    "                raw_bound = (((testdata.param[\"n0\"].reshape(40,2)/2) + 0.5) * 62) + 0\n",
    "            if kk == prerollout:\n",
    "                length, nx, ny, cen = compute_orthonormal(raw_bound)\n",
    "                cen = cen.to(device)       \n",
    "            if kk >= prerollout:\n",
    "                testdata, pred = get_data_next_step(model_fno, testdata, use_grads=False, return_data=True, is_y_diff=False)\n",
    "                press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "                x_force, y_force = compute_pressForce(torch.nn.functional.pad(press, (1,3,1,3)), raw_bound)\n",
    "                final_objective += -1/x_force + 10 * torch.square(-7.5*one_period - y_force)\n",
    "                \n",
    "        scores.append(final_objective.item())\n",
    "                \n",
    "    ### Select elite samples and compute next mean and variance ###\n",
    "    index = torch.argsort(torch.tensor(scores))\n",
    "    elites = torch.cat(candidate_boundaries, dim=1)[:, index][:, :num_elite]\n",
    "    next_mean = torch.mean(elites, dim=1, keepdim=True)\n",
    "    next_vari = torch.var(elites, dim=1, correction=0, keepdim=True)\n",
    "    \n",
    "    ### Smooth mean and variance ###\n",
    "    opt_variable = smoothing_coef * ((torch.clamp((next_mean.reshape(1, 40) - 0) / 62, 0, 1) - 0.5) * 2) + (1 - smoothing_coef) * opt_variable\n",
    "    stds = smoothing_coef * next_vari + (1 - smoothing_coef) * stds\n",
    "    \n",
    "    ### Perform evaluation with updated boundary  ###\n",
    "    tpbound = torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:].reshape(40,2)\n",
    "    rec_tpbound = (((tpbound/2) + 0.5) * 62) + 0\n",
    "    mul_static_feat, tor_batch_mask = update_bdfeature(rec_tpbound) \n",
    "\n",
    "    a = deepsnap_Batch\n",
    "    batch, _ = a._init_batch_fields(testdata.keys, [])\n",
    "    batch.batch = testdata.batch.clone()\n",
    "    batch.compute_func = testdata.compute_func\n",
    "    batch.directed = testdata.directed.detach().clone()\n",
    "    batch.dyn_dims = testdata.dyn_dims\n",
    "    batch.edge_attr = testdata.edge_attr\n",
    "    batch.edge_index = {('n0','0','n0'): testdata.edge_index[('n0','0','n0')].detach().clone()}\n",
    "    batch.edge_label_index = {('n0','0','n0'): testdata.edge_label_index[('n0','0','n0')].detach().clone()}\n",
    "    batch.grid_keys = testdata.grid_keys\n",
    "    batch.mask = {\"n0\": tor_batch_mask.detach()}\n",
    "    batch.node_feature = {\"n0\": torch.cat((mul_static_feat, orgdata.node_feature[\"n0\"][...,3:]), -1).detach()}\n",
    "    batch.node_label = {\"n0\": testdata.node_label[\"n0\"].detach().clone()}\n",
    "    batch.node_label_index = {\"n0\": testdata.node_label_index[\"n0\"].detach().clone()}\n",
    "    batch.node_pos = {\"n0\": testdata.node_pos[\"n0\"].detach().clone()}\n",
    "    batch.original_shape = testdata.original_shape\n",
    "    batch.param = {\"n0\": torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:]}\n",
    "    batch.params = testdata.params\n",
    "    batch.part_keys = testdata.part_keys\n",
    "    batch.task = testdata.task\n",
    "    testdata = batch  \n",
    "\n",
    "    for kk in range(prerollout+one_period):\n",
    "        if kk < prerollout:\n",
    "            testdata, pred = get_data_next_step(model_fno, testdata, use_grads=False, return_data=True, is_y_diff=False)\n",
    "            # press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "            raw_bound = (((testdata.param[\"n0\"].reshape(40,2)/2) + 0.5) * 62) + 0\n",
    "        if kk == prerollout:\n",
    "            length, nx, ny, cen = compute_orthonormal(raw_bound)\n",
    "            cen = cen.to(device)       \n",
    "        if kk >= prerollout:\n",
    "            testdata, pred = get_data_next_step(model_fno, testdata, use_grads=False, return_data=True, is_y_diff=False)\n",
    "            press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "            # lin_press = linear_transform(torch.nn.functional.pad(press, (1,3,1,3)), cen)\n",
    "            x_force, y_force = compute_pressForce(torch.nn.functional.pad(press, (1,3,1,3)), raw_bound)\n",
    "            ### Need to update, object should be defined here ###\n",
    "            total_x_force += x_force\n",
    "            total_y_force += y_force\n",
    "\n",
    "    total_x_force = total_x_force/one_period\n",
    "    total_y_force = total_y_force/one_period\n",
    "            \n",
    "    list_force.append(total_y_force.item())\n",
    "    list_drag_force.append(total_x_force.item())\n",
    "\n",
    "\n",
    "    ### Visualization of updated boundary \"\"\"\n",
    "    if oiter % 10 == 9:\n",
    "        print(\"iteration: \", oiter)\n",
    "        bound = torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:].reshape(40,2)\n",
    "        bd = (((bound.detach().cpu().numpy()/2) + 0.5) * 62) + 0        \n",
    "        length, nx, ny, cen = compute_orthonormal(torch.tensor(bd))\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(18,3), ncols=6)\n",
    "        mappable0 = ax[0].plot(bd[:,0], bd[:,1])\n",
    "        nx = nx.detach().cpu()\n",
    "        ny = ny.detach().cpu()\n",
    "        cen = cen.detach().cpu()\n",
    "        lin_press = lin_press.cpu()\n",
    "        normals = torch.stack((lin_press*nx,lin_press*ny), -1)#.to(device)\n",
    "        for i in range(40):\n",
    "            rel_normals = cen[i,:] + normals[i,:]\n",
    "            ax[0].plot((cen[i,0].numpy(), rel_normals[0].detach().numpy()), (cen[i,1].numpy(), rel_normals[1].detach().numpy()))\n",
    "        ax[0].set_xlim(24, 35)\n",
    "        ax[0].set_ylim(32, 43)\n",
    "        mappable1 = ax[1].imshow(testdata.node_feature[\"n0\"][:,-1,0].reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "                                 aspect='auto',\n",
    "                                 origin='lower')\n",
    "        vis_offsetmask = torch.where(testdata.node_feature[\"n0\"][:,-1,1]!=0, 1, 0)\n",
    "        mappable2 = ax[2].imshow(vis_offsetmask.reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "                                 aspect='auto',\n",
    "                                 origin='lower')        \n",
    "        mappable3 = ax[3].imshow(testdata.node_feature[\"n0\"][:,-1,0].reshape(62,62).detach().cpu().numpy()-vis_offsetmask.reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "                                 aspect='auto',\n",
    "                                 origin='lower')        \n",
    "        mappable4 = ax[4].plot(np.array(list_force)[0::5])\n",
    "        mappable5 = ax[5].plot(np.array(list_drag_force)[0::5])\n",
    "         # pdf.savefig()\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d01beda-71a3-4fe9-ab6f-5600d993acb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
