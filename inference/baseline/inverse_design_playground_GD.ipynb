{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41481747-0049-4511-b512-df8489041673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import OrderedDict\n",
    "import datetime\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pylab as plt\n",
    "from numbers import Number\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "pd.options.display.max_rows = 1500\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.width = 1000\n",
    "pd.set_option('max_colwidth', 400)\n",
    "import pdb\n",
    "import pickle\n",
    "import pprint as pp\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from deepsnap.batch import Batch as deepsnap_Batch\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..', '..'))\n",
    "from le_pde.argparser import arg_parse\n",
    "from le_pde.datasets.load_dataset import load_data\n",
    "from le_pde.models import load_model\n",
    "from le_pde.pytorch_net.util import groupby_add_keys, filter_df, get_unique_keys_df, Attr_Dict, Printer, get_num_params, get_machine_name, pload, pdump, to_np_array, get_pdict, reshape_weight_to_matrix, ddeepcopy as deepcopy, plot_vectors, record_data, filter_filename, Early_Stopping, str2bool, get_filename_short, print_banner, plot_matrices, get_num_params, init_args, filter_kwargs, to_string, COLOR_LIST\n",
    "from le_pde.utils import update_legacy_default_hyperparam, EXP_PATH, deepsnap_to_pyg, LpLoss, to_cpu, to_tuple_shape, parse_multi_step, loss_op, get_device, get_data_next_step\n",
    "from utils import compute_pressForce\n",
    "#from le_pde.utils import deepsnap_to_pyg, LpLoss, to_cpu, to_tuple_shape, parse_multi_step, loss_op, get_device, get_data_next_step\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "p = Printer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34edf99f-9265-45b0-906d-650e4261dc77",
   "metadata": {},
   "source": [
    "## 1. Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67193e7b-5777-4aac-9426-f91e6837d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(data_record):\n",
    "    x_axis = np.arange(len(data_record[\"train_loss\"]))\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(x_axis, data_record[\"train_loss\"], label=\"train\")\n",
    "    plt.plot(x_axis, data_record[\"val_loss\"], label=\"val\")\n",
    "    plt.plot(x_axis, data_record[\"test_loss\"], label=\"test\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.semilogy(x_axis, data_record[\"train_loss\"], label=\"train\")\n",
    "    plt.semilogy(x_axis, data_record[\"val_loss\"], label=\"val\")\n",
    "    plt.semilogy(x_axis, data_record[\"test_loss\"], label=\"test\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4494e7-afaf-4d55-a1fc-b32168ca62b5",
   "metadata": {},
   "source": [
    "## 2. Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a74011e-cb80-444a-ae95-6f29d830193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_PATH = \"./results/\"\n",
    "\n",
    "isplot = True\n",
    "all_hash = [\n",
    "    # \"0LVoHLHQ_ampere4\",\n",
    "    # \"zDOCitP9_ampere4\",\n",
    "    # \"6en0gt6G_turing1\",\n",
    "    # \"zHQu3EKe_turing2\",\n",
    "    # \"2okNCadZ_turing3\",\n",
    "    # \"I6EepBQI_turing3\",\n",
    "    # \"clnAWVnz_hyperturing1\",\n",
    "    # \"YDHgg+il_turing3\",\n",
    "    \"HD2hmsb+_turing3\",\n",
    "]\n",
    "hash_str = all_hash[0]\n",
    "dirname = EXP_PATH + \"naca_ellipse_2023-06-02/\"\n",
    "filename = filter_filename(dirname, include=hash_str)\n",
    "if len(filename) == 0:\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    data_record = pload(dirname + filename[0])\n",
    "except Exception as e:\n",
    "    print(f\"error {e}\")\n",
    "    # continue\n",
    "    raise\n",
    "if isplot:\n",
    "    plot_learning_curve(data_record)\n",
    "args = init_args(update_legacy_default_hyperparam(data_record[\"args\"]))\n",
    "args.filename = filename\n",
    "# model = load_model(data_record[\"best_model_dict\"], device=device)\n",
    "model = load_model(data_record[\"model_dict\"][-1], device=device)\n",
    "model.eval()\n",
    "p.print(filename, banner_size=100)\n",
    "\n",
    "# Load test dataset:\n",
    "args_test = deepcopy(args)\n",
    "if args.temporal_bundle_steps == 1:\n",
    "    if args.dataset in [\"fno\", \"fno-2\", \"fno-3\"]:\n",
    "        args_test.multi_step = \"20\"\n",
    "    elif args.dataset in [\"fno-1\"]:\n",
    "        args_test.multi_step = \"40\"\n",
    "    elif args.dataset in [\"fno-4\"]:\n",
    "        args_test.multi_step = \"10\"\n",
    "    elif args.dataset in [\"naca_ellipse_lepde\"]:\n",
    "        args_test.multi_step = \"1\"\n",
    "        args_test.latent_multi_step=\"1\"\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    pass\n",
    "args_test.batch_size = 1\n",
    "args_test.is_test_only=True\n",
    "\n",
    "(dataset_train_val, dataset_test), (train_loader, val_loader, test_loader) = load_data(args_test)\n",
    "test_loader = DataLoader(dataset_test, num_workers=0, collate_fn=deepsnap_Batch.collate(),\n",
    "                         batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749c5974-4afc-41b3-9d23-b174133f43d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "for data in test_loader:\n",
    "    # if i == 1900:\n",
    "    # if i == 2500:\n",
    "    if i == 1200:\n",
    "    # if i == 0:\n",
    "    # if i == 400:\n",
    "        break\n",
    "    i+=1\n",
    "\n",
    "    if i%100 == 0:\n",
    "        fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "        bd = (((data.param[\"n0\"].detach().cpu().numpy()/2) + 0.5) * 62) + 0\n",
    "        mappable0 = ax.plot(bd[0,0::2], bd[0,1::2])\n",
    "        ax.set_xlim(0, 62)\n",
    "        ax.set_ylim(0, 62)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8656e5-40e6-4649-9930-8ec3b0b346e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to(device)        \n",
    "testdata = data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eef9c5-771f-431a-8f23-5bc21f847795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = 64; n = 64\n",
    "# maxnum = 100\n",
    "\n",
    "# def discretize_boundary(boundary):\n",
    "#     # import pdb\n",
    "#     # pdb.set_trace()\n",
    "#     assert boundary.shape[1] == 2\n",
    "#     num_bound = boundary.shape[0]\n",
    "#     device = boundary.device\n",
    "#     p_5 = torch.tensor([0.5], device=device).repeat(num_bound)\n",
    "#     x = torch.minimum(torch.maximum(boundary[:, 0], p_5), torch.tensor([n-1.5], device=device).repeat(num_bound))\n",
    "#     x_inds = torch.minimum(x.type(torch.int32), torch.tensor([n-2], device=device).repeat(num_bound))\n",
    "#     # fs = x - x_inds\n",
    "\n",
    "#     y = torch.minimum(torch.maximum(boundary[:, 1], p_5), torch.tensor([m-1.5], device=device).repeat(num_bound))\n",
    "#     y_inds = torch.minimum(y.type(torch.int32), torch.tensor([m-2], device=device).repeat(num_bound))\n",
    "#     # ft = y - y_inds\n",
    "#     return x_inds, y_inds\n",
    "\n",
    "# def find_orthogonal_line(A, B, C, x0, y0):\n",
    "#     m1 = torch.empty((C.shape[0],), device=C.device)\n",
    "#     m1[B==0] = float('inf')\n",
    "#     m1[B!=0] = (-A/B)[B!=0]\n",
    "\n",
    "#     m2 = torch.empty((C.shape[0],), device=C.device)\n",
    "#     m2[m1==float('inf')] = 0\n",
    "#     m2[m1!=float('inf')] = (-1 / m1)[m1!=float('inf')]\n",
    "\n",
    "#     b2 = y0 - m2 * x0  # The y-intercept of L2.\n",
    "\n",
    "#     # Return the coefficients A, B, C of the line L2 (Ax + By - C = 0)\n",
    "#     return m2, -1, b2\n",
    "\n",
    "# def edge_cells(polygon):\n",
    "#     num_vertices = len(polygon)\n",
    "#     edges = []\n",
    "#     for i in range(num_vertices):\n",
    "#         v1 = polygon[i]\n",
    "#         v2 = polygon[(i + 1) % num_vertices]\n",
    "#         edge = sorted([v1, v2], key=lambda x: x[1])\n",
    "#         edges.append(edge)\n",
    "#     return edges\n",
    "\n",
    "# def find_cells_inside_curve(polygon, grid_shape):\n",
    "#     def horizontal_intersection(x1, y1, x2, y2, y):\n",
    "#         return x1 + (y - y1) * (x2 - x1) / (y2 - y1)\n",
    "#     edges = edge_cells(polygon)\n",
    "#     grid = np.zeros(grid_shape, dtype=np.uint8)\n",
    "#     height, width = grid.shape\n",
    "    \n",
    "#     for y in range(height):\n",
    "#         intersections = []\n",
    "#         for edge in edges:\n",
    "#             y1, y2 = edge[0][1], edge[1][1]\n",
    "#             if y1 < y <= y2:\n",
    "#                 x = horizontal_intersection(*edge[0], *edge[1], y)\n",
    "#                 intersections.append(x)\n",
    "#         intersections.sort()\n",
    "#         for i in range(0, len(intersections), 2):\n",
    "#             x_start, x_end = int(np.ceil(intersections[i])), int(np.floor(intersections[i + 1]))\n",
    "#             grid[y, x_start : x_end + 1] = 1\n",
    "\n",
    "#     return grid\n",
    "\n",
    "# def update_static_masks(torch_con_boundary):\n",
    "#     # import pdb\n",
    "#     # pdb.set_trace()\n",
    "#     x_inds, y_inds = discretize_boundary(torch_con_boundary)\n",
    "#     pointy_hash = maxnum*x_inds[20] + y_inds[20]\n",
    "\n",
    "#     indices = torch.stack((maxnum*x_inds,y_inds), 0)\n",
    "#     sum_indices = indices.sum(0)\n",
    "#     ind_unique = torch.unique(sum_indices, sorted=True) #, return_inverse=True)\n",
    "#     x_idx = (torch.cat([(sum_indices==ind_u).nonzero()[0] for ind_u in ind_unique])).sort()[0]\n",
    "#     # print(sum_indices[x_idx])\n",
    "#     # print(x_idx)\n",
    "#     repeat_sum_indices = torch.tile(sum_indices, (ind_unique.shape[0],1))\n",
    "#     repeat_ind_unique = torch.tile(sum_indices[x_idx].reshape(ind_unique.shape[0], 1), (1, sum_indices.shape[0]))\n",
    "#     org_mask = (repeat_ind_unique == repeat_sum_indices)\n",
    "#     fatted_mask = torch.roll(org_mask, 1, 1) + torch.roll(org_mask, -1, 1)\n",
    "\n",
    "#     relvecs = []\n",
    "#     base_pts = []\n",
    "#     base_nums = []\n",
    "#     for bdpt in range(sum_indices[x_idx].shape[0]):\n",
    "#         # i = 1\n",
    "#         if pointy_hash == sum_indices[x_idx][bdpt]:\n",
    "#             base_pt = torch.stack([x_inds[org_mask[bdpt]][0], y_inds[org_mask[bdpt]][0]]) + 0.5\n",
    "#             base_pts.append(base_pt)\n",
    "#             relvec = torch_con_boundary[20] - base_pt\n",
    "#             relvecs.append(relvec)\n",
    "#             # base_nums.append(i)\n",
    "#         elif torch.sum(org_mask[bdpt]) >= 4:\n",
    "#             base_pt = torch.stack([x_inds[org_mask[bdpt]][0], y_inds[org_mask[bdpt]][0]]) + 0.5\n",
    "#             base_pts.append(base_pt)\n",
    "#             relvec = torch_con_boundary[org_mask[bdpt]] - base_pt.repeat(torch_con_boundary[org_mask[bdpt]].shape[0], 1)\n",
    "#             ind = torch.argmin(torch.norm(relvec, dim=1))\n",
    "#             relvecs.append(relvec[ind])\n",
    "#             # base_nums.append(i)\n",
    "#         elif torch.sum(fatted_mask[bdpt] * torch.logical_not(org_mask[bdpt])) > 2:\n",
    "#             base_pt = torch.stack([x_inds[org_mask[bdpt]][0], y_inds[org_mask[bdpt]][0]]) + 0.5\n",
    "#             # base_pts.append(base_pt)\n",
    "#             relvec = torch_con_boundary[org_mask[bdpt]] - base_pt.repeat(torch_con_boundary[org_mask[bdpt]].shape[0], 1)\n",
    "#             # print(\"disjoint: \", relvec)\n",
    "#             if len(relvec.shape) == 2:\n",
    "#                 import pdb\n",
    "#                 # pdb.set_trace()\n",
    "#                 # for i in range(xbound[org_mask[bdpt]].shape[0]):\n",
    "#                     # if 2 * i + 2 == bd_points.shape[0]:\n",
    "#                 # print(\"mask:\", org_mask[bdpt])\n",
    "#                 # print(xbound[org_mask[bdpt]])\n",
    "#                 # plt.plot(xbound[org_mask[bdpt]][:, 0].numpy(), xbound[org_mask[bdpt]][:, 1].numpy())\n",
    "#                 #     # else:\n",
    "#                 #     #    plt.plot(bd_points[2*i:2*i+2, 0].numpy(), bd_points[2*i:2*i+2, 1].numpy())\n",
    "#                 # plt.scatter(base_pt[0].numpy(), base_pt[1].numpy())\n",
    "#                 # plt.show()\n",
    "#                 # for i in range(relvec.shape[0]):\n",
    "#                 #     row_relvec = relvec[i]\n",
    "#                 #     relvecs.append(row_relvec)\n",
    "#                 #     base_pts.append(base_pt)\n",
    "#                 #     i += 1\n",
    "#                 relvecs.append(relvec[-1])\n",
    "#                 base_pts.append(base_pt)\n",
    "#                 # base_nums.append(i)\n",
    "#             else:\n",
    "#                 relvecs.append(relvec)\n",
    "#                 base_pts.append(base_pt)\n",
    "#                 # base_nums.append(i)\n",
    "#         elif torch.sum(org_mask[bdpt]) == 1:\n",
    "#             base_pt = torch.stack([x_inds[org_mask[bdpt]][0], y_inds[org_mask[bdpt]][0]]) + 0.5\n",
    "#             base_pts.append(base_pt)\n",
    "#             relvec = torch_con_boundary[org_mask[bdpt]] - base_pt\n",
    "#             # print(\"rel: \", relvec[0])\n",
    "#             relvecs.append(relvec[0])\n",
    "#             # base_nums.append(i)\n",
    "#         else:    \n",
    "#             if fatted_mask[bdpt][0] and fatted_mask[bdpt][-1]:\n",
    "#                 rollnum = 1\n",
    "#                 for _ in range(0, 100):\n",
    "#                     temprole = torch.roll(fatted_mask[bdpt], rollnum, 0)\n",
    "#                     if temprole[0] and temprole[-1]:\n",
    "#                         rollnum += 1    \n",
    "#                     else:\n",
    "#                         break\n",
    "#                 #import pdb\n",
    "#                 #pdb.set_trace()\n",
    "#                 x_pts = torch.roll(torch_con_boundary[fatted_mask[bdpt]], rollnum, 0)            \n",
    "#             else:\n",
    "#                 x_pts = torch_con_boundary[fatted_mask[bdpt]]\n",
    "\n",
    "#             bd_points = torch.cat([x_pts[0:1], x_pts[1:-1].repeat(1, 2).reshape(-1,2), x_pts[-1:]], dim=0)\n",
    "#             dire_vec = bd_points[0::2] - bd_points[1::2]\n",
    "#             const = bd_points[0::2, 1] - bd_points[0::2, 0] * dire_vec[:,1]/dire_vec[:,0]\n",
    "\n",
    "#             base_pt = torch.stack([x_inds[org_mask[bdpt]][0], y_inds[org_mask[bdpt]][0]]) + 0.5\n",
    "#             base_pts.append(base_pt)\n",
    "#             # base_nums.append(i)\n",
    "#             base_points = base_pt.repeat(const.shape[0], 1)\n",
    "#             slope = dire_vec[:,1]/dire_vec[:,0]\n",
    "#             # import pdb\n",
    "#             # pdb.set_trace()\n",
    "#             ax, by, con = find_orthogonal_line(slope, -torch.ones((const.shape[0],), device=torch_con_boundary.device), const, base_points[:,0], base_points[:,1])\n",
    "\n",
    "#             # for i in range(int(bd_points.shape[0]/2)):\n",
    "#             #     if 2 * i + 2 == bd_points.shape[0]:\n",
    "#             #         plt.plot(bd_points[2*i:, 0].numpy(), bd_points[2*i:, 1].numpy())\n",
    "#             #     else:\n",
    "#             #         plt.plot(bd_points[2*i:2*i+2, 0].numpy(), bd_points[2*i:2*i+2, 1].numpy())\n",
    "#             # plt.scatter(base_pt[0].numpy(), base_pt[1].numpy())\n",
    "#             # plt.show()\n",
    "\n",
    "#             al = -ax/by\n",
    "#             bl = con\n",
    "#             cl = dire_vec[:,1]/dire_vec[:,0]\n",
    "#             dl = const\n",
    "\n",
    "#             # print(org_mask[bdpt,:])\n",
    "#             intersection = torch.stack([(dl - bl)/(al - cl), (al*dl - bl*cl)/(al - cl)]).t()\n",
    "#             # print(intersection)\n",
    "#             # print(base_pt)\n",
    "\n",
    "#             relvec = intersection - torch.tile(base_pt, (intersection.shape[0], 1))\n",
    "#             #print(relvec.sum(0)/relvec.shape[0])\n",
    "#             relvecs.append(relvec.sum(0)/relvec.shape[0])\n",
    "\n",
    "#     ### Check number of offset vectors is same as that of boundary cells of solid\n",
    "#     # print(len(base_pts), sum_indices[x_idx].shape[0])\n",
    "#     assert len(base_pts) == sum_indices[x_idx].shape[0]\n",
    "    \n",
    "#     # import pdb\n",
    "#     # pdb.set_trace()    \n",
    "    \n",
    "#     bd_offset = torch.stack(relvecs)\n",
    "#     offset_grid_bound = torch.zeros((62, 62, 2), device=torch_con_boundary.device)\n",
    "#     offset_grid_bound[x_inds, y_inds] = torch.tensor([1, 1], dtype=torch.float32, device=torch_con_boundary.device)\n",
    "#     offset_grid_bound = offset_grid_bound.transpose(1,0)\n",
    "\n",
    "#     # offset_grid = find_cells_inside_curve(torch.stack((x_inds, y_inds), -1).tolist(), grid_bound.shape)\n",
    "#     offset_grid = find_cells_inside_curve(torch.stack((x_inds, y_inds), -1).detach().cpu().tolist(), (62, 62))\n",
    "#     # fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "#     # ax.imshow(offset_grid, cmap='viridis',\n",
    "#     #          aspect='auto',\n",
    "#     #          origin='lower')\n",
    "#     # plt.show()\n",
    "#     inner_solid_mask = np.copy(offset_grid)\n",
    "#     offset_grid = offset_grid.reshape(62, 62, 1)\n",
    "#     offset_grid = np.concatenate([offset_grid, offset_grid], -1)\n",
    "\n",
    "#     offset_union = offset_grid_bound + torch.tensor(offset_grid, device=torch_con_boundary.device)\n",
    "#     offset_union[(offset_union.sum(-1) > 2),:] = torch.tensor([1, 1], dtype=torch.float32, device=torch_con_boundary.device)\n",
    "#     offset_union.index_put_((y_inds[x_idx], x_inds[x_idx]), bd_offset)    \n",
    "\n",
    "#     # np_offset_union = offset_union.detach().cpu().numpy()\n",
    "\n",
    "#     # fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "#     # ax.imshow(np_offset_union[...,1], cmap='viridis',\n",
    "#     #          aspect='auto',\n",
    "#     #          origin='lower')\n",
    "#     # plt.show()\n",
    "\n",
    "#     # gtmask = data.node_feature[\"n0\"][:,0,2].reshape(62,62).detach().cpu().numpy()\n",
    "#     # fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "#     # ax.imshow(gtmask, cmap='viridis',\n",
    "#     #          aspect='auto',\n",
    "#     #          origin='lower')\n",
    "#     # plt.show()\n",
    "\n",
    "#     # print((data.node_feature[\"n0\"][:,-1,1].reshape(62,62).detach().cpu().numpy() - np_offset_union[...,0]).sum())\n",
    "#     # print((data.node_feature[\"n0\"][:,-1,2].reshape(62,62).detach().cpu().numpy() - np_offset_union[...,1]).sum())\n",
    "    \n",
    "#     # updated_offset_mask = np_offset_union\n",
    "\n",
    "#     grid_bound = torch.zeros((62, 62), device=torch_con_boundary.device)\n",
    "#     grid_bound[x_inds, y_inds] = 1\n",
    "#     # union = grid_bound.transpose(1,0).detach().cpu().numpy() + inner_solid_mask\n",
    "#     union = grid_bound.transpose(1,0) + torch.tensor(inner_solid_mask, device=torch_con_boundary.device)\n",
    "#     union[union == 2] = 1\n",
    "\n",
    "#     # fig, ax = plt.subplots(figsize=(8,4), ncols=2)\n",
    "#     # ax[0].imshow(union.flatten().reshape(62,62), cmap='viridis',\n",
    "#     #          aspect='auto',\n",
    "#     #          origin='lower')\n",
    "#     # ax[1].imshow(data.node_feature[\"n0\"][:,-1,0].reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "#     #          aspect='auto',\n",
    "#     #          origin='lower')\n",
    "#     # plt.show()\n",
    "\n",
    "#     # print((data.node_feature[\"n0\"][:,-1,0].reshape(62,62).detach().cpu().numpy() - union).sum())\n",
    "#     updated_solid_mask = union\n",
    "    \n",
    "#     return updated_solid_mask, offset_union #updated_offset_mask\n",
    "\n",
    "# def update_bdfeature(reconstructed_boundary):\n",
    "#     upd_solid_mask, upd_solid_offset = update_static_masks(reconstructed_boundary)\n",
    "#     torch_batch_mask = torch.where(upd_solid_mask==1, False, True).clone().flatten()\n",
    "#     upd_solid_mask = upd_solid_mask[...,None]\n",
    "#     static_feature = torch.cat((upd_solid_mask, upd_solid_offset), -1)\n",
    "#     multi_static_feat = torch.stack([static_feature for _ in range(4)], -2).reshape(-1,4,3)\n",
    "#     return multi_static_feat, torch_batch_mask\n",
    "\n",
    "# def update_data(reconstructed_bound, optimdata, original_data, constant_var, opt_var):\n",
    "#     mul_static_feat, tor_batch_mask = update_bdfeature(reconstructed_bound) \n",
    "\n",
    "#     a = deepsnap_Batch\n",
    "#     batch, _ = a._init_batch_fields(optimdata.keys, [])\n",
    "#     batch.batch = optimdata.batch.clone()\n",
    "#     batch.compute_func = optimdata.compute_func\n",
    "#     batch.directed = optimdata.directed.detach().clone()\n",
    "#     batch.dyn_dims = optimdata.dyn_dims\n",
    "#     batch.edge_attr = optimdata.edge_attr\n",
    "#     batch.edge_index = {('n0','0','n0'): optimdata.edge_index[('n0','0','n0')].detach().clone()}\n",
    "#     batch.edge_label_index = {('n0','0','n0'): optimdata.edge_label_index[('n0','0','n0')].detach().clone()}\n",
    "#     batch.grid_keys = optimdata.grid_keys\n",
    "#     batch.mask = {\"n0\": tor_batch_mask.detach()}\n",
    "#     batch.node_feature = {\"n0\": torch.cat((mul_static_feat, original_data.node_feature[\"n0\"][...,3:].detach()), -1)}\n",
    "#     batch.node_label = {\"n0\": optimdata.node_label[\"n0\"].detach().clone()}\n",
    "#     batch.node_label_index = {\"n0\": optimdata.node_label_index[\"n0\"].detach().clone()}\n",
    "#     batch.node_pos = {\"n0\": optimdata.node_pos[\"n0\"].detach().clone()}\n",
    "#     batch.original_shape = optimdata.original_shape\n",
    "#     batch.param = {\"n0\": torch.cat((constant_var, opt_var), 0).transpose(1,0).flatten()[None,:]}\n",
    "#     batch.params = optimdata.params\n",
    "#     batch.part_keys = optimdata.part_keys\n",
    "#     batch.task = optimdata.task    \n",
    "#     optimdata = batch    \n",
    "    \n",
    "#     return optimdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c2ec3-faee-4f4d-b028-7026e83cf37a",
   "metadata": {},
   "source": [
    "## 3. inverse optimization with LEPDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e411271b-1663-4cc7-b585-8c7bb48a77f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = data.clone()\n",
    "orgdata = data.clone()\n",
    "#print(testdata.param[\"n0\"])\n",
    "const_variable = testdata.param[\"n0\"][:,0::2].detach().clone()\n",
    "#const_variable.requires_grad=True\n",
    "opt_variable = testdata.param[\"n0\"][:,1::2].detach().clone()\n",
    "opt_variable.requires_grad=True\n",
    "#print(const_variable, opt_variable)\n",
    "testdata.param[\"n0\"] = torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:]\n",
    "#print(testdata.param[\"n0\"])\n",
    "# optimizer = torch.optim.Adam([opt_variable, const_variable], lr=0.01)\n",
    "# best\n",
    "# optimizer = torch.optim.Adam([opt_variable], lr=0.000005)\n",
    "optimizer = torch.optim.Adam([opt_variable], lr=0.0001)\n",
    "\n",
    "prerollout = 8\n",
    "one_period = 4\n",
    "vis_prerollout = False\n",
    "\n",
    "# testdata = data.clone()\n",
    "# original_optvar = testdata.param[\"n0\"][:,1::2].detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87d51c-abb1-497c-bac3-14a94942a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_filename = os.path.join(\"./dataset/naca_ellipse/training_trajectories/\", \"normalization_max_min.p\")\n",
    "normdict = pickle.load(open(normalization_filename, \"rb\"))\n",
    "x_max = normdict[\"x_max\"]\n",
    "x_min = normdict[\"x_min\"]\n",
    "y_max = normdict[\"y_max\"]\n",
    "y_min = normdict[\"y_min\"]\n",
    "p_max = normdict[\"p_max\"]\n",
    "p_min = normdict[\"p_min\"]\n",
    "p_max = p_max.to(device)\n",
    "p_min = p_min.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f27b2a-ff48-4327-80a2-e42c1cbddd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_max, p_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c108e7-4870-45a2-9657-6213c9ebb9f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from utils import compute_pressForce, compute_orthonormal, linear_transform, update_data\n",
    "        \n",
    "optim_iter = 2000\n",
    "is_objvis = True\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "bd = testdata.param[\"n0\"].reshape(40,2).detach().cpu().numpy()\n",
    "bd = (((bd/2) + 0.5) * 62) + 0\n",
    "#print(a.shape)\n",
    "mappable0 = ax.plot(bd[:,0], bd[:,1])\n",
    "ax.set_xlim(0, 62)\n",
    "ax.set_ylim(0, 62)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "ax.imshow(testdata.node_feature[\"n0\"][:,-1,-1].reshape(62,62).detach().cpu().numpy(),\n",
    "          cmap='viridis',\n",
    "          aspect='auto')\n",
    "plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "# ax.imshow(testdata.node_label[\"n0\"][:,-1,-1].reshape(62,62).detach().cpu().numpy(),\n",
    "#           cmap='viridis',\n",
    "#           aspect='auto')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8), ncols=1)\n",
    "length, nx, ny, cen = compute_orthonormal(torch.tensor(bd))\n",
    "rec_press = ((((testdata.node_label[\"n0\"][:,-1,-1].reshape(62,62)/2) + 0.5) * (p_max-p_min)) + p_min).detach().cpu()\n",
    "lin_press = linear_transform(torch.nn.functional.pad(rec_press, (1,3,1,3)), cen) #*-1\n",
    "print(lin_press)\n",
    "mappable0 = ax.plot(bd[:,0], bd[:,1])\n",
    "normals = torch.stack((lin_press*nx,lin_press*ny), -1)\n",
    "for i in range(40):\n",
    "    rel_normals = cen[i,:] + normals[i,:]\n",
    "    ax.plot((cen[i,0], rel_normals[0]), (cen[i,1], rel_normals[1]))\n",
    "ax.set_xlim(24, 35)\n",
    "ax.set_ylim(32, 43)\n",
    "# ax.set_xlim(18, 28)\n",
    "# ax.set_ylim(37, 47)\n",
    "plt.show()\n",
    "\n",
    "pdf = PdfPages('./optimized_naca_lepde_unflip.pdf')\n",
    "list_force = []\n",
    "list_drag_force = []\n",
    "for oiter in range(optim_iter):\n",
    "    total_x_force = 0\n",
    "    total_y_force = 0\n",
    "\n",
    "    bound = torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:].reshape(40,2)\n",
    "\n",
    "    rec_bound = (((bound/2) + 0.5) * 62) + 0\n",
    "    up_solid_mask, up_solid_offset = update_static_masks(rec_bound)\n",
    "    tor_batch_mask = torch.where(up_solid_mask==1, False, True).clone().flatten()\n",
    "    up_solid_mask = up_solid_mask[...,None]\n",
    "    static_feat = torch.cat((up_solid_mask, up_solid_offset), -1)\n",
    "    mul_static_feat = torch.stack([static_feat for _ in range(4)], -2).reshape(-1,4,3)\n",
    "    \n",
    "    \n",
    "    a = deepsnap_Batch\n",
    "    batch, _ = a._init_batch_fields(testdata.keys, [])\n",
    "    batch.batch = testdata.batch.clone()\n",
    "    batch.compute_func = testdata.compute_func\n",
    "    batch.directed = testdata.directed.detach().clone()\n",
    "    batch.dyn_dims = testdata.dyn_dims\n",
    "    batch.edge_attr = testdata.edge_attr\n",
    "    batch.edge_index = {('n0','0','n0'): testdata.edge_index[('n0','0','n0')].detach().clone()}\n",
    "    batch.edge_label_index = {('n0','0','n0'): testdata.edge_label_index[('n0','0','n0')].detach().clone()}\n",
    "    batch.grid_keys = testdata.grid_keys\n",
    "    batch.mask = {\"n0\": tor_batch_mask.detach()}\n",
    "    batch.node_feature = {\"n0\": torch.cat((mul_static_feat, orgdata.node_feature[\"n0\"][...,3:].detach()), -1)}\n",
    "    batch.node_label = {\"n0\": testdata.node_label[\"n0\"].detach().clone()}\n",
    "    batch.node_label_index = {\"n0\": testdata.node_label_index[\"n0\"].detach().clone()}\n",
    "    batch.node_pos = {\"n0\": testdata.node_pos[\"n0\"].detach().clone()}\n",
    "    batch.original_shape = testdata.original_shape\n",
    "    batch.param = {\"n0\": torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:]}\n",
    "    batch.params = testdata.params\n",
    "    batch.part_keys = testdata.part_keys\n",
    "    batch.task = testdata.task\n",
    "    \n",
    "    testdata = batch\n",
    "    \n",
    "#     for _ in range(6):\n",
    "#         testdata, pred = get_data_next_step(model, testdata, use_grads=False, return_data=True, is_y_diff=False)\n",
    "#         press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "#         # press = ((((testdata.node_label[\"n0\"][:,-1,-1].reshape(62,62)/2) + 0.5) * (p_max-p_min)) + p_min) #.detach().cpu()\n",
    "#         raw_bound = (((testdata.param[\"n0\"].reshape(40,2)/2) + 0.5) * 62) + 0\n",
    "        \n",
    "#         length, nx, ny, cen = compute_orthonormal(torch.tensor(raw_bound))\n",
    "#         cen = cen.to(device)\n",
    "#         lin_press = linear_transform(torch.nn.functional.pad(press, (1,3,1,3)), cen)\n",
    "#         x_force, y_force = compute_pressForce(torch.nn.functional.pad(press, (1,3,1,3)), raw_bound)\n",
    "#         total_x_force += x_force\n",
    "#         total_y_force += y_force\n",
    "    for kk in range(prerollout+one_period):\n",
    "        if oiter % 50 == 49 and kk == 0 and vis_prerollout:\n",
    "            print(\"kk = 0\")\n",
    "            fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "            ax.imshow(torch.nn.functional.pad(((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min, ((1,3,1,3))).detach().cpu().numpy(), cmap='viridis',\n",
    "                     aspect='auto',\n",
    "                     origin='lower')\n",
    "            plt.show()\n",
    "            # print(cen.shape, raw_bound.shape)\n",
    "\n",
    "        testdata, pred = get_data_next_step(model, testdata, use_grads=False, return_data=True, is_y_diff=False)\n",
    "        # pdb.set_trace()\n",
    "        press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "        # press = ((((testdata.node_label[\"n0\"][:,-1,-1].reshape(62,62)/2) + 0.5) * (p_max-p_min)) + p_min) #.detach().cpu()\n",
    "        raw_bound = (((testdata.param[\"n0\"].reshape(40,2)/2) + 0.5) * 62) + 0\n",
    "        \n",
    "        length, nx, ny, cen = compute_orthonormal(torch.tensor(raw_bound))\n",
    "        cen = cen.to(device)\n",
    "        \n",
    "        if oiter % 50 == 49 and kk == prerollout and vis_prerollout:\n",
    "            print(\"kk = \" + str(prerollout))\n",
    "            fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "            ax.imshow(torch.nn.functional.pad(press, ((1,3,1,3))).detach().cpu().numpy(), cmap='viridis',\n",
    "                     aspect='auto',\n",
    "                     origin='lower')\n",
    "            plt.show()\n",
    "            # print(cen.shape, raw_bound.shape)\n",
    "        \n",
    "        if kk >= prerollout:\n",
    "            testdata, pred = get_data_next_step(model, testdata, use_grads=False, return_data=True, is_y_diff=False)\n",
    "            # pdb.set_trace()\n",
    "            press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "            # press = ((((testdata.node_label[\"n0\"][:,-1,-1].reshape(62,62)/2) + 0.5) * (p_max-p_min)) + p_min) #.detach().cpu()\n",
    "            raw_bound = (((testdata.param[\"n0\"].reshape(40,2)/2) + 0.5) * 62) + 0\n",
    "            lin_press = linear_transform(torch.nn.functional.pad(press, (1,3,1,3)), cen)\n",
    "            x_force, y_force = compute_pressForce(torch.nn.functional.pad(press, (1,3,1,3)), raw_bound)\n",
    "            \n",
    "            total_x_force += x_force\n",
    "            total_y_force += y_force\n",
    "        \n",
    "    total_x_force = total_x_force/one_period\n",
    "    total_y_force = total_y_force/one_period\n",
    "        \n",
    "    list_force.append(total_y_force.item())\n",
    "    list_drag_force.append(total_x_force.item())\n",
    "\n",
    "    output = -1/total_x_force + 10 * torch.square(-30 - total_y_force)\n",
    "    # output = -1/total_x_force # + 10 * torch.square(-30 - total_y_force)\n",
    "    optimizer.zero_grad()\n",
    "    output.backward()\n",
    "    torch.nn.utils.clip_grad_value_(opt_variable, 0.01)\n",
    "    # print(\"Gradient: \", opt_variable.grad)\n",
    "    optimizer.step()\n",
    "    aft_bd = torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:].reshape(40,2).clone()\n",
    "\n",
    "    ### Visualization of updated boundary \"\"\"\n",
    "    if oiter % 50 == 49:\n",
    "    # if oiter % 10 == 9:\n",
    "        print(\"iteration: \", oiter)\n",
    "        bound = torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:].reshape(40,2)\n",
    "        bd = (((bound.detach().cpu().numpy()/2) + 0.5) * 62) + 0        \n",
    "        length, nx, ny, cen = compute_orthonormal(torch.tensor(bd))\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(18,3), ncols=6)\n",
    "        mappable0 = ax[0].plot(bd[:,0], bd[:,1])\n",
    "        nx = nx.detach().cpu()\n",
    "        ny = ny.detach().cpu()\n",
    "        cen = cen.detach().cpu()\n",
    "        lin_press = lin_press.cpu()\n",
    "        normals = torch.stack((lin_press*nx,lin_press*ny), -1)#.to(device)\n",
    "        for i in range(40):\n",
    "            rel_normals = cen[i,:] + normals[i,:]\n",
    "            ax[0].plot((cen[i,0].numpy(), rel_normals[0].detach().numpy()), (cen[i,1].numpy(), rel_normals[1].detach().numpy()))\n",
    "        ax[0].set_xlim(24, 35)\n",
    "        ax[0].set_ylim(32, 43)\n",
    "        mappable1 = ax[1].imshow(testdata.node_feature[\"n0\"][:,-1,0].reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "                                 aspect='auto',\n",
    "                                 origin='lower')\n",
    "        vis_offsetmask = torch.where(testdata.node_feature[\"n0\"][:,-1,1]!=0, 1, 0)\n",
    "        mappable2 = ax[2].imshow(vis_offsetmask.reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "                                 aspect='auto',\n",
    "                                 origin='lower')        \n",
    "        mappable3 = ax[3].imshow(testdata.node_feature[\"n0\"][:,-1,0].reshape(62,62).detach().cpu().numpy()-vis_offsetmask.reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "                                 aspect='auto',\n",
    "                                 origin='lower')        \n",
    "        mappable4 = ax[4].plot(np.array(list_force)[0::5])\n",
    "        mappable5 = ax[5].plot(np.array(list_drag_force)[0::5])\n",
    "         # pdf.savefig()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"diff_bef_aft \", (aft_bd - bound).sum())\n",
    "    \n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcef5c0-42a4-400a-a1b5-42bd157589a7",
   "metadata": {},
   "source": [
    "## 4. inverse optimization with FNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf5d697-782d-43ed-9d1b-0330c7e07ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "isplot = True\n",
    "all_hash = [\n",
    "    #\"Yirzlp+j_ampere4\",\n",
    "    \"clnAWVnz_hyperturing1\",\n",
    "    \n",
    "]\n",
    "hash_str = all_hash[0]\n",
    "dirname = EXP_PATH + \"naca_ellipse_2023-06-02/\"\n",
    "filename = filter_filename(dirname, include=hash_str)\n",
    "if len(filename) == 0:\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    data_record = pload(dirname + filename[0])\n",
    "except Exception as e:\n",
    "    print(f\"error {e}\")\n",
    "    # continue\n",
    "    raise\n",
    "if isplot:\n",
    "    plot_learning_curve(data_record)\n",
    "args = init_args(update_legacy_default_hyperparam(data_record[\"args\"]))\n",
    "args.filename = filename\n",
    "# model = load_model(data_record[\"best_model_dict\"], device=device)\n",
    "model_fno = load_model(data_record[\"model_dict\"][-1], device=device)\n",
    "model_fno.eval()\n",
    "p.print(filename, banner_size=100)\n",
    "\n",
    "# Load test dataset:\n",
    "args_test = deepcopy(args)\n",
    "if args.temporal_bundle_steps == 1:\n",
    "    if args.dataset in [\"fno\", \"fno-2\", \"fno-3\"]:\n",
    "        args_test.multi_step = \"20\"\n",
    "    elif args.dataset in [\"fno-1\"]:\n",
    "        args_test.multi_step = \"40\"\n",
    "    elif args.dataset in [\"fno-4\"]:\n",
    "        args_test.multi_step = \"10\"\n",
    "    elif args.dataset in [\"naca_ellipse_lepde\"]:\n",
    "        args_test.multi_step = \"1\"\n",
    "        args_test.latent_multi_step=\"1\"\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    pass\n",
    "args_test.batch_size = 1\n",
    "args_test.is_test_only=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ff07e-8289-45b5-8379-c15f68d75db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone data\n",
    "testdata = data.clone()\n",
    "orgdata = data.clone()\n",
    "\n",
    "# Set leaf variables for optimization\n",
    "const_variable = testdata.param[\"n0\"][:,0::2].detach().clone()\n",
    "opt_variable = testdata.param[\"n0\"][:,1::2].detach().clone()\n",
    "opt_variable.requires_grad=True\n",
    "testdata.param[\"n0\"] = torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:]\n",
    "\n",
    "optimizer = torch.optim.Adam([opt_variable], lr=0.00001)\n",
    "\n",
    "prerollout = 36\n",
    "one_period = 4\n",
    "vis_prerollout = False\n",
    "\n",
    "optim_iter = 1300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e012d-ad9b-46e1-9be5-3207af8a002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for normalization\n",
    "\n",
    "normalization_filename = os.path.join(\"./dataset/naca_ellipse/training_trajectories/\", \"normalization_max_min.p\")\n",
    "normdict = pickle.load(open(normalization_filename, \"rb\"))\n",
    "x_max = normdict[\"x_max\"]\n",
    "x_min = normdict[\"x_min\"]\n",
    "y_max = normdict[\"y_max\"]\n",
    "y_min = normdict[\"y_min\"]\n",
    "p_max = normdict[\"p_max\"]\n",
    "p_min = normdict[\"p_min\"]\n",
    "p_max = p_max.to(device)\n",
    "p_min = p_min.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f08e91a-a1e7-4b9a-be47-70f7fd9c2b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from utils import compute_pressForce, compute_orthonormal, linear_transform, update_data\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "bd = testdata.param[\"n0\"].reshape(40,2).detach().cpu().numpy()\n",
    "bd = (((bd/2) + 0.5) * 62) + 0\n",
    "#print(a.shape)\n",
    "mappable0 = ax.plot(bd[:,0], bd[:,1])\n",
    "ax.set_xlim(0, 62)\n",
    "ax.set_ylim(0, 62)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "ax.imshow(testdata.node_feature[\"n0\"][:,-1,-1].reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "         aspect='auto',\n",
    "         origin='lower')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8), ncols=1)\n",
    "length, nx, ny, cen = compute_orthonormal(torch.tensor(bd))\n",
    "rec_press = ((((testdata.node_label[\"n0\"][:,-1,-1].reshape(62,62)/2) + 0.5) * (p_max-p_min)) + p_min).detach().cpu()\n",
    "lin_press = linear_transform(torch.nn.functional.pad(rec_press, (1,3,1,3)), cen) #* (-1)\n",
    "print(lin_press)\n",
    "mappable0 = ax.plot(bd[:,0], bd[:,1])\n",
    "normals = torch.stack((lin_press*nx,lin_press*ny), -1)\n",
    "for i in range(40):\n",
    "    rel_normals = cen[i,:] + normals[i,:]\n",
    "    ax.plot((cen[i,0], rel_normals[0]), (cen[i,1], rel_normals[1]))\n",
    "ax.set_xlim(24, 35)\n",
    "ax.set_ylim(32, 43)\n",
    "# ax.set_xlim(18, 28)\n",
    "# ax.set_ylim(37, 47)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9912b7d-a3df-4680-aff9-d94ef29f0778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf = PdfPages('./optimized_naca_fno_gradient.pdf')\n",
    "\n",
    "list_force = []\n",
    "list_drag_force = []\n",
    "for oiter in range(optim_iter):\n",
    "    total_x_force = 0\n",
    "    total_y_force = 0\n",
    "\n",
    "    ### Define boundary ###\n",
    "    bound = torch.cat((const_variable, opt_variable), 0).transpose(1,0).flatten()[None,:].reshape(40,2)\n",
    "\n",
    "    \n",
    "    ### update boundary ###\n",
    "    rec_bound = (((bound/2) + 0.5) * 62) + 0  \n",
    "    testdata = update_data(rec_bound, testdata, orgdata, const_variable, opt_variable)\n",
    "    raw_bound = (((testdata.param[\"n0\"].reshape(40,2)/2) + 0.5) * 62) + 0\n",
    "\n",
    "    \n",
    "    ### Perform rollout and Compute objective ###\n",
    "    for kk in range(prerollout+one_period):\n",
    "        if oiter % 50 == 49 and kk == 0 and vis_prerollout:\n",
    "            print(\"kk = 0\")\n",
    "            fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "            ax.imshow(torch.nn.functional.pad(((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min, ((1,3,1,3))).detach().cpu().numpy(), cmap='viridis',\n",
    "                     aspect='auto',\n",
    "                     origin='lower')\n",
    "            plt.show()\n",
    "\n",
    "        testdata, pred = get_data_next_step(model_fno, testdata, use_grads=False, return_data=True, is_y_diff=False)\n",
    "        press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "        \n",
    "        if oiter % 50 == 49 and kk == prerollout and vis_prerollout:\n",
    "            print(\"kk = \" + str(prerollout))\n",
    "            fig, ax = plt.subplots(figsize=(4,4), ncols=1)\n",
    "            ax.imshow(torch.nn.functional.pad(press, ((1,3,1,3))).detach().cpu().numpy(), cmap='viridis',\n",
    "                     aspect='auto',\n",
    "                     origin='lower')\n",
    "            plt.show()\n",
    "        \n",
    "        if kk >= prerollout:\n",
    "            testdata, pred = get_data_next_step(model_fno, testdata, use_grads=False, return_data=True, is_y_diff=False)\n",
    "            press = ((((pred[\"n0\"].reshape(62, 62, 1, 3)[...,0,-1])/2) + 0.5) * (p_max-p_min)) + p_min\n",
    "            x_force, y_force = compute_pressForce(torch.nn.functional.pad(press, (1,3,1,3)), raw_bound)\n",
    "            \n",
    "            total_x_force += x_force\n",
    "            total_y_force += y_force\n",
    "\n",
    "    total_x_force = total_x_force/one_period\n",
    "    total_y_force = total_y_force/one_period\n",
    "\n",
    "    list_force.append(total_y_force.item())\n",
    "    list_drag_force.append(total_x_force.item())\n",
    "\n",
    "    \n",
    "    ### Perform optimization ###\n",
    "    # output = -1/total_x_force + 5 * torch.square(-7 - total_y_force)\n",
    "    output = total_x_force \n",
    "    optimizer.zero_grad()\n",
    "    output.backward()\n",
    "    torch.nn.utils.clip_grad_value_(opt_variable, 0.01)\n",
    "    optimizer.step()\n",
    "\n",
    "    rolled_boundary = torch.roll(bound, -1, 0)\n",
    "    bd_diff = torch.abs(bound - rolled_boundary)\n",
    "    if (bd_diff > 2).sum() > 0:\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "\n",
    "        \n",
    "    ### Visualization ###\n",
    "    if oiter % 50 == 49:\n",
    "        print(\"iteration: \", oiter + 1)\n",
    "        print(\"objective: \", output)\n",
    "\n",
    "        bd = (((bound.detach().cpu().numpy()/2) + 0.5) * 62) + 0\n",
    "        length, nx, ny, cen = compute_orthonormal(torch.tensor(bd))\n",
    "        cen = cen.to(device)\n",
    "        lin_press = linear_transform(torch.nn.functional.pad(press, (1,3,1,3)), cen)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(18,3), ncols=6)\n",
    "        mappable0 = ax[0].plot(bd[:,0], bd[:,1])\n",
    "        nx = nx.detach().cpu()\n",
    "        ny = ny.detach().cpu()\n",
    "        cen = cen.detach().cpu()\n",
    "        lin_press = lin_press.cpu()\n",
    "        # print(cen.device, normals.device, lin_press.device)\n",
    "        normals = torch.stack((lin_press*nx,lin_press*ny), -1)\n",
    "        for i in range(40):\n",
    "            rel_normals = cen[i,:] + normals[i,:]\n",
    "            ax[0].plot((cen[i,0].numpy(), rel_normals[0].detach().numpy()), (cen[i,1].numpy(), rel_normals[1].detach().numpy()))\n",
    "        ax[0].set_xlim(24, 35)\n",
    "        ax[0].set_ylim(32, 43)\n",
    "        mappable1 = ax[1].imshow(testdata.node_feature[\"n0\"][:,-1,0].reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "                                 aspect='auto',\n",
    "                                 origin='lower')\n",
    "        vis_offsetmask = torch.where(testdata.node_feature[\"n0\"][:,-1,1]!=0, 1, 0)\n",
    "        mappable2 = ax[2].imshow(vis_offsetmask.reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "                                 aspect='auto',\n",
    "                                 origin='lower')        \n",
    "        mappable3 = ax[3].imshow(testdata.node_feature[\"n0\"][:,-1,0].reshape(62,62).detach().cpu().numpy()-vis_offsetmask.reshape(62,62).detach().cpu().numpy(), cmap='viridis',\n",
    "                                 aspect='auto',\n",
    "                                 origin='lower')        \n",
    "        mappable4 = ax[4].plot(np.array(list_force)[0::5])\n",
    "        mappable5 = ax[5].plot(np.array(list_drag_force)[0::5])\n",
    "        pdf.savefig()\n",
    "        plt.show()\n",
    "    \n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56efbb6-577a-4de0-b688-69c160114e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
