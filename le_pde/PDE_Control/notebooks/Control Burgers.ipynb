{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to Control Burgers Equation with Differentiable Physics\n",
    "This notebook will walk you through data generation, supervised network initialization and end-to-end training using our differentiable PDE solver, [Φ<sub>Flow</sub>](https://github.com/tum-pbs/PhiFlow).\n",
    "\n",
    "The code below replicates experiment 1 from the ICLR 2020 paper [Learning to Control PDEs with Differentiable Physics](https://ge.in.tum.de/publications/2020-iclr-holl/). The original experiment was performed on an older version of the solver, the code for which can be found under `/legacy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../PhiFlow'); sys.path.append('../src')\n",
    "from control.pde.burgers import GaussianClash, GaussianForce\n",
    "import burgers_plots as bplt\n",
    "import matplotlib.pyplot as plt\n",
    "from phi.flow import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = Domain([128], box=box[0:1])  # 1D Grid resolution and physical size\n",
    "viscosity = 0.003  # Viscosity constant for Burgers equation\n",
    "step_count = 32  # how many solver steps to perform\n",
    "dt = 0.03  # Time increment per solver step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at an example Burgers simulation with Gaussian forcing. The classes `BurgersVelocity` and `Burgers` are part of the Φ<sub>Flow</sub> library.\n",
    "\n",
    "*Hint: You can execute the cell below multiple times to get different results. Both `GaussianClash` and `GaussianForce` use random numbers internally.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set up physics ---\n",
    "world = World()\n",
    "u0 = BurgersVelocity(domain, velocity=GaussianClash(1), viscosity=viscosity)\n",
    "u = world.add(u0, physics=Burgers(diffusion_substeps=4))\n",
    "force = world.add(FieldEffect(GaussianForce(1), ['velocity']))\n",
    "# --- Plot ---\n",
    "print('Force: %f at %f' % (force.field.amp[0], force.field.loc[0]))\n",
    "bplt.burgers_figure('Training data')\n",
    "plt.plot(u.velocity.data[0,:,0], color=bplt.gradient_color(0, step_count+1), linewidth=0.8)  # data[example, values, component]\n",
    "plt.legend(['Initial state in dark red, final state in dark blue.'])\n",
    "for frame in range(1, step_count + 1):\n",
    "    world.step(dt=dt)  # runs one simulation step\n",
    "    plt.plot(u.velocity.data[0,:,0], color=bplt.gradient_color(frame, step_count+1), linewidth=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define how many examples to generate and where to store them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'forced-burgers-clash'\n",
    "scene_count = 1000  # how many examples to generate (training + validation + test)\n",
    "batch_size = 100  # How many examples to generate in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will generate and store the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch_index in range(scene_count // batch_size):\n",
    "    scene = Scene.create(data_path, count=batch_size)\n",
    "    print(scene)\n",
    "    world = World()\n",
    "    u0 = BurgersVelocity(domain, velocity=GaussianClash(batch_size), viscosity=viscosity, batch_size=batch_size, name='burgers')\n",
    "    u = world.add(u0, physics=Burgers(diffusion_substeps=4))\n",
    "    force = world.add(FieldEffect(GaussianForce(batch_size), ['velocity']))\n",
    "    scene.write(world.state, frame=0)\n",
    "    for frame in range(1, step_count + 1):\n",
    "        world.step(dt=dt)\n",
    "        scene.write(world.state, frame=frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delete the generated data, uncomment and run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for scene in Scene.list(data_path): scene.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a supervised observation loss to initialize the observation prediction (OP) networks.\n",
    "This teaches them to reproduce the simulations from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from control.pde.burgers import BurgersPDE\n",
    "from control.control_training import ControlTraining\n",
    "from control.sequences import StaggeredSequence, RefinedSequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define what part of the data is used for training, validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_range = range(100)\n",
    "val_range = range(100, 200)\n",
    "train_range = range(200, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell trains all OP$_n \\,\\, \\forall n\\in\\{2,4,8,16,32\\}$.\n",
    "The `ControlTraining` class is used to set up the optimization problem.\n",
    "\n",
    "The loss for the supervised initialization is defined as the observation loss at the center frame.\n",
    "\n",
    "$\\boldsymbol L_o^\\textrm{sup} = \\left|\\mathrm{OP}[o(t_i),o(t_j)] - u^\\textrm{GT}\\left(\\frac{t_i+t_j}{2}\\right)\\right|^2.$\n",
    "\n",
    "Consequently, no sequence needs to be simulated (`sequence_class=None`) and an observation loss is required at frame $\\frac n 2$ (`obs_loss_frames=[n // 2]`).\n",
    "The pretrained network checkpoints are stored in `supervised_checkpoints`.\n",
    "\n",
    "*Note: The next cell will run for some time. You can skip it and load the pretrained networks instead (see instructions below).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_checkpoints = {}\n",
    "\n",
    "for n in [2, 4, 8, 16, 32]:\n",
    "    app = ControlTraining(n,\n",
    "                          BurgersPDE(domain, viscosity, dt),\n",
    "                          datapath=data_path,\n",
    "                          val_range=val_range,\n",
    "                          train_range=train_range,\n",
    "                          trace_to_channel=lambda trace: 'burgers_velocity',\n",
    "                          obs_loss_frames=[n // 2],\n",
    "                          trainable_networks=['OP%d' % n],\n",
    "                          sequence_class=None,\n",
    "                          batch_size=100,\n",
    "                          view_size=20,\n",
    "                          learning_rate=1e-3,\n",
    "                          learning_rate_half_life=1000,\n",
    "                          dt=dt).prepare()\n",
    "    # show(app, force_launch=True)  # launches the Φ-Flow web interface\n",
    "    for i in range(3000):\n",
    "        app.progress()  # Run Optimization for one batch\n",
    "    supervised_checkpoints['OP%d' % n] = app.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already initialized the networks, you can simply copy the `supervised_checkpoints` by pasting the output above into the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised_checkpoints = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or load the pretrained networks that are included in the repository by uncommenting and running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised_checkpoints = {'OP%d'%n: '../networks/burgers/supervised/OP%d_3000'%n for n in [2,4,8,16,32]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have not actually set up a simulation for the training. To evaluate the quality of our current solutions, we will use the `ControlTraining` class again but this time passing a `sequence_class`.\n",
    "With a sequence class, `ControlTraining` sets up the necessary physics steps and networks.\n",
    "Example sequence classes are `StaggeredSequence` and `RefinedSequence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "supervised_staggered_app = ControlTraining(\n",
    "                            32,\n",
    "                            BurgersPDE(domain, viscosity, dt),\n",
    "                            datapath=data_path,\n",
    "                            val_range=val_range,\n",
    "                            train_range=train_range,\n",
    "                            trace_to_channel=lambda trace: 'burgers_velocity',\n",
    "                            obs_loss_frames=[],\n",
    "                            trainable_networks=[],\n",
    "                            sequence_class=StaggeredSequence,\n",
    "                            batch_size=100,\n",
    "                            view_size=20,\n",
    "                            learning_rate=1e-3,\n",
    "                            learning_rate_half_life=1000,\n",
    "                            dt=dt).prepare()\n",
    "supervised_staggered_app.load_checkpoints(supervised_checkpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at the force required to exactly match the target in our test set.\n",
    "\n",
    "*Note:* The property `'Total Force'` is created by `BurgersPDE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Force (supervised): %f' % supervised_staggered_app.infer_scalars(test_range)['Total Force'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at some of the reconstructed sequences. Change the `test_range` indices to look at different examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = supervised_staggered_app.infer_all_frames(test_range[0:1])\n",
    "bplt.burgers_figure('Supervised')\n",
    "for frame in range(0, step_count + 1):\n",
    "    plt.plot(states[frame].burgers.velocity.data[0,:,0], color=bplt.gradient_color(frame, step_count+1), linewidth=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end Training with Differentiable Physics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initiale training with the differentiable physics loss, we create a new `ControlTraining` instance with the staggered execution scheme.\n",
    "\n",
    "The following cell trains all OP networks jointly to minimize the force (see the `trainable_networks` parameter). You can increase the number of optimization steps or execute the next cell multiple times to further increase performance.\n",
    "\n",
    "*Note: The next cell will run for some time. You can skip the next two cells and load the pretrained networks instead.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staggered_app = ControlTraining(\n",
    "                            32,\n",
    "                            BurgersPDE(domain, viscosity, dt),\n",
    "                            datapath=data_path,\n",
    "                            val_range=val_range,\n",
    "                            train_range=train_range,\n",
    "                            trace_to_channel=lambda trace: 'burgers_velocity',\n",
    "                            obs_loss_frames=[],\n",
    "                            trainable_networks=['OP%d' % n for n in [2,4,8,16,32]],\n",
    "                            sequence_class=StaggeredSequence,\n",
    "                            batch_size=100,\n",
    "                            view_size=20,\n",
    "                            learning_rate=1e-3,\n",
    "                            learning_rate_half_life=1000,\n",
    "                            dt=dt).prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(3000):\n",
    "    staggered_app.progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staggered_checkpoint = staggered_app.save_model()\n",
    "staggered_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the pretrained networks included in this repository, uncomment and execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#staggered_app.load_checkpoints({'OP%d'%n: '../networks/burgers/staggered/OPn_18000' for n in [2,4,8,16,32]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the performance of our networks after end-to-end training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Force (diff. phys. / staggered): %f' % staggered_app.infer_scalars(test_range)['Total Force'])\n",
    "states = staggered_app.infer_all_frames(test_range[0:1])\n",
    "bplt.burgers_figure('Staggered execution')\n",
    "for frame in range(0, step_count + 1):\n",
    "    plt.plot(states[frame].burgers.velocity.data[0,:,0], color=bplt.gradient_color(frame, step_count+1), linewidth=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our models using the prediction refinement scheme, we repeat the above steps but using a `RefinedSequence` instead of a `StaggeredSequence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "refined_app = ControlTraining(step_count,\n",
    "                      BurgersPDE(domain, viscosity, dt),\n",
    "                      datapath=data_path,\n",
    "                      val_range=val_range,\n",
    "                      train_range=train_range,\n",
    "                      trace_to_channel=lambda trace: 'burgers_velocity',\n",
    "                      obs_loss_frames=[],\n",
    "                      trainable_networks=['OP%d' % n for n in [2,4,8,16,32]],\n",
    "                      sequence_class=RefinedSequence,\n",
    "                      batch_size=100,\n",
    "                      view_size=20,\n",
    "                      learning_rate=1e-3,\n",
    "                      learning_rate_half_life=1000,\n",
    "                      dt=dt).prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the weights we just trained, run the cell below.\n",
    "\n",
    "To load the pretrained weights, skip the next cell and uncomment and run the one after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_app.load_checkpoints({'OP%d' % n: staggered_checkpoint for n in [2,4,8,16,32]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refined_app.load_checkpoints({'OP%d'%n: '../networks/burgers/staggered/OPn_18000' for n in [2,4,8,16,32]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could still refine training at this point by repeatedly calling `refined_app.progress()`.\n",
    "Here, we show that the prediction refinement scheme beats the staggered execution, despite not being trained with that architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Force (diff. phys. / refined): %f' % refined_app.infer_scalars(test_range)['Total Force'])\n",
    "states = refined_app.infer_all_frames(test_range[0:1])\n",
    "bplt.burgers_figure('Prediction refinement')\n",
    "for frame in range(0, step_count + 1):\n",
    "    plt.plot(states[frame].burgers.velocity.data[0,:,0], color=bplt.gradient_color(frame, step_count+1), linewidth=0.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
