{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e984d0b-5834-4270-b61b-d1a0eab91f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..', '..'))\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..', '..', '..'))\n",
    "\n",
    "import io\n",
    "import argparse\n",
    "import pickle\n",
    "import random\n",
    "import pdb\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "import torch.nn.functional as F\n",
    "from deepsnap.batch import Batch as deepsnap_Batch\n",
    "from le_pde.argparser import arg_parse\n",
    "from le_pde.models import load_model, get_model\n",
    "from le_pde.utils import EXP_PATH\n",
    "from le_pde.pytorch_net.util import filter_filename, ddeepcopy as deepcopy, init_args\n",
    "from le_pde.datasets.load_dataset import load_data\n",
    "from le_pde.utils import to_tuple_shape, get_pos_dims_dict, get_device, get_precision_floor\n",
    "from le_pde.PDE_Control.legacy.phi.fluidformat import *\n",
    "from le_pde.PDE_Control.legacy.phi.flow import FluidSimulation, DomainBoundary\n",
    "from le_pde.PDE_Control.legacy.phi.math.nd import *\n",
    "from le_pde.pytorch_net.util import get_decay_list\n",
    "from le_pde.pytorch_net.util import to_np_array\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>div.output_scroll { height: unset; }</style>\"))\n",
    "\n",
    "args = arg_parse()\n",
    "args.exp_id = \"smoke\"\n",
    "args.date_time = \"2022-3-6\"\n",
    "args.dataset=\"movinggas\"\n",
    "args.n_train= \"-1\"\n",
    "args.time_interval= 1\n",
    "args.save_interval= 10\n",
    "args.algo= \"contrast\"\n",
    "args.reg_type= None\n",
    "args.reg_coef= 0\n",
    "args.is_reg_anneal= True\n",
    "args.no_latent_evo= False\n",
    "args.encoder_type= \"cnn-s\"\n",
    "args.evolution_type= \"mlp-3-elu-2\"\n",
    "args.decoder_type= \"cnn-tr\"\n",
    "args.encoder_n_linear_layers= \"0\"\n",
    "args.n_conv_blocks= 4\n",
    "args.n_latent_levs= 2\n",
    "args.n_conv_layers_latent= 3\n",
    "args.channel_mode= \"exp-16\"\n",
    "args.is_latent_flatten= False\n",
    "args.evo_groups= 1\n",
    "args.recons_coef= 1\n",
    "args.consistency_coef= 1\n",
    "args.contrastive_rel_coef= 0\n",
    "args.hinge= 0\n",
    "args.density_coef= 0.001\n",
    "args.latent_noise_amp= \"1e-5\"\n",
    "args.normalization_type= \"gn\"\n",
    "args.latent_size= 16\n",
    "args.kernel_size= 4\n",
    "args.stride= 2\n",
    "args.padding= 1\n",
    "args.padding_mode= \"zeros\"\n",
    "args.act_name= \"elu\"\n",
    "args.multi_step= \"1\"\n",
    "args.latent_multi_step= \"1\"\n",
    "args.use_grads= False\n",
    "args.use_posargs= False\n",
    "args.is_y_diff= False\n",
    "args.loss_type= \"mse\"\n",
    "args.loss_type_consistency= \"mse\"\n",
    "args.batch_size= 2\n",
    "args.val_batch_size= 8\n",
    "args.epochs= 52\n",
    "args.opt= \"adam\"\n",
    "args.weight_decay= 0\n",
    "args.disc_coef= 0\n",
    "args.seed= 0\n",
    "args.gpuid= 3\n",
    "args.id= 0\n",
    "args.is_train=False\n",
    "args.is_test_only=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83af5f4-7645-4bee-8cb5-f0eee02a024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(model, preds, info, data, is_recons):\n",
    "    \"\"\"Go to original representation.\"\"\"\n",
    "    info[\"input\"] = data.node_feature\n",
    "    precision_floor = get_precision_floor(model.loss_type)\n",
    "    if model.loss_type is not None and precision_floor is not None:\n",
    "        preds_core = {}\n",
    "        if is_recons and \"recons\" in info:\n",
    "            recons_core = {}\n",
    "        for loss_type_key in model.loss_type.split(\"^\"):\n",
    "            key = loss_type_key.split(\":\")[0]\n",
    "            if \"mselog\" in loss_type_key or \"huberlog\" in loss_type_key or \"l1log\" in loss_type_key:\n",
    "                if len(preds) > 0 and len(preds[key]) > 0:\n",
    "                    preds_core[key] = torch.exp(preds[key]) - precision_floor\n",
    "                if is_recons and \"recons\" in info:\n",
    "                    recons_core[key] = torch.exp(info[\"recons\"][key]) - precision_floor\n",
    "            else:\n",
    "                if len(preds) > 0:\n",
    "                    preds_core[key] = preds[key]\n",
    "                if is_recons and \"recons\" in info:\n",
    "                    recons_core[key] = info[\"recons\"][key]\n",
    "        preds = preds_core\n",
    "        if is_recons and \"recons\" in info:\n",
    "            info[\"recons\"] = recons_core\n",
    "    return preds, info\n",
    "\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else: return super().find_class(module, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0e8d5f-911d-4976-a692-5fac6056c6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings:\n",
    "\n",
    "exp_id = \"smoke\"\n",
    "date_time = \"2022-3-28\"\n",
    "# include is a list of strings that the filename must include \n",
    "include = [\n",
    "    \".p\",\n",
    "    \"movinggas_train_-1_algo_contrast_ebm_False_ebmt_cd_enc_cnn-s_evo_cnn_act_elu_hid_128_lo_mse_recef_1.0_conef_1.0_nconv_4_nlat_1_clat_3_lf_True_reg_None_id_0_Hash_TgzjEJou_turing4.p\",\n",
    "]\n",
    "\n",
    "# Load dataset:\n",
    "dataset_name = \"movinggas\"\n",
    "print(date_time)\n",
    "(dataset_train_val, dataset_test), (train_loader, val_loader, test_loader) = load_data(args)\n",
    "\n",
    "\n",
    "init_indices = [0]  # starting t\n",
    "n_rollout_steps = 70  # number of rollout steps\n",
    "interval = 1         # Interval to visualize\n",
    "is_test = True      # Whether to use the test dataset\n",
    "\n",
    "# Run analysis:\n",
    "dirname = \"results/\" + \"{}_{}/\".format(exp_id, date_time)\n",
    "filenames = filter_filename(dirname, include=include)\n",
    "args_list = list(arg_parse().__dict__.keys())\n",
    "dataset = deepcopy(dataset_test) if is_test else deepcopy(dataset_train_val)\n",
    "isplot=2\n",
    "n_plots_row=6\n",
    "print(filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6663575-32e9-436b-89eb-e8fa33a92210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(filenames)==0:\n",
    "    raise Exception(\"No file in the current path. Check if your current path, that is dirname, is correct!\")\n",
    "\n",
    "original_shape = dataset[0].original_shape\n",
    "is_gpu=True\n",
    "if is_gpu:\n",
    "     for filename in filenames:\n",
    "        data_record = pickle.load(open(dirname + filename, \"rb\"))\n",
    "        args = init_args(data_record[\"args\"])\n",
    "        device = \"cuda:0\"\n",
    "        #device = get_device(args)\n",
    "        print(data_record[\"best_model_dict\"][\"type\"])\n",
    "        try:\n",
    "            #pdb.set_trace()\n",
    "            model = load_model(data_record[\"best_model_dict\"], device, input_shape=original_shape)\n",
    "        except Exception as e:\n",
    "            raise\n",
    "            print(\"Cannot load '{}'\".format(filename))\n",
    "            continue\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    for filename in filenames:\n",
    "        f = open(dirname + filename, \"rb\")\n",
    "        data_record = CPU_Unpickler(f).load()\n",
    "        try:\n",
    "            model = load_model(data_record[\"best_model_dict\"], device, input_shape=original_shape)\n",
    "        except Exception as e:\n",
    "            raise\n",
    "            print(\"Cannot load '{}'\".format(filename))\n",
    "            continue\n",
    "\n",
    "model.model_dict[\"input_size\"]\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bdc5ae-4a77-4bc6-a2e4-21c7d6a8bed9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PDE_Control.legacy.phi.math.nd import *\n",
    "from PDE_Control.legacy.phi.solver.sparse import SparseCGPressureSolver\n",
    "from PDE_Control.legacy.phi.fluidformat import *\n",
    "\n",
    "def initialize_velocity():\n",
    "    vx = np.random.uniform(low=2.99, high=2.99)\n",
    "    vy = np.random.uniform(low=0., high=0.)\n",
    "    velocity_array = np.empty([129, 129, 2], np.float32)\n",
    "    velocity_array[...,0] = vx\n",
    "    velocity_array[...,1] = vy\n",
    "    init_op_velocity = StaggeredGrid(velocity_array.reshape((1,)+velocity_array.shape))\n",
    "    optimizable_velocity = init_op_velocity.staggered\n",
    "    return init_op_velocity, optimizable_velocity\n",
    "\n",
    "def apply_mask(sim, optimizable_velocity):\n",
    "    ###Set Initial Condition for Velocity###\n",
    "    control_mask = sim.ones(\"staggered\")\n",
    "    control_mask.staggered[:, 4:117, 18:-18, :] = 0\n",
    "    divergent_velocity = optimizable_velocity * control_mask.staggered\n",
    "    divergent_velocity = StaggeredGrid(divergent_velocity)\n",
    "    return divergent_velocity\n",
    "\n",
    "def plot_velocity_with_mask(divergent_velocity):\n",
    "    fig, ax = plt.subplots(figsize=(8,4),ncols=2)\n",
    "    ###Heatmap of initial velocity in x-dirction###\n",
    "    mappable0 = ax[0].imshow(divergent_velocity.staggered[0,:,:,0], cmap='viridis',\n",
    "                             #extent=[0,sensordata.shape[0],0,sensordata.shape[1]],\n",
    "                             aspect='auto',\n",
    "                             origin='lower')\n",
    "    ###Heatmap of initial velocity in y-dirction###\n",
    "    mappable1 = ax[1].imshow(divergent_velocity.staggered[0,:,:,1], cmap='viridis',\n",
    "                             #extent=[0,sensordata.shape[0],0,sensordata.shape[1]],\n",
    "                             interpolation=\"bicubic\",\n",
    "                             aspect='auto',\n",
    "                             origin='lower')\n",
    "    fig.colorbar(mappable0, ax=ax[0])\n",
    "    fig.colorbar(mappable1, ax=ax[1])\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_velocity_boundary_effect(velocity):\n",
    "    hor_velocity_array = np.empty([129, 129, 1], np.float32)\n",
    "    hor_velocity_array[...,0] = velocity.staggered[0,:,:,0]\n",
    "\n",
    "    ver_velocity_array = np.empty([129, 129, 1], np.float32)\n",
    "    ver_velocity_array[...,0] = velocity.staggered[0,:,:,1]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,4),ncols=2)\n",
    "    ###Heatmap of velocity meating equation in x-dirction###\n",
    "    mappable0 = ax[0].imshow(hor_velocity_array, cmap='viridis',\n",
    "                             #extent=[0,sensordata.shape[0],0,sensordata.shape[1]],\n",
    "                             aspect='auto',\n",
    "                             origin='lower')\n",
    "    ###Heatmap of velocity meating equation in y-dirction###\n",
    "    mappable1 = ax[1].imshow(ver_velocity_array, cmap='viridis',\n",
    "                             #extent=[0,sensordata.shape[0],0,sensordata.shape[1]],\n",
    "                             interpolation=\"bicubic\",\n",
    "                             aspect='auto',\n",
    "                             origin='lower')\n",
    "    fig.colorbar(mappable0, ax=ax[0])\n",
    "    fig.colorbar(mappable1, ax=ax[1])\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_initial_velocity(sim):\n",
    "    fig_ob, ax_ob = plt.subplots(figsize=(4,4))\n",
    "    ###Heatmap of initial velocity in x-dirction###\n",
    "    mappable_ob0 = ax_ob.imshow(sim._active_mask[0,:,:,0], cmap='viridis',\n",
    "                             #extent=[0,sensordata.shape[0],0,sensordata.shape[1]],\n",
    "                             aspect='auto',\n",
    "                             origin='lower')\n",
    "    fig_ob.colorbar(mappable_ob0, ax=ax_ob)\n",
    "    fig_ob.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_init_op_velocity(init_op_velocity):\n",
    "    fig, ax = plt.subplots(figsize=(8,4),ncols=2)\n",
    "    ###Heatmap of initial velocity in x-dirction###\n",
    "    mappable0 = ax[0].imshow(init_op_velocity.staggered[0,:,:,0], cmap='viridis',\n",
    "                             #extent=[0,sensordata.shape[0],0,sensordata.shape[1]],\n",
    "                             aspect='auto',\n",
    "                             origin='lower')\n",
    "    ###Heatmap of initial velocity in y-dirction###\n",
    "    mappable1 = ax[1].imshow(init_op_velocity.staggered[0,:,:,1], cmap='viridis',\n",
    "                             #extent=[0,sensordata.shape[0],0,sensordata.shape[1]],\n",
    "                             interpolation=\"bicubic\",\n",
    "                             aspect='auto',\n",
    "                             origin='lower')\n",
    "    fig.colorbar(mappable0, ax=ax[0])\n",
    "    fig.colorbar(mappable1, ax=ax[1])\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_vector_field(velocity):\n",
    "    fig = plt.figure()\n",
    "    x,y = np.meshgrid(np.linspace(0,128,129),np.linspace(0, 128, 129))\n",
    "    xvel = np.zeros([129]*2)\n",
    "    yvel = np.zeros([129]*2)\n",
    "    xvel[1::8,1::8] = velocity.staggered[0,1::8,1::8,0]\n",
    "    yvel[1::8,1::8] = velocity.staggered[0,1::8,1::8,1]\n",
    "\n",
    "    plt.quiver(x,y,xvel,yvel,scale=2.5, scale_units='inches')\n",
    "    plt.show()\n",
    "\n",
    "def get_beta_list(start_value, end_value, steps, mode=\"const\"):\n",
    "    if mode == \"const\":\n",
    "        beta_list = [0.051 for _ in range(steps)]\n",
    "    elif mode == \"linear\":\n",
    "        beta_list = np.linspace(start_value, end_value, steps)\n",
    "    elif mode == \"exp\":\n",
    "        beta_list = np.logspace(np.log(start_value), np.log(end_value), steps)\n",
    "    elif mode == \"cos\":\n",
    "        from plasma.pytorch_net.util import get_cosine_decay\n",
    "        beta_list = get_cosine_decay(start_value, end_value, steps)\n",
    "    else:\n",
    "        raise\n",
    "    return beta_list\n",
    "\n",
    "def diffble_map_to_grid(x0, x1, beta, hor=[], ver=[]):\n",
    "\n",
    "    grid = np.zeros([128,128], dtype=np.float32)\n",
    "\n",
    "    small = x0\n",
    "    large = x1\n",
    "\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    lineval_list = []\n",
    "    for i in range(128):\n",
    "        if i==0:\n",
    "            if i <= small:\n",
    "                thor_tensor = sigmoid((i-small)/beta)\n",
    "            elif i >= large:\n",
    "                thor_tensor = sigmoid((large-i)/beta)\n",
    "            else:\n",
    "                denominator = 1/torch.abs(i-small) + 1/torch.abs(i-large)\n",
    "                thor_tensor = sigmoid(2/(beta*denominator))\n",
    "            hor_tensor = thor_tensor\n",
    "        else:    \n",
    "            if i <= small:\n",
    "                temp_tensor = sigmoid((i-small)/beta)\n",
    "                hor_tensor = torch.cat((hor_tensor, temp_tensor))\n",
    "            elif i >= large:\n",
    "                temp_tensor = sigmoid((large-i)/beta)\n",
    "                hor_tensor = torch.cat((hor_tensor,temp_tensor))\n",
    "            else:\n",
    "                denominator = 1/torch.abs(i-small) + 1/torch.abs(i-large)\n",
    "                hor_tensor = torch.cat((hor_tensor, sigmoid(2/(beta*denominator))))\n",
    "\n",
    "    if len(hor) > 0:\n",
    "        thor_tensor = hor_tensor.reshape(1,128)\n",
    "        p2d = (0, 0, int(hor[0]), int(128 - hor[0] - 1))\n",
    "        line_ingrid = F.pad(thor_tensor, p2d, \"constant\", 0.)\n",
    "    elif len(ver) > 0:\n",
    "        thor_tensor = hor_tensor.reshape(128, 1)\n",
    "        p2d = (int(ver[0]), int(128 - ver[0] - 1), 0, 0)\n",
    "        line_ingrid = F.pad(thor_tensor, p2d, \"constant\", 0.)\n",
    "    else:\n",
    "        raise Exception(\"Either of hor or ver for diffble_map_to_grid must be non-empty.\")\n",
    "\n",
    "    return line_ingrid\n",
    "\n",
    "def continuous_bound(lx1, rx1, rx2, beta, lver=20, rver=110, bhor=4, uhor=115):\n",
    "    #left boundary\n",
    "    lx0 = torch.tensor([4. - 2.]).to(device)\n",
    "    l_inlet = torch.tensor([20.]).to(device)\n",
    "    lx2 = torch.tensor([115. + 2.]).to(device)\n",
    "\n",
    "    left_bottom = diffble_map_to_grid(lx0, lx0+lx1, beta, hor=[], ver=[lver])\n",
    "    left_upper = diffble_map_to_grid(lx0+lx1+l_inlet, lx2, beta, hor=[], ver=[lver])\n",
    "\n",
    "    #right_boundary\n",
    "    rx0 = torch.tensor([4. - 2.]).to(device)\n",
    "    r_outlet1 = torch.tensor([20.]).to(device)\n",
    "\n",
    "    r_outlet2 = torch.tensor([20.]).to(device)\n",
    "    rx3 = torch.tensor([115. + 2.]).to(device)\n",
    "\n",
    "    rx01 = torch.max(torch.cat((rx0+rx1, rx0 + 5.), -1), -1).values.reshape((1,))\n",
    "    right_bottom = diffble_map_to_grid(rx0, rx01, beta, ver=[rver])\n",
    "    rxmin = torch.max(torch.cat((rx2, torch.tensor([5.]).to(device)), -1), -1).values.reshape((1,))\n",
    "    right_middle = diffble_map_to_grid(rx01+r_outlet1, rx01+r_outlet1+rxmin, beta, ver=[rver])\n",
    "    upper_bottom = torch.min(torch.cat((rx01+r_outlet1+rxmin+r_outlet2, rx3 - 5.), -1), -1).values.reshape((1,))\n",
    "    right_upper = diffble_map_to_grid(upper_bottom, rx3, beta, ver=[rver])\n",
    "\n",
    "    #ceiling\n",
    "    ceil0 = torch.tensor([20. - 2.]).to(device)\n",
    "    ceil1 = torch.tensor([110. + 2.]).to(device)\n",
    "\n",
    "    ceiling = diffble_map_to_grid(ceil0, ceil1, beta, hor=[uhor])\n",
    "\n",
    "    #bottom\n",
    "    bott0 = torch.tensor([20. - 2.]).to(device)\n",
    "    bott1 = torch.tensor([110. + 2.]).to(device)\n",
    "\n",
    "    bottom = diffble_map_to_grid(bott0, bott1, beta, hor=[bhor])\n",
    "\n",
    "    left_bound = torch.max(torch.cat((left_bottom.reshape(left_bottom.shape+(1,)), left_upper.reshape(left_upper.shape+(1,))), -1), -1).values\n",
    "    right_bound = torch.max(\n",
    "        torch.cat(\n",
    "            (right_bottom.reshape(right_bottom.shape+(1,)),\n",
    "             right_middle.reshape(right_middle.shape+(1,)),\n",
    "             right_upper.reshape(right_upper.shape+(1,))\n",
    "            ), -1\n",
    "        ), -1\n",
    "                          ).values\n",
    "\n",
    "    lr_bound = torch.max(torch.cat((left_bound.reshape(left_bound.shape+(1,)), right_bound.reshape(right_bound.shape+(1,))), -1), -1).values\n",
    "\n",
    "    cb_bound = torch.max(torch.cat((ceiling.reshape(ceiling.shape+(1,)), bottom.reshape(bottom.shape+(1,))), -1), -1).values\n",
    "\n",
    "    full_bound = torch.max(torch.cat((lr_bound.reshape(lr_bound.shape+(1,)), cb_bound.reshape(cb_bound.shape+(1,))), -1), -1).values\n",
    "\n",
    "    return full_bound\n",
    "\n",
    "def make_thick_bound(lx1, rx1, rx2, lver=20, rver=110, bhor=4, uhor=115, beta=0.001):\n",
    "    full_bound = continuous_bound(lx1, rx1, rx2, beta)\n",
    "    full_bound_l1 = continuous_bound(lx1, rx1, rx2, beta, lver=20-1, rver=110-1, bhor=4+1, uhor=115-1)\n",
    "    full_bound_l2 = continuous_bound(lx1, rx1, rx2, beta, lver=20-2, rver=110-2, bhor=4+2, uhor=115-2)\n",
    "    full_bound_r1 = continuous_bound(lx1, rx1, rx2, beta, lver=20+1, rver=110+1, bhor=4+3, uhor=115+1)\n",
    "\n",
    "    thick_bound = torch.max(torch.cat((full_bound.reshape((128,128,1)), full_bound_l1.reshape((128,128,1)), full_bound_l2.reshape((128,128,1)), full_bound_r1.reshape((128,128,1))), -1), -1).values\n",
    "\n",
    "    return 1. - thick_bound\n",
    "\n",
    "def outlet_masks(lx1, rx1, rx2):\n",
    "    lx0 = torch.tensor([4. - 2.]).to(device)\n",
    "    l_inlet = torch.tensor([20.]).to(device)\n",
    "    lx2 = torch.tensor([115. + 2.]).to(device)\n",
    "\n",
    "    #right_boundary\n",
    "    rx0 = torch.tensor([4. - 2.]).to(device)\n",
    "    r_outlet1 = torch.tensor([20.]).to(device)\n",
    "\n",
    "    r_outlet2 = torch.tensor([20.]).to(device)\n",
    "    rx3 = torch.tensor([115. + 2.]).to(device)\n",
    "\n",
    "    rx01 = torch.max(torch.cat((rx0+rx1, rx0 + 5.), -1), -1).values.reshape((1,))\n",
    "    rxmin = torch.max(torch.cat((rx2, torch.tensor([5.]).to(device)), -1), -1).values.reshape((1,))\n",
    "    upper_bottom = torch.min(torch.cat((rx01+r_outlet1+rxmin+r_outlet2, rx3 - 5.), -1), -1).values.reshape((1,))\n",
    "\n",
    "    mask_out1 = torch.zeros((128, 128), dtype=torch.float32).to(device)\n",
    "    mask_out2 = torch.zeros((128, 128), dtype=torch.float32).to(device)\n",
    "\n",
    "    mask_out1[int(torch.round(rx01)[0])+4-2:int(torch.round(rx01)[0])+4+20+2, 108:112] = 1.\n",
    "    mask_out2[int(torch.round(rx01+r_outlet1+rxmin)[0]):int(torch.round(rx01+r_outlet1+rxmin+r_outlet2)[0])+3, 108:112] = 1.\n",
    "\n",
    "    return mask_out1, mask_out2\n",
    "\n",
    "def initialize_gas():\n",
    "    array = np.zeros([128, 128, 1], np.float32)\n",
    "    m = margin = 10\n",
    "    start_x = np.random.randint(24, 40)\n",
    "    start_y = np.random.randint(8+m, 100)\n",
    "    array[start_y:start_y+11, start_x:start_x+11, :] = 1\n",
    "    print(array.shape)\n",
    "    return array\n",
    "\n",
    "def put_gas(start_x, inlet_coord):\n",
    "    array = np.zeros([128, 128, 1], np.float32)\n",
    "    m = margin = 10\n",
    "    #start_x = np.random.randint(24, 40)\n",
    "    start_y = int(inlet_coord)\n",
    "    #start_y = inlet_coord + np.random.randint(-5, 5)\n",
    "    #start_y = np.random.randint(8+m, 100)\n",
    "    array[start_y:start_y+11, start_x:start_x+11, :] = 1\n",
    "    print(array.shape)\n",
    "    return array\n",
    "\n",
    "\n",
    "def velocity_update(np_bound):\n",
    "    sim = FluidSimulation([128]*2, DomainBoundary([(True, True), (True, True)]), force_use_masks=True)\n",
    "    sim._active_mask[0,:,:,0] = np_bound\n",
    "    sim._fluid_mask[0,:,:,0] = np_bound\n",
    "    sim._velocity_mask = sim._boundary.create_velocity_mask(sim._fluid_mask, sim._dimensions, sim._mac)\n",
    "\n",
    "    init_op_velocity, optimizable_velocity = initialize_velocity()\n",
    "    divergent_velocity = apply_mask(sim, optimizable_velocity)\n",
    "    #plot_velocity_with_mask(divergent_velocity)\n",
    "    velocity = sim.divergence_free(divergent_velocity, solver=SparseCGPressureSolver(), accuracy=1e-5)\n",
    "    velocity = sim.with_boundary_conditions(velocity)\n",
    "    vel_x = velocity.staggered[0,:-1,:-1,0]\n",
    "    vel_y = velocity.staggered[0,:-1,:-1,1]\n",
    "    return vel_x, vel_y\n",
    "\n",
    "def outlet_loss(preds, masks, preds_length):\n",
    "    gas_scenes = preds[\"n0\"][:,:,0]\n",
    "    inners1 = []\n",
    "    inners2 = []\n",
    "    for i in range(preds_length):\n",
    "        inners1.append(torch.inner(gas_scenes[:,i], masks[0].reshape(-1)))\n",
    "        inners2.append(torch.inner(gas_scenes[:,i], masks[1].reshape(-1)))\n",
    "    gas_out1 = torch.stack(inners1).sum()\n",
    "    gas_out2 = torch.stack(inners2).sum()\n",
    "\n",
    "    pred_fractions = torch.cat((gas_out1.reshape((1,)), gas_out2.reshape((1,))))\n",
    "    return torch.div(pred_fractions, pred_fractions.sum())\n",
    "\n",
    "\n",
    "init_step=89\n",
    "orgdata = deepcopy(dataset[init_step]).to(device)\n",
    "def make_data(data, thick_bound):\n",
    "    ta = thick_bound.reshape([16384, 1, 1])\n",
    "    init_gas = orgdata.node_feature[\"n0\"][:,:,1].reshape([16384, 1, 1])\n",
    "    tb = orgdata.node_feature[\"n0\"][:,:,2].reshape([16384, 1, 1])\n",
    "    tc = orgdata.node_feature[\"n0\"][:,:,3].reshape([16384, 1, 1])\n",
    "    data.node_feature[\"n0\"]=torch.cat((ta, init_gas, tb, tc), -1)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc6e86d-1f3f-453b-8b7b-f91f6f862f64",
   "metadata": {},
   "source": [
    "Parameters for Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c79ed5-04c1-41fd-9aa6-552006d45456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "#device='cuda:2'\n",
    "is_recons=False\n",
    "is_test_pred=False\n",
    "is_binary_thick_bound=False\n",
    "target_length=69\n",
    "args.latent_multi_step=str(target_length)\n",
    "iterations = 100\n",
    "time_draw=10\n",
    "args.entropy_coef = 1e+3\n",
    "preds_length=20\n",
    "drawstep=60\n",
    "loss = MSELoss()\n",
    "fdata = deepcopy(dataset[init_step]).to(device)\n",
    "stdata = deepcopy(dataset[init_step]).to(device)\n",
    "#beta=0.051\n",
    "beta_list = get_decay_list(0.1, 0.051, iterations, \"linear\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e956bd7-a00c-4109-9bf5-44071c855b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_gas(init_gas, rand=None):\n",
    "    re_gas = init_gas.reshape([128,128]).cpu().detach().numpy()\n",
    "    indices = np.where(re_gas != 0.)\n",
    "    \n",
    "    if rand != None:\n",
    "        ran_y = rand[0] # np.random.randint(-5, 5)\n",
    "        ran_x = rand[1] # np.random.randint(-5, 5)\n",
    "        new_indices = (indices[0] + ran_y, indices[1] + ran_x)\n",
    "    else:    \n",
    "        new_indices = (indices[0], indices[1])\n",
    "        \n",
    "    rand_init_gas = np.zeros([128, 128], dtype = np.float32)\n",
    "    rand_init_gas[new_indices] = re_gas[indices]\n",
    "    \n",
    "    return torch.tensor(rand_init_gas).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90721f7-bb63-4e3d-baf6-685a8180356c",
   "metadata": {},
   "source": [
    "# optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ee214-949f-49fa-bcc0-3554ccc5c629",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_samples = 20\n",
    "test_time = 20\n",
    "\n",
    "lx1_range = [79., 80.]\n",
    "rx1_range = [44., 45., 46., 47., 48., 49., 50.]\n",
    "rx2_range = [16.]\n",
    "y_direc = [-1, 0, 1]\n",
    "x_direc = [0, 1]\n",
    "\n",
    "from itertools import product\n",
    "sample_space = list(product(lx1_range, rx1_range, rx2_range, y_direc, x_direc))\n",
    "size_samspace = len(sample_space)\n",
    "\n",
    "sample_indices = np.random.choice(size_samspace, size=50, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67065258-8594-44d1-b50a-92f016528d4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_shape = dict(to_tuple_shape(fdata.original_shape))\n",
    "pos_dims = get_pos_dims_dict(original_shape)\n",
    "grid_keys = fdata.grid_keys\n",
    "\n",
    "pre_defined_fraction = torch.tensor([0.3, 0.7], dtype=torch.float32).to(device)\n",
    "\n",
    "all_pred_fractions = []\n",
    "all_test_fractions = []\n",
    "all_test_params = []\n",
    "all_losses = []\n",
    "all_times = []\n",
    "\n",
    "params_dict = {}\n",
    "for i in range(num_samples):\n",
    "    print(time.time(), \"sampled_params: \", sample_space[sample_indices[i]])\n",
    "\n",
    "    pred_fraction1 = []\n",
    "    pred_fraction2 = []\n",
    "    target_fractions1 = []\n",
    "    target_fractions2 = []\n",
    "\n",
    "    loss_list = []\n",
    "    #entropy_list = []\n",
    "\n",
    "    best_preds = None\n",
    "    best_loss = np.infty\n",
    "    best_fractions = []\n",
    "    best_params = ()\n",
    "    times = []\n",
    "\n",
    "    lx1 = torch.tensor([sample_space[sample_indices[i]][0]]).to(device)\n",
    "    lx1.requires_grad=True\n",
    "    rx1 = torch.tensor([sample_space[sample_indices[i]][1]]).to(device) #  <--- best_configuration\n",
    "    rx1.requires_grad=True\n",
    "    rx2 = torch.tensor([16.]).to(device) #  <--- best_configuration\n",
    "    rx2.requires_grad=True\n",
    "    optimizer = torch.optim.Adam([lx1, rx1, rx2], lr=3.7e-1) # <--- best_configuration\n",
    "\n",
    "    params_test = [(torch.clone(lx1).detach(), torch.clone(rx1).detach(), torch.clone(rx2).detach())]\n",
    "\n",
    "    rand = [sample_space[sample_indices[i]][3], sample_space[sample_indices[i]][4]]\n",
    "    org_gas = orgdata.node_feature[\"n0\"][:,:,1]\n",
    "    plt.imshow(to_np_array(org_gas.reshape([128,128])), origin=\"lower\")\n",
    "    plt.show()\n",
    "    for it in range(iterations):\n",
    "        print(\"iteration_\"+str(it))\n",
    "        if ((it+1)%test_time == 0):\n",
    "            params_test.append((torch.clone(lx1).detach(), torch.clone(rx1).detach(), torch.clone(rx2).detach()))\n",
    "            print(\"params_test: \", params_test)\n",
    "\n",
    "        thick_bound = make_thick_bound(lx1, rx1, rx2, beta=beta_list[it])\n",
    "        if is_binary_thick_bound:\n",
    "            binary_thick_bound = torch.where(thick_bound>0.5, 1., 0.)\n",
    "        else:\n",
    "            binary_thick_bound = thick_bound\n",
    "        np_bound = to_np_array(binary_thick_bound)\n",
    "\n",
    "        if it%time_draw==0:\n",
    "            fig_t0, axt0 = plt.subplots()\n",
    "            mappablet0 = axt0.imshow(np_bound, origin=\"lower\")\n",
    "            fig_t0.colorbar(mappablet0, ax=axt0)\n",
    "            plt.show()\n",
    "        # pdb.set_trace()\n",
    "        vel_x, vel_y = velocity_update(np_bound)\n",
    "        masks = outlet_masks(lx1, rx1, rx2)\n",
    "\n",
    "        if is_test_pred:\n",
    "            data=orgdata\n",
    "        else:\n",
    "            fdata = deepcopy(dataset[init_step]).to(device)\n",
    "            fdata = make_data(fdata, binary_thick_bound)\n",
    "            ta = fdata.node_feature[\"n0\"][:,:,0].reshape([16384, 1, 1])\n",
    "            #init_gas = fdata.node_feature[\"n0\"][:,:,1].reshape([16384, 1, 1])\n",
    "            rand_gas = randomize_gas(org_gas, rand)\n",
    "            print(\"rand_gas\")\n",
    "            plt.imshow(to_np_array(rand_gas), origin=\"lower\")\n",
    "            plt.show()\n",
    "            init_gas = rand_gas.reshape([16384,1,1])\n",
    "            tb = torch.tensor(vel_y).reshape([16384, 1, 1]).to(device)\n",
    "            tc = torch.tensor(vel_x).reshape([16384, 1, 1]).to(device)\n",
    "            fdata.node_feature[\"n0\"]=torch.cat((ta, init_gas, tb, tc), -1)\n",
    "\n",
    "            stdata = deepcopy(dataset[init_step]).to(device)\n",
    "            stdata=make_data(stdata, binary_thick_bound)\n",
    "            ta = stdata.node_feature[\"n0\"][:,:,0].reshape([16384, 1, 1])\n",
    "            init_gas = stdata.node_feature[\"n0\"][:,:,1].reshape([16384, 1, 1])\n",
    "            tb = torch.tensor(vel_y).reshape([16384, 1, 1]).to(device)\n",
    "            tc = torch.tensor(vel_x).reshape([16384, 1, 1]).to(device)\n",
    "            stdata.node_feature[\"n0\"]=ta\n",
    "\n",
    "    #     if it%time_draw==0:\n",
    "    #         size = torch.Size([1,4])\n",
    "    #         print(*size)\n",
    "    #         a = to_np_array(fdata.node_feature[\"n0\"].reshape(*original_shape[\"n0\" if \"n0\" in grid_keys else grid_keys[0]], *size))\n",
    "\n",
    "    #         fig, ax1 = plt.subplots(figsize=(16,4),ncols=4)\n",
    "    #         ###Boundary Location###\n",
    "    #         mappable0 = ax1[0].imshow(a[:,:,0,0], cmap='viridis',\n",
    "    #                                  aspect='auto',\n",
    "    #                                  origin='lower')\n",
    "    #         ax1[0].set_title('Boundary Map')\n",
    "    #         ###Heatmap of Optimized Gas Location###\n",
    "    #         mappable1 = ax1[1].imshow(a[:,:,0,1], cmap='viridis',\n",
    "    #                                  interpolation=\"bicubic\",\n",
    "    #                                  aspect='auto',\n",
    "    #                                  origin='lower')\n",
    "    #         ax1[1].set_title('Initial Location')\n",
    "    #         mappable2 = ax1[2].imshow(a[:,:,0,2], cmap='viridis',\n",
    "    #                                  interpolation=\"bicubic\",\n",
    "    #                                  aspect='auto',\n",
    "    #                                  origin='lower')\n",
    "    #         ax1[2].set_title('X-Veloctiy')\n",
    "    #         mappable3 = ax1[3].imshow(a[:,:,0,3], cmap='viridis',\n",
    "    #                                  interpolation=\"bicubic\",\n",
    "    #                                  aspect='auto',\n",
    "    #                                  origin='lower')\n",
    "    #         ax1[3].set_title('Y-Veloctiy')\n",
    "    #         fig.colorbar(mappable0, ax=ax1[0])\n",
    "    #         fig.colorbar(mappable1, ax=ax1[1])\n",
    "    #         fig.colorbar(mappable2, ax=ax1[2])\n",
    "    #         fig.colorbar(mappable3, ax=ax1[3])\n",
    "    #         fig.tight_layout()\n",
    "    #         plt.show()\n",
    "\n",
    "        t2 = time.time()\n",
    "        preds, info = model(fdata, \n",
    "                            pred_steps=np.arange(target_length-preds_length, target_length),\n",
    "                            #pred_steps=np.arange(1, n_rollout_steps+1), \n",
    "                            use_grads=args.use_grads, \n",
    "                            is_recons=is_recons, \n",
    "                            is_y_diff=args.is_y_diff, \n",
    "                            is_rollout=False,\n",
    "                            static_data=stdata\n",
    "                           )  # [n_nodes, pred_steps: n_rollout_steps, dyn_dims]\n",
    "\n",
    "        preds, info = rollout(model, preds, info, fdata, is_recons)\n",
    "        t3 = time.time()\n",
    "\n",
    "        np_pred_target = to_np_array(preds[\"n0\"].reshape(*original_shape[\"n0\" if \"n0\" in grid_keys else grid_keys[0]], *preds[\"n0\"].shape[1:]))\n",
    "        if it == drawstep:\n",
    "            pdf = PdfPages('./results/figures/predicted_trajectory.pdf')\n",
    "            for j in range(preds_length):\n",
    "                fig, ax = plt.subplots(figsize=(4,4))\n",
    "                ###Heatmap of prediction of gas location###\n",
    "                mappable0 = ax.imshow(np_pred_target[:,:,j,0], cmap='viridis',\n",
    "                                         aspect='auto',\n",
    "                                         origin='lower')\n",
    "                ax.set_title('Predicted Target')\n",
    "                fig.colorbar(mappable0, ax=ax)\n",
    "                fig.tight_layout()\n",
    "                pdf.savefig()\n",
    "                plt.show()\n",
    "            pdf.close()\n",
    "\n",
    "        #calculate fractions and loss associated with the fractions\n",
    "        pred_gas_fractions = outlet_loss(preds, masks, preds_length)    \n",
    "        output = loss(pre_defined_fraction, torch.div(pred_gas_fractions, pred_gas_fractions.sum()))\n",
    "        print(\"loss: \", output)\n",
    "\n",
    "        if is_gpu:\n",
    "            gpu_loss = output.cpu().detach().numpy()\n",
    "            gpu_fraction1 = pred_gas_fractions[0].cpu().detach().numpy()\n",
    "            gpu_fraction2 = pred_gas_fractions[1].cpu().detach().numpy()\n",
    "            if gpu_loss < best_loss:\n",
    "                best_loss = gpu_loss\n",
    "                best_preds = preds\n",
    "                best_fractions = [gpu_fraction1, gpu_fraction2]\n",
    "                best_params = (lx1, rx1, rx2)\n",
    "\n",
    "            print(pred_gas_fractions[0].cpu().detach().numpy())\n",
    "            pred_fraction1.append(gpu_fraction1)\n",
    "            target_fractions1.append(pre_defined_fraction[0].cpu().detach().numpy())\n",
    "\n",
    "            pred_fraction2.append(gpu_fraction2)\n",
    "            target_fractions2.append(pre_defined_fraction[1].cpu().detach().numpy())\n",
    "\n",
    "            loss_list.append(gpu_loss)\n",
    "\n",
    "        else:\n",
    "            loss_list.append(output.detach().numpy())\n",
    "\n",
    "        if it%time_draw==0:\n",
    "            # draw output\n",
    "            fig, ax = plt.subplots(figsize=(24,8),ncols=3)\n",
    "            x = list(range(len(loss_list)))\n",
    "            y = loss_list\n",
    "            ax[0].plot(x, y)\n",
    "            ax[0].set_yscale(\"log\", base=10)\n",
    "            ax[0].set_title(\"Loss b.w. Ground Truth and Prediced Targets\")\n",
    "            #plt.show()\n",
    "\n",
    "            x_1 = list(range(len(pred_fraction1)))\n",
    "            y_1 = pred_fraction1\n",
    "            yt_1 = target_fractions1\n",
    "            ax[1].plot(x_1, y_1)\n",
    "            ax[1].plot(x_1, yt_1, '--')\n",
    "            ax[1].set_yscale(\"log\", base=10)\n",
    "            ax[1].set_title(\"Loss b.w. Target and Prediced fractions at OUTLET 1\")\n",
    "            #plt.show()\n",
    "\n",
    "            x_2 = list(range(len(pred_fraction2)))\n",
    "            y_2 = pred_fraction2\n",
    "            yt_2 = target_fractions2\n",
    "            ax[2].plot(x_2, y_2)\n",
    "            ax[2].plot(x_2, yt_2, '--')\n",
    "            ax[2].set_yscale(\"log\", base=10)\n",
    "            ax[2].set_title(\"Loss b.w. Target and Prediced fractions at OUTLET 2\")\n",
    "            plt.show()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        t0 = time.time()\n",
    "        \n",
    "        output.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        t1 = time.time()\n",
    "        times.append([t1-t0, t3-t2])\n",
    "        # plt.plot(times)\n",
    "        # plt.show()\n",
    "\n",
    "        print(\"current parameters and their gradients\")\n",
    "        print(lx1, lx1.grad)\n",
    "        print(rx1, rx1.grad)\n",
    "        print(rx2, rx2.grad)\n",
    "\n",
    "\n",
    "    x = list(range(len(loss_list)))\n",
    "    y = loss_list\n",
    "\n",
    "    # Draw Transition of Loss\n",
    "    plt.plot(x, y)\n",
    "    plt.yscale(\"log\", base=10)\n",
    "    plt.title(\"Loss b.w. Ground Truth and Predicted Targets\")\n",
    "    plt.show()\n",
    "    \n",
    "    params_dict[str(i)] = {\n",
    "        \"initial_params\": sample_space[sample_indices[i]],\n",
    "        \"pred_fractions\": [pred_fraction1, pred_fraction2],\n",
    "        \"params_test\": params_test,\n",
    "        \"loss_list\": loss_list,\n",
    "        \"times\": times\n",
    "    }\n",
    "    all_pred_fractions.append([pred_fraction1, pred_fraction2])\n",
    "    all_test_params.append(params_test)\n",
    "    all_losses.append(loss_list)\n",
    "    all_times.append(times)\n",
    "    \n",
    "    \n",
    "with open('latent_data.pkl', 'wb') as f:\n",
    "    pickle.dump(params_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403f745-0e03-4990-8297-c75a0db00293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(all_pred_fractions), len(all_pred_fractions[0][0]))\n",
    "\n",
    "average_preds1 = []\n",
    "average_preds2 = []\n",
    "\n",
    "for j in range(iterations):\n",
    "    for k in range(2):\n",
    "        temp = []\n",
    "        for i in range(len(all_pred_fractions)): \n",
    "            temp.append(all_pred_fractions[i][k][j])\n",
    "        if k == 0:\n",
    "            average_preds1.append(np.mean(np.array(temp)))\n",
    "        if k == 1:\n",
    "            average_preds2.append(np.mean(np.array(temp)))\n",
    "\n",
    "plt.plot(average_preds1)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "plt.plot(average_preds2)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b0e232-fb0b-4b03-b0fe-90c77808dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_losses\n",
    "\n",
    "average_losses = []\n",
    "#average_times2 = []\n",
    "\n",
    "for j in range(iterations):\n",
    "    temp = []\n",
    "    for i in range(len(all_pred_fractions)): \n",
    "        temp.append(all_losses[i][j])\n",
    "    average_losses.append(np.mean(np.array(temp)))\n",
    "    \n",
    "plt.plot(average_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06a3782-f6b7-4b49-ae79-90e27f72562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_times\n",
    "\n",
    "average_times = []\n",
    "#average_times2 = []\n",
    "\n",
    "for j in range(iterations):\n",
    "    temp = []\n",
    "    for i in range(len(all_times)): \n",
    "        temp.append(sum(all_times[i][j]))\n",
    "    average_times.append(np.mean(np.array(temp)))\n",
    "    \n",
    "plt.plot(average_times)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239ff41-c176-4837-817d-ded28bd4698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_test_params), len(all_test_params[0]), len(all_test_params[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e0e78-4731-4e3b-89e2-04d32289f106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth_test(params, beta):\n",
    "\n",
    "    ims = []\n",
    "    #list_final_fractions = []\n",
    "    scenecount=1\n",
    "\n",
    "    loop=75\n",
    "    test_is_binary_thick_bound = True\n",
    "\n",
    "    #pdf = PdfPages('./dataset/figures/optimized_trajectory.pdf')\n",
    "\n",
    "    print(params)\n",
    "    lx1, rx1, rx2, yrand, xrand = params\n",
    "    rand = (yrand, xrand)\n",
    "    for scene_index in range(scenecount):\n",
    "        print(\"SCENE\"+str(scene_index))\n",
    "        thick_bound = make_thick_bound(lx1, rx1, rx2, beta=beta)\n",
    "        if test_is_binary_thick_bound:\n",
    "            binary_thick_bound = torch.where(thick_bound>0.5, 1., 0.)\n",
    "        else:\n",
    "            binary_thick_bound = thick_bound\n",
    "        np_bound = to_np_array(binary_thick_bound)\n",
    "\n",
    "        sim = FluidSimulation([128]*2, DomainBoundary([(True, True), (True, True)]), force_use_masks=True)\n",
    "        sim._active_mask[0,:,:,0] = np_bound\n",
    "        sim._fluid_mask[0,:,:,0] = np_bound\n",
    "        sim._velocity_mask = sim._boundary.create_velocity_mask(sim._fluid_mask, sim._dimensions, sim._mac)\n",
    "\n",
    "        res_sim = sim._fluid_mask.reshape((128,128))\n",
    "        boundaries = np.argwhere(res_sim==0)\n",
    "        ver_bound = boundaries[:,0]\n",
    "        hor_bound = boundaries[:,1]\n",
    "\n",
    "        x,y = np.meshgrid(np.linspace(0,128,129),np.linspace(0, 128, 129))\n",
    "\n",
    "        print(sim)\n",
    "        #plot_initial_velocity(sim)\n",
    "        init_op_velocity, optimizable_velocity = initialize_velocity()\n",
    "        #plot_init_op_velocity(init_op_velocity)\n",
    "        divergent_velocity = apply_mask(sim, optimizable_velocity)\n",
    "        #plot_velocity_with_mask(divergent_velocity)\n",
    "        velocity = sim.divergence_free(divergent_velocity, solver=SparseCGPressureSolver(), accuracy=1e-5)\n",
    "        velocity = sim.with_boundary_conditions(velocity)\n",
    "        #plot_velocity_boundary_effect(velocity)\n",
    "        #plot_vector_field(velocity)\n",
    "        org_gas = orgdata.node_feature[\"n0\"][:,:,1]\n",
    "        rand_gas = randomize_gas(org_gas, rand)\n",
    "        # init_gas = rand_gas.reshape([16384,1,1])\n",
    "        init_gas = to_np_array(rand_gas.reshape([128, 128, 1]))\n",
    "        # fig = plt.figure()\n",
    "        # plt.imshow(init_gas.reshape([128,128]), origin='lower')\n",
    "        # plt.show()\n",
    "        array = init_gas\n",
    "        init_op_density = StaggeredGrid(array)\n",
    "        init_op_density = init_op_density.staggered.reshape((1,)+init_op_density.staggered.shape)\n",
    "\n",
    "        #Advect\n",
    "        advected_density = velocity.advect(init_op_density)\n",
    "        #Visualize One-step Advected Gas\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(advected_density[0,:,:,0], origin='lower')\n",
    "        plt.show()\n",
    "\n",
    "        loop_advected_density = advected_density\n",
    "        loop_velocity = velocity\n",
    "\n",
    "        vel_array = np.empty([129, 129, 2], np.float32)\n",
    "        vel_array[...,0] = loop_velocity.staggered[0,:,:,0]\n",
    "        vel_array[...,1] = loop_velocity.staggered[0,:,:,1]\n",
    "        masks = outlet_masks(lx1, rx1, rx2)\n",
    "        masks = (to_np_array(masks[0]), to_np_array(masks[1]))\n",
    "        evaluate_densities = []\n",
    "        evaluate_timestamps = [i for i in range(loop-preds_length, loop)]\n",
    "        for frame in range(1, loop):\n",
    "            loop_advected_density = loop_velocity.advect(loop_advected_density)\n",
    "            loop_velocity = sim.divergence_free(loop_velocity, solver=SparseCGPressureSolver(), accuracy=1e-5)\n",
    "            loop_velocity = sim.with_boundary_conditions(loop_velocity)\n",
    "            vel_array = np.empty([129, 129, 2], np.float32)\n",
    "            vel_array[...,0] = loop_velocity.staggered[0,:,:,0]\n",
    "            vel_array[...,1] = loop_velocity.staggered[0,:,:,1]\n",
    "            if frame in evaluate_timestamps:\n",
    "                evaluate_densities.append(loop_advected_density[0,:,:,0].reshape(-1))\n",
    "            # if True:\n",
    "            #     fig, ax = plt.subplots()\n",
    "            #     ax.imshow(loop_advected_density[0,:,:,0], origin='lower')\n",
    "            #     ax.scatter(hor_bound, ver_bound, s=1, color=\"grey\", marker=\",\")\n",
    "            #     #pdf.savefig()\n",
    "            #     plt.show()\n",
    "        #pdf.close()    \n",
    "\n",
    "        inners1 = []\n",
    "        inners2 = []\n",
    "        for i in range(preds_length):\n",
    "            inners1.append(np.inner(to_np_array(evaluate_densities[i]), masks[0].reshape(-1)))\n",
    "            inners2.append(np.inner(to_np_array(evaluate_densities[i]), masks[1].reshape(-1)))\n",
    "        sim_gas_out1 = np.stack(inners1).sum()\n",
    "        sim_gas_out2 = np.stack(inners2).sum()\n",
    "\n",
    "        sim_pred_fractions = np.concatenate((sim_gas_out1.reshape((1,)), sim_gas_out2.reshape((1,))))\n",
    "        final_fractions = np.divide(sim_pred_fractions, sim_pred_fractions.sum())\n",
    "        print(\"final ratio over outlets: \", final_fractions)\n",
    "        #list_final_fractions.append(final_fractions)\n",
    "    return final_fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7149fa15-78be-4876-a58c-ebf9366418ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_beta = []\n",
    "for i in range(len(params_test)):\n",
    "    if i == 0:\n",
    "        index_beta.append(beta_list[0])\n",
    "    else: \n",
    "        index_beta.append(beta_list[test_time*i - 1])\n",
    "\n",
    "all_fractions_test = []\n",
    "for params_test in all_test_params:\n",
    "    index = all_test_params.index(params_test)\n",
    "    print(index)\n",
    "    rand_direc = (sample_space[sample_indices[index]][3], sample_space[sample_indices[index]][4])\n",
    "    fractions_test = [ground_truth_test(params_test[j]+rand_direc , index_beta[j]) for j in range(len(params_test))]\n",
    "    all_fractions_test.append(fractions_test)\n",
    "\n",
    "test_fractions_dict = {\"all_fractions_test\": all_fractions_test}\n",
    "with open('latent_test_results.pkl', 'wb') as f:\n",
    "    pickle.dump(test_fractions_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504384ec-8144-4494-beaa-8e33ffbbb238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(all_fractions_test), len(all_fractions_test[0]), len(all_fractions_test[0][0]))\n",
    "print(test_time+1)\n",
    "#all_pred_fractions\n",
    "\n",
    "average_testpreds1 = []\n",
    "average_testpreds2 = []\n",
    "\n",
    "for j in range(int(iterations/test_time)+1):\n",
    "    for k in range(2):\n",
    "        temp = []\n",
    "        for i in range(len(all_fractions_test)): \n",
    "            temp.append(all_fractions_test[i][j][k])\n",
    "        if k == 0:\n",
    "            average_testpreds1.append(np.mean(np.array(temp)))\n",
    "        if k == 1:\n",
    "            average_testpreds2.append(np.mean(np.array(temp)))\n",
    "\n",
    "plt.plot(average_testpreds1)\n",
    "plt.show()\n",
    "plt.plot(average_testpreds2)\n",
    "plt.show()\n",
    "\n",
    "average_fractions_test = [average_testpreds1, average_testpreds2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d42fd3-d0d0-414d-8e90-8a88a1dd55cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "deviations1 = []\n",
    "deviations2 = []\n",
    "for j in range(iterations):\n",
    "    for k in range(2):\n",
    "        temp = []\n",
    "        for i in range(len(all_pred_fractions)): \n",
    "            temp.append(all_pred_fractions[i][k][j])\n",
    "        if k == 0:\n",
    "            deviations1.append(np.std(temp))\n",
    "        elif k == 1:\n",
    "            deviations2.append(np.std(temp))\n",
    "            \n",
    "len(deviations1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef5c7ab-fc77-4a4c-b7e4-af12d04eaf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.arange(iterations)\n",
    "\n",
    "fractions_lower = []\n",
    "\n",
    "for i in range(iterations):\n",
    "    if i == 0:\n",
    "        fractions_lower.append(average_fractions_test[0][i])\n",
    "    elif i%test_time == test_time - 1:\n",
    "        print((i+1)/20)\n",
    "        fractions_lower.append(average_fractions_test[0][int((i+1)/20)])\n",
    "    else:\n",
    "        fractions_lower.append(None)\n",
    "        \n",
    "series1 = np.array(fractions_lower).astype(np.double)\n",
    "s1mask = np.isfinite(series1)\n",
    "\n",
    "test_deviations1 = []\n",
    "for j in range(int(iterations/test_time)+1):\n",
    "    for k in range(2):\n",
    "        temp = []\n",
    "        for i in range(len(all_fractions_test)): \n",
    "            temp.append(all_fractions_test[i][j][k])\n",
    "        if k == 0:\n",
    "            test_deviations1.append(np.std(temp))\n",
    "        #if k == 1:\n",
    "        #    average_testpreds2.append(np.mean(np.array(temp)))      \n",
    "len(test_deviations1)\n",
    "\n",
    "error_deviations = []\n",
    "for i in range(iterations):\n",
    "    if i == 0:\n",
    "        error_deviations.append(test_deviations1[i])\n",
    "    elif i%test_time == test_time - 1:\n",
    "        print((i+1)/20)\n",
    "        error_deviations.append(test_deviations1[int((i+1)/20)])\n",
    "    else:\n",
    "        error_deviations.append(0.)\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "plt.ylim(-0.1,1.)\n",
    "ax.plot(xs[s1mask], series1[s1mask], linestyle='-', marker='o', color=\"orange\", label=\"Ground Truth\")\n",
    "ax.errorbar(xs[s1mask], series1[s1mask], yerr = test_deviations1, color=\"orange\")\n",
    "ax.plot(xs, average_preds1,color=\"blue\", label=\"Predicted values\") \n",
    "ax.errorbar(xs, average_preds1, yerr=deviations1, color=\"blue\")\n",
    "#ax.set_yticks([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"fraction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d483eba-3372-46cb-a25c-c54198e86d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###Multiple Advections of Gas###\n",
    "ims = []\n",
    "\n",
    "scenecount=1\n",
    "\n",
    "loop=75\n",
    "test_is_binary_thick_bound = True\n",
    "\n",
    "#pdf = PdfPages('./dataset/figures/optimized_trajectory.pdf')\n",
    "\n",
    "print(best_params)\n",
    "lx1, rx1, rx2 = best_params\n",
    "for scene_index in range(scenecount):\n",
    "    print(\"SCENE\"+str(scene_index))\n",
    "    thick_bound = make_thick_bound(lx1, rx1, rx2, beta=0.051)\n",
    "    if test_is_binary_thick_bound:\n",
    "        binary_thick_bound = torch.where(thick_bound>0.5, 1., 0.)\n",
    "    else:\n",
    "        binary_thick_bound = thick_bound\n",
    "    np_bound = to_np_array(binary_thick_bound)\n",
    "\n",
    "    sim = FluidSimulation([128]*2, DomainBoundary([(True, True), (True, True)]), force_use_masks=True)\n",
    "    sim._active_mask[0,:,:,0] = np_bound\n",
    "    sim._fluid_mask[0,:,:,0] = np_bound\n",
    "    sim._velocity_mask = sim._boundary.create_velocity_mask(sim._fluid_mask, sim._dimensions, sim._mac)\n",
    "\n",
    "    res_sim = sim._fluid_mask.reshape((128,128))\n",
    "    boundaries = np.argwhere(res_sim==0)\n",
    "    ver_bound = boundaries[:,0]\n",
    "    hor_bound = boundaries[:,1]\n",
    "\n",
    "    x,y = np.meshgrid(np.linspace(0,128,129),np.linspace(0, 128, 129))\n",
    "\n",
    "    print(sim)\n",
    "    plot_initial_velocity(sim)\n",
    "    init_op_velocity, optimizable_velocity = initialize_velocity()\n",
    "    plot_init_op_velocity(init_op_velocity)\n",
    "    divergent_velocity = apply_mask(sim, optimizable_velocity)\n",
    "    plot_velocity_with_mask(divergent_velocity)\n",
    "    velocity = sim.divergence_free(divergent_velocity, solver=SparseCGPressureSolver(), accuracy=1e-5)\n",
    "    velocity = sim.with_boundary_conditions(velocity)\n",
    "    plot_velocity_boundary_effect(velocity)\n",
    "    plot_vector_field(velocity)\n",
    "    init_gas = to_np_array(orgdata.node_feature[\"n0\"][:,:,1].reshape([128, 128, 1]))\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(init_gas.reshape([128,128]), origin='lower')\n",
    "    plt.show()\n",
    "    array = init_gas\n",
    "    init_op_density = StaggeredGrid(array)\n",
    "    init_op_density = init_op_density.staggered.reshape((1,)+init_op_density.staggered.shape)\n",
    "\n",
    "    #Advect\n",
    "    advected_density = velocity.advect(init_op_density)\n",
    "    #Visualize One-step Advected Gas\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(advected_density[0,:,:,0], origin='lower')\n",
    "    plt.show()\n",
    "\n",
    "    loop_advected_density = advected_density\n",
    "    loop_velocity = velocity\n",
    "\n",
    "    vel_array = np.empty([129, 129, 2], np.float32)\n",
    "    vel_array[...,0] = loop_velocity.staggered[0,:,:,0]\n",
    "    vel_array[...,1] = loop_velocity.staggered[0,:,:,1]\n",
    "    masks = outlet_masks(lx1, rx1, rx2)\n",
    "    masks = (to_np_array(masks[0]), to_np_array(masks[1]))\n",
    "    evaluate_densities = []\n",
    "    evaluate_timestamps = [i for i in range(loop-preds_length, loop)]\n",
    "    for frame in range(1, loop):\n",
    "        loop_advected_density = loop_velocity.advect(loop_advected_density)\n",
    "        loop_velocity = sim.divergence_free(loop_velocity, solver=SparseCGPressureSolver(), accuracy=1e-5)\n",
    "        loop_velocity = sim.with_boundary_conditions(loop_velocity)\n",
    "        vel_array = np.empty([129, 129, 2], np.float32)\n",
    "        vel_array[...,0] = loop_velocity.staggered[0,:,:,0]\n",
    "        vel_array[...,1] = loop_velocity.staggered[0,:,:,1]\n",
    "        if frame in evaluate_timestamps:\n",
    "            evaluate_densities.append(loop_advected_density[0,:,:,0].reshape(-1))\n",
    "        if True:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(loop_advected_density[0,:,:,0], origin='lower')\n",
    "            ax.scatter(hor_bound, ver_bound, s=1, color=\"grey\", marker=\",\")\n",
    "            #pdf.savefig()\n",
    "            plt.show()\n",
    "    #pdf.close()    \n",
    "\n",
    "    inners1 = []\n",
    "    inners2 = []\n",
    "    for i in range(preds_length):\n",
    "        inners1.append(np.inner(to_np_array(evaluate_densities[i]), masks[0].reshape(-1)))\n",
    "        inners2.append(np.inner(to_np_array(evaluate_densities[i]), masks[1].reshape(-1)))\n",
    "    sim_gas_out1 = np.stack(inners1).sum()\n",
    "    sim_gas_out2 = np.stack(inners2).sum()\n",
    "\n",
    "    sim_pred_fractions = np.concatenate((sim_gas_out1.reshape((1,)), sim_gas_out2.reshape((1,))))\n",
    "    final_fractions = np.divide(sim_pred_fractions, sim_pred_fractions.sum())\n",
    "    print(\"final ratio over outlets: \", final_fractions)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d752af3-7b36-44ed-a22b-16d5ebe8ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18536f0c-217a-403f-a4fc-e64f60aeaa4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###Multiple Advections of Gas###\n",
    "ims = []\n",
    "\n",
    "scenecount=1\n",
    "\n",
    "loop=75\n",
    "test_is_binary_thick_bound = True\n",
    "\n",
    "#pdf = PdfPages('./dataset/figures/optimized_trajectory.pdf')\n",
    "\n",
    "print(best_params)\n",
    "lx1, rx1, rx2 = params_test[0]\n",
    "for scene_index in range(scenecount):\n",
    "    print(\"SCENE\"+str(scene_index))\n",
    "    thick_bound = make_thick_bound(lx1, rx1, rx2, beta=0.051)\n",
    "    if test_is_binary_thick_bound:\n",
    "        binary_thick_bound = torch.where(thick_bound>0.5, 1., 0.)\n",
    "    else:\n",
    "        binary_thick_bound = thick_bound\n",
    "    np_bound = to_np_array(binary_thick_bound)\n",
    "\n",
    "    sim = FluidSimulation([128]*2, DomainBoundary([(True, True), (True, True)]), force_use_masks=True)\n",
    "    sim._active_mask[0,:,:,0] = np_bound\n",
    "    sim._fluid_mask[0,:,:,0] = np_bound\n",
    "    sim._velocity_mask = sim._boundary.create_velocity_mask(sim._fluid_mask, sim._dimensions, sim._mac)\n",
    "\n",
    "    res_sim = sim._fluid_mask.reshape((128,128))\n",
    "    boundaries = np.argwhere(res_sim==0)\n",
    "    ver_bound = boundaries[:,0]\n",
    "    hor_bound = boundaries[:,1]\n",
    "\n",
    "    x,y = np.meshgrid(np.linspace(0,128,129),np.linspace(0, 128, 129))\n",
    "\n",
    "    print(sim)\n",
    "    plot_initial_velocity(sim)\n",
    "    init_op_velocity, optimizable_velocity = initialize_velocity()\n",
    "    plot_init_op_velocity(init_op_velocity)\n",
    "    divergent_velocity = apply_mask(sim, optimizable_velocity)\n",
    "    plot_velocity_with_mask(divergent_velocity)\n",
    "    velocity = sim.divergence_free(divergent_velocity, solver=SparseCGPressureSolver(), accuracy=1e-5)\n",
    "    velocity = sim.with_boundary_conditions(velocity)\n",
    "    plot_velocity_boundary_effect(velocity)\n",
    "    plot_vector_field(velocity)\n",
    "    init_gas = to_np_array(orgdata.node_feature[\"n0\"][:,:,1].reshape([128, 128, 1]))\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(init_gas.reshape([128,128]), origin='lower')\n",
    "    plt.show()\n",
    "    array = init_gas\n",
    "    init_op_density = StaggeredGrid(array)\n",
    "    init_op_density = init_op_density.staggered.reshape((1,)+init_op_density.staggered.shape)\n",
    "\n",
    "    #Advect\n",
    "    advected_density = velocity.advect(init_op_density)\n",
    "    #Visualize One-step Advected Gas\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(advected_density[0,:,:,0], origin='lower')\n",
    "    plt.show()\n",
    "\n",
    "    loop_advected_density = advected_density\n",
    "    loop_velocity = velocity\n",
    "\n",
    "    vel_array = np.empty([129, 129, 2], np.float32)\n",
    "    vel_array[...,0] = loop_velocity.staggered[0,:,:,0]\n",
    "    vel_array[...,1] = loop_velocity.staggered[0,:,:,1]\n",
    "    masks = outlet_masks(lx1, rx1, rx2)\n",
    "    masks = (to_np_array(masks[0]), to_np_array(masks[1]))\n",
    "    evaluate_densities = []\n",
    "    evaluate_timestamps = [i for i in range(loop-preds_length, loop)]\n",
    "    for frame in range(1, loop):\n",
    "        loop_advected_density = loop_velocity.advect(loop_advected_density)\n",
    "        loop_velocity = sim.divergence_free(loop_velocity, solver=SparseCGPressureSolver(), accuracy=1e-5)\n",
    "        loop_velocity = sim.with_boundary_conditions(loop_velocity)\n",
    "        vel_array = np.empty([129, 129, 2], np.float32)\n",
    "        vel_array[...,0] = loop_velocity.staggered[0,:,:,0]\n",
    "        vel_array[...,1] = loop_velocity.staggered[0,:,:,1]\n",
    "        if frame in evaluate_timestamps:\n",
    "            evaluate_densities.append(loop_advected_density[0,:,:,0].reshape(-1))\n",
    "        if True:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(loop_advected_density[0,:,:,0], origin='lower')\n",
    "            ax.scatter(hor_bound, ver_bound, s=1, color=\"grey\", marker=\",\")\n",
    "            #pdf.savefig()\n",
    "            plt.show()\n",
    "    #pdf.close()    \n",
    "\n",
    "    inners1 = []\n",
    "    inners2 = []\n",
    "    for i in range(preds_length):\n",
    "        inners1.append(np.inner(to_np_array(evaluate_densities[i]), masks[0].reshape(-1)))\n",
    "        inners2.append(np.inner(to_np_array(evaluate_densities[i]), masks[1].reshape(-1)))\n",
    "    sim_gas_out1 = np.stack(inners1).sum()\n",
    "    sim_gas_out2 = np.stack(inners2).sum()\n",
    "\n",
    "    sim_pred_fractions = np.concatenate((sim_gas_out1.reshape((1,)), sim_gas_out2.reshape((1,))))\n",
    "    final_fractions = np.divide(sim_pred_fractions, sim_pred_fractions.sum())\n",
    "    print(\"final ratio over outlets: \", final_fractions)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lepde",
   "language": "python",
   "name": "lepde"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
