{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import OrderedDict\n",
    "import datetime\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pylab as plt\n",
    "from numbers import Number\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 1500\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.width = 1000\n",
    "pd.set_option('max_colwidth', 400)\n",
    "# import pdb\n",
    "import pickle\n",
    "import pprint as pp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from deepsnap.batch import Batch as deepsnap_Batch\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..', '..'))\n",
    "from le_pde.argparser import arg_parse\n",
    "from le_pde.datasets.load_dataset import load_data\n",
    "from le_pde.models import load_model, rollout#, rollout_plasma, plot_vlasov\n",
    "from le_pde.pytorch_net.util import to_np_array, get_pdict, reshape_weight_to_matrix, ddeepcopy as deepcopy, plot_vectors, record_data, filter_filename, Early_Stopping, str2bool, get_filename_short, print_banner, plot_matrices, get_num_params, init_args, filter_kwargs, to_string, COLOR_LIST\n",
    "from le_pde.utils import update_legacy_default_hyperparam, EXP_PATH\n",
    "from le_pde.utils import to_cpu, to_tuple_shape, parse_multi_step, loss_op, get_cholesky_inverse, get_device, get_data_comb\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    model,\n",
    "    dataset,\n",
    "    args,\n",
    "    init_indices,\n",
    "    n_rollout_steps=100,\n",
    "    interval=20,\n",
    "    n_plots_row=6,\n",
    "    max_shift=50,\n",
    "    dataset_name=None,\n",
    "    isplot=0,\n",
    "):\n",
    "    def plot_loss_summary(loss_list_dict_all):\n",
    "        fontsize = 16\n",
    "        for key, loss_list in loss_list_dict_all.items():\n",
    "            loss_list_mean = loss_list.mean(0)\n",
    "            loss_list_std = loss_list.std(0)\n",
    "            plt.figure(figsize=(8,6))\n",
    "            for k in range(loss_list.shape[-1]):\n",
    "                plt.errorbar(np.arange(loss_list_mean.shape[0]), loss_list_mean[:, k], yerr=loss_list_std[:, k], alpha=0.6, label=\"{}\".format(k))\n",
    "            plt.xlabel(\"rollout_step\", fontsize=fontsize)\n",
    "            plt.ylabel(\"MAE\", fontsize=fontsize)\n",
    "            plt.tick_params(labelsize=fontsize)\n",
    "            plt.title(\"Species '{}' Summary MAE vs. rollout steps\".format(key), fontsize=fontsize)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "    model.eval()\n",
    "    for i, init_step in enumerate(init_indices):\n",
    "        (preds, target), losses_rollout_all, info = rollout(\n",
    "            dataset,\n",
    "            init_step=int(init_step),\n",
    "            model=model,\n",
    "            device=device,\n",
    "            algo=args.algo,\n",
    "            n_rollout_steps=n_rollout_steps,\n",
    "            interval=interval,\n",
    "            n_plots_row=n_plots_row,\n",
    "            use_grads=args.use_grads,\n",
    "            is_y_diff=args.is_y_diff,\n",
    "            loss_type=args.loss_type,\n",
    "            dataset_name=dataset_name,\n",
    "            isplot=isplot,\n",
    "        )\n",
    "        if i == 0:\n",
    "            preds_all = {key: [] for key in preds}\n",
    "            target_all = {key: [] for key in target}\n",
    "            loss_list_dict_all = {key: [] for key in preds}\n",
    "            MAE_list_dict_all = {key: [] for key in preds}\n",
    "        for key in preds_all:\n",
    "            preds_all[key].append(preds[key])\n",
    "            target_all[key].append(target[key])\n",
    "            loss_list_dict_all[key].append(losses_rollout_all[\"loss_list_dict\"][key])\n",
    "            MAE_list_dict_all[key].append(losses_rollout_all[\"MAE_list_dict\"][key])\n",
    "\n",
    "    for key in preds_all:\n",
    "        preds_all[key] = np.stack(preds_all[key])  # [n_indices, n_rollout_steps, n_nodes, dyn_dims]\n",
    "        target_all[key] = np.stack(target_all[key])   # [n_indices, n_rollout_steps, n_nodes, dyn_dims]\n",
    "        loss_list_dict_all[key] = np.stack(loss_list_dict_all[key])  # [n_indices, n_rollout_steps, dyn_dims]\n",
    "        MAE_list_dict_all[key] = np.stack(MAE_list_dict_all[key])  # [n_indices, n_rollout_steps, dyn_dims]\n",
    "\n",
    "    # Plot summary:\n",
    "    plot_loss_summary(MAE_list_dict_all)\n",
    "    for key in preds_all:\n",
    "        for dyn_dim in range(preds_all[key].shape[-1]):\n",
    "            print(\"Species '{}' autocorrelation dim={}:\".format(key, dyn_dim))\n",
    "            get_auto_correlation(preds_all[key][..., dyn_dim], target_all[key][..., dyn_dim], max_shift=max_shift, isplot=True)\n",
    "    return (preds_all, target_all, loss_list_dict_all, MAE_list_dict_all), info\n",
    "\n",
    "\n",
    "def get_auto_correlation(array, array_gt, max_shift=30, isplot=True):\n",
    "    def auto_correlation(array, shift):\n",
    "        ac = (np.roll(array, shift, axis=-1) * array).mean(-1)\n",
    "        return ac\n",
    "\n",
    "    ac_list = []\n",
    "    ac_gt_list = []\n",
    "    for shift in range(max_shift):\n",
    "        ac = auto_correlation(array, shift)\n",
    "        ac_gt = auto_correlation(array_gt, shift)\n",
    "        ac_list.append(ac)\n",
    "        ac_gt_list.append(ac_gt)\n",
    "    ac_list = np.stack(ac_list, -1)\n",
    "    ac_gt_list = np.stack(ac_gt_list, -1)\n",
    "\n",
    "    mean_idx = tuple(range(len(ac_list.shape)-1))\n",
    "    info = {}\n",
    "    info[\"ac_mean\"] = ac_list.mean(mean_idx)\n",
    "    info[\"ac_std\"] = ac_list.std(mean_idx)\n",
    "    info[\"ac_gt_mean\"] = ac_gt_list.mean(mean_idx)\n",
    "    info[\"ac_gt_std\"] = ac_gt_list.std(mean_idx)\n",
    "\n",
    "    if isplot:\n",
    "        fontsize = 14\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.errorbar(np.arange(len(info[\"ac_mean\"])), info[\"ac_mean\"], info[\"ac_std\"], capsize=3, elinewidth=2, markeredgewidth=1, label='pred', alpha=0.5)\n",
    "        plt.errorbar(np.arange(len(info[\"ac_gt_mean\"])), info[\"ac_gt_mean\"], info[\"ac_gt_std\"], capsize=3, elinewidth=2, markeredgewidth=1, label='gt', alpha=0.5)\n",
    "        plt.legend(bbox_to_anchor=[1,1], fontsize=fontsize)\n",
    "        plt.xlabel(\"$\\Delta x$\", fontsize=fontsize)\n",
    "        plt.ylabel(\"autocorrelation\", fontsize=fontsize)\n",
    "        plt.tick_params(labelsize=fontsize)\n",
    "        plt.show()\n",
    "    return info\n",
    "\n",
    "def get_df(\n",
    "    filenames,\n",
    "    dataset,\n",
    "    arg_list,\n",
    "    init_indices,\n",
    "    dataset_name,\n",
    "    analysis_metrics=[\"loss\", \"recons\", \"svd-latent\", \"svd-evo\", \"rollout\"],\n",
    "    n_rollout_steps=100,\n",
    "    interval=20,\n",
    "    n_plots_row=6,\n",
    "    isplot=1,\n",
    "):\n",
    "    df_dict_list = []\n",
    "    info_all = {}\n",
    "    original_shape = dataset[0].original_shape\n",
    "    for filename in filenames:\n",
    "        if isplot >= 1:\n",
    "            print_banner(filename, banner_size=140)\n",
    "        data_record = pickle.load(open(dirname + filename, \"rb\"))\n",
    "        if \"epoch\" not in data_record:\n",
    "            continue\n",
    "        if data_record[\"epoch\"][-1] < 5:\n",
    "            print(\"The epoch {} of {} is smaller than 5. Skip.\".format(data_record[\"epoch\"][-1], filename))\n",
    "            continue\n",
    "        try:\n",
    "            model = load_model(data_record[\"best_model_dict\"], device, input_shape=original_shape)\n",
    "        except Exception as e:\n",
    "            raise\n",
    "            print(\"Cannot load '{}'\".format(filename))\n",
    "            continue\n",
    "\n",
    "        # kwargs:\n",
    "        df_dict = data_record[\"args\"]\n",
    "        args = init_args(data_record[\"args\"])\n",
    "        df_dict = update_legacy_default_hyperparam(df_dict)\n",
    "        if df_dict[\"disc_coef\"] > 0:\n",
    "            discriminator = load_model(data_record[\"best_disc_model_dict\"], device)\n",
    "        else:\n",
    "            discriminator = None\n",
    "        df_dict[\"filename\"] = filename\n",
    "        kwargs = filter_kwargs(data_record[\"args\"], arg_list)\n",
    "        if len(kwargs) < len(arg_list):\n",
    "            print(\"{} in the arg_list are not in the data_record's args!\".format(set(arg_list) - set(kwargs.keys())))\n",
    "        if isplot >= 1:\n",
    "            pp.pprint(kwargs)\n",
    "\n",
    "        # Best epoch:\n",
    "        best_epoch = df_dict[\"best_epoch\"] = data_record[\"best_epoch\"]\n",
    "        if best_epoch != np.argmin(data_record[\"val_loss\"]):\n",
    "            print(\"saved best epoch {} does not equal the best epoch {} in val_loss!\".format(best_epoch, np.argmin(data_record[\"val_loss\"])))\n",
    "        df_dict[\"epoch\"] = len(data_record[\"train_loss\"])\n",
    "        print(\"\\nbest_epoch:\\t{}/{}\".format(df_dict[\"best_epoch\"], df_dict[\"epoch\"]))\n",
    "\n",
    "        # Loss:\n",
    "        print(\"losses (best, last, median):\")\n",
    "        #pdb.set_trace()\n",
    "        for key in data_record:\n",
    "            if \"loss\" in key and \"history\" not in key and type(data_record[key])==list:\n",
    "                df_dict[\"{}_l\".format(key)] = data_record[key][-1]\n",
    "                df_dict[\"{}_b\".format(key)] = data_record[key][best_epoch]\n",
    "                df_dict[key] = data_record[key]\n",
    "                print(\"{0}  \\t{1:.3e}     {2:.3e}     {3:.3e}\".format(\"{}:\".format(key).ljust(20), df_dict[\"{}_b\".format(key)], df_dict[\"{}_l\".format(key)], np.median(data_record[key])))\n",
    "        # Plot learning curve:\n",
    "        if isplot >= 1:\n",
    "            #pdb.set_trace()\n",
    "            plot_vectors(\n",
    "                Dict=filter_kwargs(data_record, contains=\"loss\"),\n",
    "                x_range=data_record[\"epoch\"],\n",
    "                xlabel=\"epoch\",\n",
    "                ylabel=data_record[\"args\"][\"loss_type\"],\n",
    "                linestyle_dict={\"tr\": \"--\", \"val\": \":\", \"te\": \"-\"},\n",
    "                alpha=0.9,\n",
    "            )\n",
    "\n",
    "        # Plot reconstruction:\n",
    "        if \"recons\" in analysis_metrics:\n",
    "            data_4_recons = deepcopy(dataset[init_indices[0]]).to(device)\n",
    "            try:\n",
    "                preds, info = model(\n",
    "                    data_4_recons,\n",
    "                    pred_steps=[],\n",
    "                    latent_pred_steps=[],\n",
    "                    is_recons=True,\n",
    "                    use_grads=args.use_grads,\n",
    "                    is_y_diff=args.is_y_diff,\n",
    "                    use_pos=args.use_pos,\n",
    "                    latent_noise_amp=0,\n",
    "                    reg_type=args.reg_type if args.reg_coef > 0 else \"None\",\n",
    "                    is_rollout=True,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                raise\n",
    "                print(\"Error {} happen when running {}.\".format(e, filename))\n",
    "                continue\n",
    "\n",
    "        # Rollout:\n",
    "        if \"rollout\" in analysis_metrics:\n",
    "            dyn_dims_dict = dict(dataset[0].dyn_dims)\n",
    "            (preds_all, target_all, loss_list_dict_all, MAE_list_dict_all), info_rollout = evaluate(\n",
    "                model=model,\n",
    "                dataset=dataset,\n",
    "                args=args,\n",
    "                init_indices=init_indices,\n",
    "                n_rollout_steps=n_rollout_steps,\n",
    "                interval=interval,\n",
    "                n_plots_row=n_plots_row,\n",
    "                isplot=isplot,\n",
    "                dataset_name=dataset_name,\n",
    "            )\n",
    "            info_rollout[\"model\"] = model\n",
    "            info_rollout[\"discriminator\"] = discriminator\n",
    "            info_rollout[\"rollout_MSE_list\"] = loss_list_dict_all\n",
    "            info_rollout[\"rollout_MAE_list\"] = MAE_list_dict_all\n",
    "            info_rollout[\"rollout_preds_all\"] = preds_all\n",
    "            info_rollout[\"rollout_target_all\"] = target_all\n",
    "            info_all[filename] = info_rollout\n",
    "\n",
    "            for key, dyn_dims in dyn_dims_dict.items():\n",
    "                for i in range(interval, n_rollout_steps+interval, interval):\n",
    "                    for metric in [\"MAE\", \"MSE\"]:\n",
    "                        df_dict[\"{}_{}_rollout_{}\".format(key, metric, i)] = np.mean(info_rollout[\"rollout_{}_list\".format(metric)][key].mean(0)[i-1])\n",
    "                        df_dict[\"{}_{}_rollout_{}_std\".format(key, metric, i)] = np.mean(info_rollout[\"rollout_{}_list\".format(metric)][key].std(0)[i-1])\n",
    "                        for k in range(dyn_dims):\n",
    "                            df_dict[\"{}_{}_rollout_{}_{}\".format(key, metric, i, k)] = info_rollout[\"rollout_{}_list\".format(metric)][key].mean(0)[i-1][k]\n",
    "\n",
    "        # Save:\n",
    "        df_dict_list.append(df_dict)\n",
    "    df = pd.DataFrame(df_dict_list)\n",
    "    return df, info_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = arg_parse()\n",
    "args.exp_id = \"smoke\"\n",
    "args.date_time = \"2022-3-11\"\n",
    "args.dataset=\"movinggas\"\n",
    "args.n_train= \"-1\"\n",
    "args.time_interval= 1\n",
    "args.save_interval= 10\n",
    "args.algo= \"contrast\"\n",
    "args.reg_type= None\n",
    "args.reg_coef= 0\n",
    "args.is_reg_anneal= True\n",
    "args.no_latent_evo= False\n",
    "args.encoder_type= \"cnn-s\"\n",
    "args.evolution_type= \"mlp-3-elu-2\"\n",
    "args.decoder_type= \"cnn-tr\"\n",
    "args.encoder_n_linear_layers= \"0\"\n",
    "args.n_conv_blocks= 4\n",
    "args.n_latent_levs= 2\n",
    "args.n_conv_layers_latent= 3\n",
    "args.channel_mode= \"exp-16\"\n",
    "args.is_latent_flatten= False\n",
    "args.evo_groups= 1\n",
    "args.recons_coef= 1\n",
    "args.consistency_coef= 1\n",
    "args.contrastive_rel_coef= 0\n",
    "args.hinge= 0\n",
    "args.density_coef= 0.001\n",
    "args.latent_noise_amp= \"1e-5\"\n",
    "args.normalization_type= \"gn\"\n",
    "args.latent_size= 16\n",
    "args.kernel_size= 4\n",
    "args.stride= 2\n",
    "args.padding= 1\n",
    "args.padding_mode= \"zeros\"\n",
    "args.act_name= \"elu\"\n",
    "args.multi_step= \"1\"\n",
    "args.latent_multi_step= \"1\"\n",
    "args.use_grads= False\n",
    "args.use_posargs= False\n",
    "args.is_y_diff= False\n",
    "args.loss_type= \"mse\"\n",
    "args.loss_type_consistency= \"mse\"\n",
    "args.batch_size= 2\n",
    "args.val_batch_size= 8\n",
    "args.epochs= 52\n",
    "args.opt= \"adam\"\n",
    "args.weight_decay= 0\n",
    "args.disc_coef= 0\n",
    "args.seed= 0\n",
    "args.gpuid= 1\n",
    "args.id= 0\n",
    "args.is_train=False\n",
    "args.is_test_only=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Settings:\n",
    "exp_id = \"smoke\"\n",
    "date_time = \"2022-3-28\"\n",
    "analsys_metrics = [\n",
    "    \"loss\",\n",
    "    \"recons\",\n",
    "    \"rollout\",\n",
    "]\n",
    "# include is a list of strings that the filename must include \n",
    "include = [\n",
    "    \".p\",\n",
    "    \"movinggas_train_-1_algo_contrast_ebm_False_ebmt_cd_enc_cnn-s_evo_cnn_act_elu_hid_128_lo_mse_recef_1.0_conef_1.0_nconv_4_nlat_1_clat_3_lf_True_reg_None_id_0_Hash_TgzjEJou_turing4.p\",\n",
    "]\n",
    "\n",
    "dataset_name = \"movinggas\"\n",
    "(dataset_train_val, dataset_test), (train_loader, val_loader, test_loader) = load_data(args)\n",
    "\n",
    "init_indices = [89]  # starting t\n",
    "n_rollout_steps = 86  # number of rollout steps\n",
    "interval = 1         # Interval to visualize\n",
    "is_test = True      # Whether to use the test dataset\n",
    "\n",
    "# Run analysis:\n",
    "dirname = EXP_PATH + \"{}_{}/\".format(exp_id, date_time)\n",
    "filenames = filter_filename(dirname, include=include)\n",
    "args_list = list(arg_parse().__dict__.keys())\n",
    "dataset = deepcopy(dataset_test[:init_indices[0]+n_rollout_steps+2]) if is_test else deepcopy(dataset_train_val[:init_indices[0]+n_rollout_steps+2])\n",
    "df, info_all = get_df(\n",
    "    filenames,\n",
    "    dataset,\n",
    "    arg_list=args_list,\n",
    "    analysis_metrics=analsys_metrics,\n",
    "    init_indices=init_indices,\n",
    "    n_rollout_steps=n_rollout_steps,\n",
    "    dataset_name=dataset_name,\n",
    "    interval=interval,\n",
    "    isplot=2,\n",
    ")\n",
    "# pickle.dump({\"df\": df, \"info_all\": info_all}, open(dirname + \"df_analysis_{}-{}.p\".format(datetime.datetime.now().month, datetime.datetime.now().day), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lepde",
   "language": "python",
   "name": "lepde"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
